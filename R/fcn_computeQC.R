#' Create a quality control report (in PDF format).
#'
#' This is the main function of the package and the only thing you need to call directly if you are 
#' just interested in getting a QC report.
#' 
#' You need to provide the folder name of the 'txt' output, as generated by MaxQuant and 
#' optionally a YAML configuration object, which allows to (de)activate certain plots and holds other parameters.
#' The yaml_obj is complex and best obtained by running this function once using the default (empty list).
#' A full YAML configuration object will be written in the 'txt' folder you provide and can be loaded using
#' \code{\link[yaml]{yaml.load}}. 
#' 
#' The PDF and the config file will be stored in the given txt folder.
#' 
#' @note You need write access to the txt folder!
#' 
#' For updates, bug fixes and feedback please visit \url{http://github.com/cbielow/R-PTXQC}.
#'
#' @param txt_folder Path to txt output folder of MaxQuant (e.g. "c:/data/Hek293/txt")
#' @param yaml_obj   A nested list object with configuration parameters for the report.
#'                   Useful to switch off certain plots or skip entire sections.
#' @return List with two strings: 
#'          \itemize{
#'            \item pdf_filename  Path to PDF report
#'            \item yaml_filename Path to a YAML configuration file used during report generation. 
#'                                Parameters missing in yaml_obj (input param) were restored to default.
#'          }
#'          
#' @import ggplot2
#' @import directlabels
#' @importFrom PerformanceAnalytics textplot
#' @importFrom plyr ddply summarise
#' @importFrom plotrix addtable2plot
#' @importFrom reshape2 melt
#' @importFrom RColorBrewer brewer.pal
#' @importFrom OrgMassSpecR MonoisotopicMass ConvertPeptide
#' @importFrom yaml as.yaml
#' @importFrom splines ns
#'  
#' @export
#'           
createReport <- function(txt_folder, yaml_obj = list())
{
  
if (0) ## for local execution and debug
{
  source("c:/projects/QC/_debugDirectLoad.R")
}
  
### script starts...

if (!file.info(txt_folder)$isdir)
{
  stop(paste0("Argument txt_folder with value '", txt_folder, "' is not a valid directory\n"));
}

YAML_CONFIG = list()
if (class(yaml_obj) != "list")
{
  stop(paste0("Argument 'yaml_obj' is not of type list\n"));
}


txt_files = list()
txt_files$param = "parameters.txt"
txt_files$summary = "summary.txt"
txt_files$groups = "proteinGroups.txt"
txt_files$evd = "evidence.txt"
txt_files$msms = "msms.txt"
txt_files$msmsScan = "msmsScans.txt"
txt_files = lapply(txt_files, function(x) paste(txt_folder, x, sep="\\"))


# ideas:
## automatic flagging of suspicious results
  
## increase package number if required. Added to output filename
if (!require("PTXQC", quietly=T)) pv = "_unknown" else pv = packageVersion("PTXQC")
report_version = paste0("v", pv)  


time_start = Sys.time()

stats_file = paste(txt_folder, "\\report_", report_version, "_stats.txt", sep="")
unlink(stats_file)

report_file = paste(txt_folder, "\\report_", report_version, ".pdf", sep="")
pdf(report_file, onefile=T)

yaml_file = paste(txt_folder, "\\report_", report_version, ".yaml", sep="")

######
######  parameters.txt ...
######

enabled_parameters = getYAML(yaml_obj, "File$Parameters$enabled", TRUE)
if (enabled_parameters)
{
  d_parAll = readMQ(txt_files$param, type="par")
  
  line_break = "\n  "; ## use space to make it work with table
  ## remove AIF stuff
  d_parAll = d_parAll[!grepl("^AIF ", d_parAll$parameter),]
  d_parAll$value = gsub(";", line_break, d_parAll$value)
  ## seperate FASTA files (usually they destroy the layout)
  idx_fastafile = grepl("fasta file", d_parAll$parameter, ignore.case = T)
  d_par_file = d_parAll[idx_fastafile, ]
  d_par = d_parAll[!idx_fastafile, ]
  ## remove duplicates
  d_par = d_par[!duplicated(d_par$parameter),]
  rownames(d_par) = d_par$parameter
  ## trim long param names (the user should know what they mean)
  d_par$parameter = sapply(d_par$parameter, function (s) {
    allowed_len = nchar("Keep low-scoring versions of ..."); 
    if (nchar(s) > allowed_len) {
      s = paste(substring(s, 1, allowed_len), "...", collapse = "", sep=" ")
    }
    return (s)
  })
  
  ## break long values into multiple lines (to preserve table width)
  d_par$value = sapply(d_par$value, function (s) {
    allowed_len = nchar("  Acetyl (Protein N-term)"); ## this is a typical entry -- everything which is longer gets split
    if (nchar(s) > allowed_len) {
      s_beg = seq(1, nchar(s) - 1, allowed_len)
      s = paste(unlist(substring(s, s_beg, s_beg + allowed_len)), collapse = line_break)
    }
    return (s)
  })
  
  ## two column layout
  d_par$parameter_ = NA
  d_par$value_ = NA
  mid = nrow(d_par)/2
  d_par$parameter_[1:mid] = d_par$parameter[(mid+1):nrow(d_par)]
  d_par$value_[1:mid] = d_par$value[(mid+1):nrow(d_par)]
  d_par = d_par[1:mid,]
  
  ##todo: read in mqpar.xml to get group information and ppm tolerances (parameters.txt just gives Group1)
  
  palette(c("black", "DarkBlue"))
  palette()
  tcol = matrix(2, nrow=nrow(d_par), ncol=ncol(d_par))
  tcol[, c(1,3)] = 1
  #install.packages("PerformanceAnalytics")
  #require(PerformanceAnalytics)
  textplot(d_par, halign="left", valign="center",  show.rownames=F, show.colnames=F, col.data=tcol)
  title(main="PAR: Parameters")
  mtext(text=gsub("(.*)", "  \\1", d_par_file$value), side=1, adj=0, line=3, omd=c(0,0,0,0)+0.1, cex=0.8)
  #dev.off()
}

######
######  summary.txt ...
######

enabled_summary = getYAML(yaml_obj, "File$Summary$enabled", TRUE)
if (enabled_summary)
{
    
  d_smy = readMQ(txt_files$summary, type="sm")
  #colnames(d_smy)
  #colnames(d_smy[[1]])
  
  ### MS/MS identified [%]
  dms = d_smy[[1]][,"ms.ms.identified...."]
  lab_IDd = c("bad (<20%)", "ok (20-35%)", "great (>35%)")
  d_smy[[1]]$color = factor(cut(dms, breaks=c(-1, 20, 35, 100), labels=lab_IDd))
  #unique(d_smy[[1]]$color)
  cols_IDd = c("red", "blue", "green")
  cols_IDs_active = cols_IDd[lab_IDd %in% unique(d_smy[[1]]$color)]
  #cols_IDs_active
  
  d_smy[[1]]$x = 1:nrow(d_smy[[1]])
  print(
    ggplot(d_smy[[1]], aes_string(x = "x", y = "ms.ms.identified....")) +
      geom_point(aes_string(colour = "color")) +
      xlab("raw file (ordered as in SM.txt)") + ylab("MS/MS identified [%]") +
      scale_colour_manual(values=cols_IDs_active) + 
      ggtitle("SM: MS/MS identified per RAW file") + 
      ylim(0, max(dms)*1.1) + 
      guides(color=guide_legend(title="ID class"))
    )
  
  ## table of files with 'bad' MS/MS id rate
  bad_id_count = sum(d_smy[[1]]$color==lab_IDd[1])
  if (bad_id_count>0)
  {
    plot(0:100, 0:100, type="n", axes=F, xlab="", ylab="")
    tbl_cex = ifelse(bad_id_count<25, 1, 25/bad_id_count)
    addtable2plot("topleft", y=NULL, 
                  d_smy[[1]][d_smy[[1]]$color==lab_IDd[1],c("raw.file","ms.ms.identified....")],
                  xjust=0, yjust=-0.0,
                  xpad=0, ypad=0.5,
                  title=paste0("SM: Files with '", lab_IDd[1], "' ID rate (", round(bad_id_count*100/nrow(d_smy[[1]])),"% of samples)\n"),
                  cex=tbl_cex)
  }
}  


######
######  proteinGroups.txt ...
######

enabled_proteingroups = getYAML(yaml_obj, "File$ProteinGroups$enabled", TRUE)
if (enabled_proteingroups)
{
    
  d_pg = readMQ(txt_files$groups, type="pg", col_subset=NA, filter="R")
  
  ## Contaminants stats
  idx_int = colnames(d_pg)[grep("^intensity\\.", colnames(d_pg))]
  idx_int
  con_stats = t(sapply(idx_int, function(x) sum(as.numeric(d_pg[d_pg$contaminant=="+", x]))/sum(as.numeric(d_pg[, x]))*100 ))
  con_stats[is.na(con_stats)] = 0
  colnames(con_stats) = shortenStrings(simplifyNames(delLCP(idx_int)), max_len = 12)
  
  #barplot(con_stats, ylim=c(0,max(20, max(con_stats)*1.1)), main="PG: Contaminant per condition", xlab="", ylab="% intensity of contaminants", las=3,)
  #abline(a=5, b=0, col="red", lwd=4)
  plotContsPG = function(datav) {
    datav$section = as.integer(seq(0, nrow(datav)/40, length.out=nrow(datav)))
    pl = 
      ggplot(data=datav, aes_string(x = "x", y = "y")) +
        geom_bar(stat="identity") +
        theme(axis.text.x = element_text(angle=90)) +
        xlab("")  +
        ggtitle("PG: Contaminant per condition") +
        ylab("contaminant (% intensity)") +
        geom_hline(aes_string(yintercept = "5"), linetype = 'dashed') +
        facet_wrap(~ section, ncol = 1, scales="free_x")
    return (pl)
  }
  df.con_stats = data.frame(x=colnames(con_stats), y=as.vector(con_stats[1,]))
  # plot list (for later plotting)
  pg_plots_cont = byXflex(df.con_stats, 1:length(df.con_stats), 120, plotContsPG, sort_indices=T)
  for (p in pg_plots_cont) print(p);
  
  ### warn of special contaminants!
  ## these need to be in FASTA headers (description is not enough)!
  ## syntax:  list( contaminant1 = c(name, threshold), contaminant2 = c(...), ...)
  contaminant_alarm = list("cont_MYCO" = c(name="MYCOPLASMA", threshold=1)) # name (FASTA), threshold for % of unique peptides
  #contaminant_alarm = list("cont_MYCO" = c(name="UniRef100", threshold=1)) # name (FASTA), threshold for % of unique peptides
  #contaminant_alarm = list("cont_MYCO" = c("MYCOPLASMA", 1), "cont_corrbt" = c("corrbt7", 1)) 
  # yaml_contaminants = contaminant_alarm
  yaml_contaminants = getYAML(yaml_obj, "File$ProteinGroups$SpecialContaminants", contaminant_alarm)
  for (ca_entry in yaml_contaminants)
  {
    #ca_entry = yaml_contaminants[[1]]
    ca = ca_entry[1]
  
    # ca = yaml_contaminants[1]
    # idx = 1:30
    idx = grep(ca, d_pg$fasta.header, ignore.case = T)
  
    ## we might or might not have found something... we plot it anyways, so the user can be sure that we searched for it
  
    ## total number of unique peptides
    unique_total = sum(d_pg$unique.peptides[idx])
    idx_uniquePep = grepv("^unique.peptides", colnames(d_pg))
    idx_intensity = grepv("^intensity", colnames(d_pg))
    
    ca_protgroups = d_pg$protein.ids[idx]
    ca_samples_pep = colSums(d_pg[idx, idx_uniquePep, drop=F])
    
    ca_samples_intProportion = colSums(d_pg[idx, idx_intensity, drop=F]) / colSums(d_pg[, idx_intensity, drop=F], na.rm = T) * 100
    names(ca_samples_intProportion) = paste0("int", delLCP(names(ca_samples_intProportion)))
  
    ca_samples_pepProportion = colSums(d_pg[idx, idx_uniquePep, drop=F]) / colSums(d_pg[, idx_uniquePep, drop=F], na.rm = T) * 100
    above.thres = (ca_samples_pepProportion > as.numeric(ca_entry[2]))
    names(ca_samples_pepProportion) = paste0("pep", delLCP(names(ca_samples_pepProportion)))
    
    names(above.thres) = delLCP(names(above.thres))
    above.thres
    
    ## build data for plotting
    bar.data = data.frame(name = c(names(ca_samples_pepProportion), names(ca_samples_intProportion)),
                          value = c(ca_samples_pepProportion, ca_samples_intProportion))
    bar.data$name = shortenStrings(simplifyNames(as.character(factor(bar.data$name, levels=bar.data$name))))
    bar.data$group = c(rep("pepCount", length(ca_samples_pepProportion)), rep("int", length(ca_samples_intProportion)))
    #pdf("test.pdf")
    main_sub_found = ""
    main_col = "red"
    if (sum(above.thres) == 0) {
      #install.packages("gridExtra")
      #library(gridExtra)
      #grid.newpage()
      #gt = grid.text((paste("Not found")),
      #          x = unit(.5, "npc"), y = unit(.5, "npc"), just = c("center", "bottom"), 
      #          gp = gpar(fontface = "bold", fontsize = 18, col = "red"))
      main_sub_found = "\n\nNot found"
      main_col="black"
    }
  
    if (sum(bar.data$value)==0)
    { ## identifier was not found in any sample
      plot(0:100, 0:100, type="n", axes=F, xlab="",ylab="")
      mtext(line=-2, paste0("Contaminant '", ca, "' was not found in any sample.\n\nDid you use the correct database?"))  
    } else {
      plotContUser = function(datav, extra_limit) {
        cat(paste0("CA entry is ", extra_limit, "\n"))
        datav$section = as.integer(seq(0, nrow(datav)/40, length.out = nrow(datav)))
        pr = ggplot(datav, aes_string(x = "factor(name)", y = "value")) +
            geom_bar(stat="identity", aes_string(fill = "group"), position = "dodge") +
            theme(axis.text.x = element_text(angle=90)) +
            xlab("")  +
            theme(plot.title = element_text(colour = main_col)) +
            ylab("abundance (%)") +
            ylim(c(0, max(extra_limit, max(bar.data$value, extra_limit)*1.1))) +
            geom_hline(yintercept = extra_limit, linetype = 'dashed') +
            facet_wrap(~ section, ncol = 1, scales = "free_x")
        pr = addGGtitle(pr, paste0("PG: Contaminant '", ca, "'"), main_sub_found)
        print(pr) 
      }
      byXflex(data = bar.data, indices = 1:nrow(bar.data), subset_size = 120, FUN = plotContUser, sort_indices=T, extra_limit = as.numeric(ca_entry[2]))
    }
  
    #dev.off()
    
    report_short = pastet("Contaminant:", ca, paste0(sum(above.thres),"/",length(ca_samples_pep)," sample-classes"), paste0(unique_total," unique peptides total"))
    report_samples  = pastet("Contaminant-details (name, sample, peptides%): " , ca, names(ca_samples_pepProportion), ca_samples_pepProportion, collapse="\n")
    report_samples2 = pastet("Contaminant-details (name, sample, intensity%): ", ca, names(ca_samples_intProportion), ca_samples_intProportion, collapse="\n")
    cat(pasten(report_short, report_samples, report_samples2), file=stats_file, append=T, sep="\n")
    
  } ## contaminant loop
  
  clusterCols = list()
  ## intensity boxplots ##
  colsSIL = grepv("^intensity.[HLM].", colnames(d_pg))
  colsLF = grepv("^intensity.[^HLM].", colnames(d_pg))
  colsOneCond = "intensity"
  if (length(colsSIL)) colsW = colsSIL else if (length(colsLF)) colsW = colsLF else colsW = colsOneCond
  clusterCols$raw.intensity = colsW ## cluster using intensity
  cat("colsW:\n")
  cat(paste0(colsW, collapse=","))
  ## some stats (for plot title)
  medians_no0 = sort(apply(log2(d_pg[, colsW, drop=F]), 2, function(x) quantile(x[x>0], probs=0.5))) # + c(0,0,0,0,0,0))
  int_dev_no0 = RSD(medians_no0)
  ## do not remove zeros (but add +1 since RSD is 'NA' when 'inf' is included in log-data)
  medians = sort(apply(log2(d_pg[, colsW, drop=F]+1), 2, quantile, na.rm=T, probs=0.5)) # + c(0,0,0,0,0,0))
  int_dev = RSD(medians)
  int_dev.s = pastet("INT RSD [%]", round(int_dev, 3))
  boxplotCompare(data1 = d_pg[, colsW, drop=F], data2=NA, log2_ratios = T, 
                 mainlab="intensity distribution", 
                 sublab=paste0("RSD ", round(int_dev_no0, 1),"% (should be < 5%)\nRSD ", round(int_dev, 1),"% (with 0's remaining) [high RSD indicates few peptides])"),
                 abline = 25)
  cat(int_dev.s, file=stats_file, append=T, sep="\n")
  
  ## LFQ boxplots
  colsSIL = grepv("^lfq.intensity.[HLM].", colnames(d_pg))
  colsLF = grepv("^lfq.intensity.[^HLM].", colnames(d_pg))
  if (length(c(colsSIL, colsLF)) > 0)
  {
    if (length(colsSIL)) colsW = colsSIL else colsW = colsLF
    clusterCols$lfq.intensity = colsW ## cluster using LFQ
    ## some stats (for plot title)
    medians_no0 = sort(apply(log2(d_pg[, colsW, drop=F]), 2, function(x) quantile(x[x>0], probs=0.5))) # + c(0,0,0,0,0,0))
    lfq_dev_no0 = RSD(medians_no0)
    ## do not remove zeros (but add +1 since RSD is 'NA' when 'inf' is included in log-data)
    medians = sort(apply(log2(d_pg[, colsW, drop=F]+1), 2, quantile, probs=0.5)) # + c(0,0,0,0,0,0))
    lfq_dev = RSD(medians)
    lfq_dev.s = pastet("LFQ RSD [%]", round(lfq_dev, 3))
    boxplotCompare(d_pg[, colsW, drop=F], NA, T, ylab="LFQ", 
                   mainlab="LFQ intensity distribution", 
                   sublab= paste0("RSD ", round(lfq_dev_no0, 1),"% (should be < 5%)\nRSD ", round(lfq_dev, 1),"% (with 0's remaining) [high RSD indicates few peptides])"),
                   abline = 25)
    cat(lfq_dev.s, file=stats_file, append=T, sep="\n")
  }
  
  ## for iTRAQ/TMT, reporter ion intensity boxplot
  colsITRAQ = grepv("^reporter.intensity.[0-9].", colnames(d_pg))
  if (length(colsITRAQ) > 0)
  {
    colsW = colsITRAQ
    clusterCols$reporter.intensity = colsW ## cluster using reporters
    ## some stats (for plot title)
    medians_no0 = sort(apply(log2(d_pg[, colsW, drop=F]), 2, function(x) quantile(x[x>0], probs=0.5))) # + c(0,0,0,0,0,0))
    reprt_dev_no0 = RSD(medians_no0)
    ## do not remove zeros (but add +1 since RSD is 'NA' when 'inf' is included in log-data)
    medians = sort(apply(log2(d_pg[, colsW, drop=F]+1), 2, quantile, probs=0.5)) # + c(0,0,0,0,0,0))
    reprt_dev = RSD(medians)
    reprt_dev.s = pastet("Reporter RSD [%]", round(reprt_dev, 3))
    boxplotCompare(d_pg[, colsW, drop=F], NA, T, ylab="Reporter", 
                   mainlab="Reporter intensity distribution", 
                   sublab= paste0("RSD ", round(reprt_dev_no0, 1),"% (should be < 5%)\nRSD ", round(reprt_dev, 1),"% (with 0's remaining) [high RSD indicates low reporter intensity])"),
                   abline = 25)
    cat(reprt_dev.s, file=stats_file, append = T, sep="\n")
  }
  
  
  ## some clustering (its based on intensity / lfq.intensity columns..)
  ## todo: maybe add ratios -- requires loading from txt though..
  for (cond in names(clusterCols))
  {
    #cond = names(clusterCols)[3]
    print(clusterCols[cond])
    if (length(clusterCols[cond]) <= 1) 
    { ## only one condition.. PCA does not make sense (and will not work)
      next;
    }
    data = t(d_pg[, unlist(clusterCols[cond]), drop=F])
    ## remove constant/zero columns (== dimensions == proteins)
    data = data[, colSums(data) > 0, drop=F]
    rownames(data) = simplifyNames(strings = rownames(data), infix_iterations = 2)
    getPCA(data = data, gg_layer = ggtitle(paste("PG: PCA\n", sub(".", " ", cond, fixed=T))))
  }
  
  ##################################
  ## ratio plots
  ##################################
  
  ## get ratio column
  ratio_cols = grepv("^ratio\\.h\\.l", colnames(d_pg))
  ## remove everything else
  ratio_cols = grepv("^ratio.h.l.normalized", ratio_cols, invert=T)
  ratio_cols = grepv("^ratio.h.l.count", ratio_cols, invert=T)
  ratio_cols = grepv("^ratio.h.l.variability", ratio_cols, invert=T)
  ratio_cols
  
  if (length(ratio_cols) > 0)
  {
    d_sub = log2(d_pg[,ratio_cols, drop=F])
    ## rename "ratio.l.h" to "ratio.l.h.l.h"
    colnames(d_sub)[1] = "l.h"
    ## simplify the rest
    if (ncol(d_sub) > 1) 
    {
      colnames(d_sub)[-1] = simplifyNames(strings = delLCP(colnames(d_sub)[-1]))
    }
    #summary(d_sub)
    # 
    # plot(density(d_sub[,1], bw = "SJ", adjust=1, na.rm=T, n=128))
    # plot(d_sub[,1])
    # h = density(d_sub[,1], bw = "SJ", adjust=1, na.rm=T, n=128)
    
    
    ## get ranges to fix breaks for density intervals
    # breaks = seq(min(d_sub, na.rm=T), max(d_sub, na.rm=T), length.out=(max(dd, na.rm=T)-min(dd, na.rm=T))/0.5)
    # mid = hist(d_sub[, 1], breaks = breaks)$mids
    ratio.densities = do.call(rbind, (lapply(1:ncol(d_sub), function(x) {
      h = density(d_sub[ ,x], bw = "SJ", adjust=2, na.rm=T)
      name = colnames(d_sub)[x]
      count = sum(getMaxima(h$y))
      if (count > 1) name = paste(name, "*")
      df = data.frame(x = h$x, y = h$y, col = name, multimodal = (count>1))
      return (df)
    })))
    ratio.densities$alpha = c(0.8, 1)[ratio.densities$multimodal+1]
    ratio.densities$ltype = c("dotted", "solid")[ratio.densities$multimodal+1]
    #head((ratio.densities))
    
    title_ratio = "PG: ratio density"
    title_col = "black"
    if (any(ratio.densities$multimodal))
    {
      title_ratio = paste0(title_ratio, "\nWarning: multimodal densities detected")
      title_col = "red"
    }
    
    plotRatios = function(df_ratios, d_min, d_max, title_col)
    {
      br = c(2, 5, 10, 20);
      print(
        ggplot(data = df_ratios, aes_string(x = "x", y = "y", colour = "col")) + 
          facet_grid(col ~ ., scales = "free_y") +
          geom_line(aes_string(linetype="ltype", alpha = "alpha"), size = 1.2) +
          geom_area(aes_string(fill = "col"), alpha=0.5) +
          xlab("ratio")  +
          ylab("density")  +
          #facet_grid(col ~ ) +
          scale_fill_manual(values = rep(brewer.pal(6,"Accent"), times=400), guide_legend("")) + 
          scale_colour_manual(values = rep(brewer.pal(6,"Accent"), times=400), guide_legend("")) +
          scale_linetype_manual(values = c("dotted"="dotted", "solid"="solid"), 
                                labels=c("dotted"="unimodal", "solid"="multimodal"),
                                guide_legend("mode")
          ) +
          scale_x_continuous(limits = c(d_min, d_max), trans = "identity", breaks = c(-br, 0, br), labels=c(paste0("1/",2^(br)), 0, 2^br)) +
          guides(alpha=FALSE, colour=FALSE) +
          theme(plot.title = element_text(colour = title_col)) +
          ggtitle(title_ratio)
      )
      return (1)
    }
    
    byXflex(ratio.densities, ratio.densities$col, 5, plotRatios, sort_indices = F, d_min = min(d_sub, na.rm=T), d_max = max(d_sub, na.rm=T), title_col)
    
  }
  
}

######
######  evidence.txt ...
######

enabled_evidence = getYAML(yaml_obj, "File$Evidence$enabled", TRUE)
if (enabled_evidence)
{
  #d_evd_s = readMQ(txt_files$evd, type="ev", nrows=10000)
  #colnames(d_evd)
  #[grep("ount", colnames(d_evd))]
  
  d_evd = readMQ(txt_files$evd, type="ev", filter="R", col_subset=c("proteins", "Retention.Length", "retention.time.calibration", "Match.Time.Difference", "^Sequence$", "^intensity$", "Mass\\.Error", "^uncalibrated...calibrated." , "Raw.file", "^Protein.Group.IDs$", "Contaminant", "Retention.time$", "^m.z$", "^Contaminant", "[RK]\\.Count", "^Charge$", "modified.sequence", "^Mass$"))
  #d_evd = readMQ(txt_files$evd, type="ev", filter="R", col_subset=c("labeling.state", "Match.Time.Difference", "fasta.headers", "^intensity$", "Raw.file", "^Protein.Group.IDs$"))
  #summary(head(d_evd))
  #head(d_evd)
  #colnames(d_evd)
{
  ## ms.ms.count is always 0 when mtd has a number; 'type' is always "MULTI-MATCH" and ms.ms.ids is empty!
  #dsub = d_evd[,c("ms.ms.count", "match.time.difference")]
  #head(dsub[is.na(dsub[,2]),])
  #sum(0==(dsub[,1]) & is.na(dsub[,2]))
  ##
  ## MQ1.4 MTD is either: NA or a number
  ##
  
  
  # use only if it contains information (all NA if disabled)
  has_mtd = !is.na(d_evd$match.time.difference)
  head(has_mtd)
  # if ALL na's, just fill it with "true"
  #length(na.omit(d_evd$match.time.difference))==0
  #if (length(na.omit(d_evd$match.time.difference))==0) has_mtd = rep(T,length(mtd))
  
  ## only count protein groups from non-inferred evidence
  # get only the column without MTDs
  d_evd$hasMTD = has_mtd
  protGroupCount_pre = ddply(d_evd[, c("hasMTD", "raw.file", "protein.group.ids")], "raw.file", .fun = function(x){
    ## proteins
    # remove duplicates (since strsplit below is expensive)
    x$group_mtdinfo = paste(x$protein.group.ids, x$hasMTD, sep="_")
    xpro = x[!duplicated(x$group_mtdinfo),]
    p_groups = lapply(as.character(xpro$protein.group.ids), function(x) {
      return (strsplit(x, split=";", fixed=T))
    })
    # get number of unique groups
    pg_count_noMBR = length(unique(unlist(p_groups[!xpro$hasMTD])))
    pg_count_extraMBR = length(unique(unlist(p_groups))) - pg_count_noMBR
    
    ## peptides
    ## (we count double sequences... mhh...)
    pep_count_noMBR = sum(!x$hasMTD)
    pep_count_MBRgain = nrow(x) - pep_count_noMBR
    
    return (c(proteinCount_noMBR = pg_count_noMBR, 
              proteinCount_MBRgain = pg_count_extraMBR,
              pep_count_noMBR = pep_count_noMBR,
              pep_count_MBRgain = pep_count_MBRgain))
  })
  protGroupCount_pre
  ## manually melt
  pgc =       data.frame(raw.file = protGroupCount_pre$raw.file, protCount = protGroupCount_pre$proteinCount_noMBR, match = "no")
  pgc = rbind(pgc,
              data.frame(raw.file = protGroupCount_pre$raw.file, protCount = protGroupCount_pre$proteinCount_MBRgain, match = "yes"))
  pgc

  # combine Prot & Pep stats
  ## Warn: this is still different from summary.txt...
  #colnames(ppg) = c("# protein groups", "# peptides", "# peptides\n(incl. matched)", "file")
  #mdat = melt(ppg, id.vars="file")
  
  head(pgc)
  pgc$block = factor(assignBlocks(pgc$raw.file, 30))
  max_prot = max(protGroupCount_pre$proteinCount_noMBR + protGroupCount_pre$proteinCount_MBRgain)
  #require(RColorBrewer)
  ddply(pgc, "block", .fun = function(x) {
    x$s.raw.file = simplifyNames((as.character(x$raw.file)))
    print(ggplot(x, aes_string(x = "s.raw.file", y = "protCount", fill = "match")) +
            geom_bar(stat = "identity", position = "stack") +
            xlab("") +
            ylim(0, max_prot) +
            scale_fill_manual(values = rep(brewer.pal(6,"Accent"), times=400)) +
            ggtitle("EV: Protein ID stats (small bias vs SM.txt)") + 
            ylab("count") +
            coord_flip()
          )
    return (1)
  })
  
  
  pepc =       data.frame(raw.file = protGroupCount_pre$raw.file, pepCount = protGroupCount_pre$pep_count_noMBR, match = "no")
  pepc = rbind(pepc,
               data.frame(raw.file = protGroupCount_pre$raw.file, pepCount = protGroupCount_pre$pep_count_MBRgain, match = "yes"))
  pepc
  
  head(pepc)
  pepc$block = factor(assignBlocks(pepc$raw.file, 30))
  max_pep = max(protGroupCount_pre$pep_count_noMBR + protGroupCount_pre$pep_count_MBRgain)
  #require(RColorBrewer)
  ddply(pepc, "block", .fun = function(x) {
    x$s.raw.file = simplifyNames((as.character(x$raw.file)))
    print(ggplot(x, aes_string(x = "s.raw.file", y = "pepCount", fill = "match")) +
            geom_bar(stat = "identity", position = "stack") +
            xlab("") +
            ylim(0, max_pep) +
            scale_fill_manual(values = rep(brewer.pal(6,"Accent"), times=400)) +
            ggtitle("EV: Peptide ID stats (small bias vs SM.txt)") + 
            ylab("count") +
            coord_flip()
    )
    return (1)
  })
    
  ##
  ## retention time calibration (to see if window was sufficiently large)
  if (any(d_evd$retention.time.calibration, na.rm=T)) 
  {
    MBR_warning = ""
    if (-1e-4 < min(d_evd$retention.time.calibration) & max(d_evd$retention.time.calibration) < 1e-4)
    { ## Proably MBR was switched off
      ## Alternatively, we could use 'd_evd$match.time.difference', but its not guaranteed that the user has activated it
      MBR_warning = "Warning: MBR was off - data are (very small) MQ artifacts"  
    }
    
    param_name_mbr = "File$Evidence$MatchBetweenRuns_wA"
    param_evd_mbr = getYAML(yaml_obj, param_name_mbr, "auto")
    if (param_evd_mbr == FALSE || (nchar(MBR_warning)>0 && param_evd_mbr=="auto"))
    {
      MBR_warning_auto = ""
      if (nchar(MBR_warning)>0) MBR_warning_auto = "Match-between-runs has no data to show."
      plot(0:100, 0:100, type="n", axes=F, xlab="",ylab="")
      mtext(line=-2, paste0("'Match-between-runs' plot is disabled.\n\nYAML variable '", param_name_mbr, "' is set to '",  param_evd_mbr,"'.\n", MBR_warning_auto))  
    } else
    {
      ## global histogram of delta times
      hist(d_evd$retention.time.calibration, 100, 
           main=paste0("EV: Summary of time difference between\nmatched features across files\n", MBR_warning), 
           xlab="time [min]",
           ylab="count")
      
      #require(splines) ## for ns()
      splitRTAlignByRawFile = function(RTdata) {
        pl = ggplot(data=RTdata, aes_string(x = "retention.time", y = "retention.time.calibration")) 
        # needs to be done here and not at the end (due to facet_wrap)
        pl = addGGtitle(pl, "EVD: Retention Time Mapping", MBR_warning)
        pl = pl +
          geom_point(alpha=0.5) +
          stat_smooth(method = "lm", formula = y ~ ns(x,30), se = TRUE, size=1, colour = "red") +
          facet_wrap( ~ fc.raw.file) +
          ylab("match time difference [min]") +
          xlab("retention time [min]")
        print(pl)
      }
      
      byX(d_evd[,c("retention.time", "retention.time.calibration", "fc.raw.file")], as.numeric(as.factor(d_evd$fc.raw.file)), 8, splitRTAlignByRawFile)
    }
  }
  
  ##
  ## additional evidence by matching MS1 by AMT across files
  if (any(d_evd$match.time.difference, na.rm=T)) {
    ## scatter plot: for each raw file give median time diff and # peptides used for matching
    r = (by(d_evd$match.time.difference, d_evd$raw.file, function(x) {
      match_count_abs = sum(!is.na(x));
      match_count_pc  = round(100*sum(!is.na(x))/length(x))
      c(match_count_abs, match_count_pc)
    }))
    tmp_lab = names(r)
    r = unlist(r)
    mtr.df = data.frame(abs = r[seq(1,length(r),by=2)], pc = r[seq(2,length(r),by=2)])
    mtr.df$lab = tmp_lab
    ## shorten labels (if required)
    if (max(nchar(mtr.df$lab)) > 10) {
      mtr.df$lab = as.character(d_evd$fc.raw.file[match(mtr.df$lab, d_evd$raw.file)])
    }
    
    
    p_amt = ggplot(data=mtr.df, aes_string(x = "abs", y = "pc", col = "lab")) + 
      geom_point(size=2) + 
      #geom_text(size=2, vjust=1, aes_string(alpha=0.5)) + 
      ggtitle(paste0("EVD: Peptides inferred by AMT-matching\n", round(100*sum(!is.na(d_evd$match.time.difference))/nrow(d_evd)) ,"% average" )) +
      xlab("inferred by MS1 [count]") +
      ylab("inferred by MS1 [%]") +
      xlim(0, max(mtr.df$abs, na.rm=T)*1.1) +
      ylim(0, max(mtr.df$pc, na.rm=T)*1.1)
    #install.packages("directlabels")
    #require(directlabels)
    print(direct.label(p_amt, list(cex=0.5, "smart.grid")))
    #print(p_amt)
    
  } 
  
  ##
  ## charge distribution
  ##
  fcChargePlot = function(d_sub)
  {
    print(
      mosaicPlot(d_evd$fc.raw.file, d_evd$charge) +
             xlab("RAW file") +
             ylab("fraction [%]") +
             guides(fill=guide_legend(title="charge"), color=FALSE) + # avoid black line in legend
             coord_flip() +
             theme(axis.text.y=element_blank(), axis.ticks=element_blank()) +
             ggtitle("EVD: charge distribution")
    )
    return (1);
  }
  byXflex(d_evd[, c("fc.raw.file", "charge")], d_evd$fc.raw.file, 30, fcChargePlot, sort_indices = FALSE)
  
  
  
  ## peptides per RT 
  raws_perPlot = 8
  smr_evdRT = summary(d_evd$retention.time)
  max_y = max(by(d_evd$retention.time, d_evd$fc.raw.file,  function(d) max(hist(d, breaks=seq(from=min(d)-3, to=max(d)+3, by=3), plot=F)$counts)))
  fcRTSubset <- function(d_sub, smr_evdRT)
  {
    qp = ggplot(data = d_sub, aes_string(x = "retention.time", colour = "fc.raw.file")) +
                geom_freqpoly(binwidth = 3) +
                xlim(from = smr_evdRT["Min."] - 1, to = smr_evdRT["Max."] + 2) +
                xlab("RT [min]") + 
                ylim(from = 0, to = max_y) +
                ylab("ID count") +
                ggtitle("EVD: IDs over RT") +
                theme(legend.title=element_blank()) +
                scale_color_brewer(palette="Set2")
    print(qp)
    return (1)
  }
  byXflex(d_evd, d_evd$raw.file, raws_perPlot, fcRTSubset, smr_evdRT=smr_evdRT)
} 
  ## histograms of mass error
  
  ## MQ seems to mess up mass recal on some (iTRAQ) samples, by reporting ppm errors which include modifications
  ## , thus one sees >1e5 ppm, e.g. 144.10 Da
  ##  this affects both 'uncalibrated.mass.error..ppm.'   and
  ##                    'mass.error..ppm.'
  ## HOWEVER, 'uncalibrated...calibrated.m.z..ppm.' seems unaffected, but is not available in all MQ versions :(
  ##    also, 'mass' and 'm/z' columns seem unaffected.
  ##  But weirdly, one cannot reconstruct mass_error[ppm] from 'm/z' and mass columns (m/z is just too close to the theoretical value)
  ##  , this might be due to lacking precision of the stored numbers though
  ## The MQ list reports one case with high ppm error (8000), where the KR.count was at fault. We cannot
  ## reconstruct this.
  recal_message = ""
  ## check each raw file individually (usually its just a few who are affected)
  de_cal = ddply(d_evd, "raw.file", .fun = function(x) (quantile(abs(x$uncalibrated.mass.error..ppm.), probs = 0.5, na.rm=T)) > 1e3)
  if (any(de_cal[,2]))
  {
    ## for stats, show how many % of spectra suffer from this
    de_cal_pc = ddply(d_evd, "raw.file", .fun = function(x) (sum((abs(x$uncalibrated.mass.error..ppm.)) > 1e3, na.rm=T) / nrow(x) * 100))
    de_cal_pc_pl = de_cal_pc[de_cal_pc[,2]>0, ]
    byXflex(de_cal_pc_pl, 1:nrow(de_cal_pc_pl), 25, function(x) {
      dc = x[, 2]
      names(dc) = x[, 1]
      barplot(dc, horiz=T, las=2, main = "RAW files affected by wrong calibration numbers", xlab="% of ID's affected", cex.names = 0.5)
    })
    affected_raw_files = de_cal_pc_pl[, 1]
    
    ## re-compute 'uncalibrated.mass.error..ppm.'
    
    if (!("uncalibrated...calibrated.m.z..ppm." %in% colnames(d_evd)))
    {
      stop("column missing: 'uncalibrated...calibrated.m.z..ppm.'")
    }
    if (!("mass" %in% colnames(d_evd)))
    {
      stop("column missing: 'mass'")
    }
    
    { ## this MQ version has it...
      
#       counts =  d_evd$k.count + d_evd$r.count
#       idx_decal = (abs(d_evd$uncalibrated.mass.error..ppm.) > 30)
#       hist(d_evd$mass - d_evd$m.z * d_evd$charge, 1000)
#       unique(d_evd$mass - d_evd$m.z * d_evd$charge)
#       hist(counts[!idx_decal])
      
      recal_message = "m/z recalibration bugfix applied"
      
      d_evd$theomz = d_evd$mass / d_evd$charge + 1.00726
      
      ## re-estimate 'mass.error..ppm.'
      d_evd$mass.error..ppm.2 = (d_evd$theomz - d_evd$m.z) / d_evd$theomz * 1e6
      #hist(d_evd$mass.error..ppm.2, 1000)
      #plot(d_evd$mass.error..ppm.2, d_evd$mass)
      #hist(d_evd$mass.error..ppm. - d_evd$mass.error..ppm.2, 100000, xlim=c(-30,30))
      d_evd$uncalibrated.mass.error..ppm.2 = d_evd$mass.error..ppm.2 + d_evd$uncalibrated...calibrated.m.z..ppm.
      
      # check if fix worked
      de_cal2 = ddply(d_evd, "raw.file", .fun = function(x) (median(abs(x$uncalibrated.mass.error..ppm.2), na.rm=T)) > 1e3)
      if (any(de_cal2[,2]))
      {
        ## fix did not work
        recal_message = "m/z recalibration bugfix applied but failed\n(there are still large numbers)"
      }
      
    }
#      else {
#       recal_message = "m/z recalibration bugfix cannot be applied\n(uncalibrated values not recoverable)\naffected samples are set to 0")
#       d_evd$uncalibrated.mass.error..ppm.2[d_evd$raw.file %in% affected_raw_files ] = 0
#     }
    #hist(d_evd$uncalibrated.mass.error..ppm. - d_evd$uncalibrated.mass.error..ppm.2, 100000, xlim=c(-30,30))
    
    idx_overwrite = (d_evd$raw.file %in% affected_raw_files)
    ## overwrite original values
    d_evd$mass.error..ppm.[idx_overwrite] = d_evd$mass.error..ppm.2[idx_overwrite]
    d_evd$uncalibrated.mass.error..ppm.[idx_overwrite] = d_evd$uncalibrated.mass.error..ppm.2[idx_overwrite]

    #max_ume = max(abs(d_evd$uncalibrated.mass.error..ppm.), na.rm=T)
    #max_idx = which (abs(d_evd$uncalibrated.mass.error..ppm.) == max_ume)
    #d_evd[max_idx,]
    #iqr
    
  }
  
  
  ## some outliers have 5000ppm or so.. messing up the plot
  ## , so either remove outliers before (quantile estimation seems not robust enough) or don't plot them (default)
  plotAlignDiff = function(d_evd, affected_raw_files)
  {
    ## sort by rawfile name
    d_evd = d_evd[order(as.character(d_evd$raw.file)),]
    col = c("black", "red")[(unique(d_evd$raw.file) %in% affected_raw_files) + 1]
    
    boxplot(uncalibrated.mass.error..ppm. ~ raw.file, d_evd, names=d_evd$fc.raw.file[match(unique(d_evd$raw.file), d_evd$raw.file)], 
            ylab="ppm error", main = "EVD: Uncalibrated mass error", horizontal = TRUE,
            las=1, outline=FALSE, varwidth=T, pars = list(cex.axis=0.75), cex.names = 0.5, col = col)
    if (nchar(recal_message)) mtext(text=recal_message, side=3, col="red")
  }
  pp = byXflex(d_evd, d_evd$fc.raw.file, 20, plotAlignDiff, sort_indices=T, affected_raw_files=affected_raw_files)
  
  plotAlignDiffCal = function(d_evd, affected_raw_files)
  {
    ## sort by rawfile name
    d_evd = d_evd[order(as.character(d_evd$raw.file)),]
    col = c("black", "red")[(unique(d_evd$raw.file) %in% affected_raw_files) + 1]
    
    boxplot(mass.error..ppm. ~ raw.file, d_evd, names=d_evd$fc.raw.file[match(unique(d_evd$raw.file), d_evd$raw.file)], 
            ylab="ppm error", main = "EVD: Calibrated mass error", horizontal = TRUE,
            las=2, outline=FALSE, varwidth=T, pars = list(cex.axis=0.75), cex.names = 0.5, col = col)
    if (nchar(recal_message)) mtext(text=recal_message, side=3, col="red")
  }
  pp = byXflex(d_evd, d_evd$fc.raw.file, 20, plotAlignDiffCal, sort_indices=T, affected_raw_files=affected_raw_files)
  
  ## compute how well calibration worked
  cal_medians = as.vector(by(d_evd$mass.error..ppm., d_evd$raw.file, median, na.rm=T))
  cal_stats = quantile(cal_medians, probs=c(0,0.5,1))
  cat(pastet("medianCalibratedMassError(min,median,max) [ppm]", paste(cal_stats, collapse=",")), file=stats_file, append=T, sep="\n") 
  
  ## elaborate contaminant fraction per Raw.file
  ## find top 5 contaminants (globally)
  d_evd.totalInt = sum(as.numeric(d_evd$intensity), na.rm=T)
  d_evd.cont.only = d_evd[d_evd$contaminant=="+",]
  cont.top = by(d_evd.cont.only, d_evd.cont.only$proteins, function(x) sum(as.numeric(x$intensity), na.rm=T) / d_evd.totalInt*100)
  cont.top.sort = sort(cont.top, decreasing=T)
  #head(cont.top.sort)
  cont.top5.names = names(cont.top.sort)[1:5]
  plotCont = function(d_evd_sub, top5) 
  { 
    intensity = NULL ## to make R CHECK happy...
    d_evd.cont.only_sub = d_evd_sub[d_evd_sub$contaminant=="+",]
    ## rewrite prot names, and subsume 6th and below as 'other'
    d_evd.cont.only_sub$proteins[!(d_evd.cont.only_sub$proteins %in% top5)] = 'other'
    ## aggregate identical proteins
    ##  use sum(as.numeric(.)) to prevent overflow
    d_sum = ddply(d_evd.cont.only_sub[, c("intensity", "proteins", "fc.raw.file")], c("proteins", "fc.raw.file"), function(x) summarise(x, s.intensity=sum(as.numeric(intensity), na.rm=T)))
    ## normalize by total intensity of raw file
    d_norm = ddply(d_evd_sub[, c("intensity", "fc.raw.file")],  "fc.raw.file", function(x) summarise(x, s.intensity=sum(as.numeric(intensity), na.rm=T)))
    d_sum$s.intensity = d_sum$s.intensity / d_norm$s.intensity[match(d_sum$fc.raw.file, d_norm$fc.raw.file)] * 100
    ## shorten protein-groups (at most two protein names)
    d_sum$proteins = sapply(d_sum$proteins, function(x) {
      p.split = unlist(strsplit(x, split=";"))
      ifelse(length(p.split)<=2, paste(p.split, sep="", collapse=";"),
                                 paste0(paste(p.split[1:2], sep="", collapse=";"),";..."))
    })
    
    ## plot
    print(ggplot(d_sum) +
      geom_bar(aes_string(x = "factor(fc.raw.file)", y = "s.intensity", fill = "factor(proteins)"), stat="identity") +
      theme(axis.text.x = element_text(angle=90)) +
      xlab("")  +
      ggtitle("EVD: Contaminant per RAW file") +
      ylab("contaminant (% intensity)") +
      geom_hline(aes_string(yintercept = "5"), linetype='dashed') +
      guides(fill = guide_legend(nrow = 2, ncol = 3, byrow = TRUE, reverse = T)) +
      theme(legend.position="top", legend.title=element_blank())
    )
      
  }
  pp = byXflex(d_evd[, c("intensity", "proteins", "fc.raw.file", "contaminant")], d_evd$fc.raw.file, 40, sort_indices=T, plotCont, top5=cont.top5.names)
  
  con_stats_smry = quantile(con_stats[,1], probs=c(0,0.5,1))
  cat(pastet("contamination(min,median,max) [%]", paste(con_stats_smry, collapse=",")), file=stats_file, append=T, sep="\n")  
  
  ## write peptides to stats file
  for (ca_entry in contaminant_alarm)
  {
    ca = ca_entry[1]
    ## this relies on ProteinGroups!!!
    idx_pg = grep(ca, d_pg$fasta.header, ignore.case = T)
    if (length(idx_pg))
    { ## found something
      idx_pep = which(d_evd$protein.group.ids %in% d_pg$id[idx_pg])
      cat(pastet("contamination-proteins:", ca, paste((d_pg$majority.protein.ids[idx_pg]), collapse=",")), file=stats_file, append=T, sep="\n") 
      cat(pastet("contamination-peptides:", ca, paste(unique(d_evd$sequence[idx_pep]), collapse=",")), file=stats_file, append=T, sep="\n") 
    }
  }
  
  
  ### peak width (all raw.files --- too much for large experiments)
  #   print(ggplot(d_evd, aes_string(x="retention.length", colour="fc.raw.file")) +
  #           geom_density() +
  #           scale_x_log10() + xlab("retention length") + ggtitle("EVD: Peak width histogram")
  #         )
  ## compute density manually
  d_evd.m = melt(d_evd[,c("retention.length","fc.raw.file")])
  d_evd.m.d = ddply(d_evd.m, "fc.raw.file", .fun = function(x) 
  {
    tmp = density(x$value, na.rm=T)
    x1 = tmp$x
    y1 = tmp$y
    data.frame(retention.length = x1, dens = y1, fc.raw.file = unique(x$fc.raw.file))
  })    
  head(d_evd.m.d)
  d_evd.m.d$block = factor(assignBlocks(d_evd.m.d$fc.raw.file, 15))
  ## identical limits for all plots
  d_evd.xlim = quantile(d_evd.m.d$retention.length, c(0,1))
  d_evd.xlim = c(max(1e-2,d_evd.xlim[1]), d_evd.xlim[2]) ## could give negative numbers and we plan to plot on log scale
  d_evd.ylim = quantile(d_evd.m.d$dens, c(0,1))
  for (bl in unique(d_evd.m.d$block))
  {
    print(ggplot(d_evd.m.d[d_evd.m.d$block==bl,], aes_string(x = "retention.length", y = "dens", colour = "fc.raw.file")) +
            geom_line(stat="identity") +
            xlab("retention length [min]") +
            theme(axis.text.x = element_text(angle=90)) +
            ylab("density") +
            ylim(d_evd.ylim) +
            scale_x_continuous(limits=d_evd.xlim, trans = "log10", breaks = c(0.01, 0.1, 0.25, 0.5, 1, 3, 10, 30)) +
            ggtitle("EVD: Peak width histogram") +
            theme(legend.title=element_blank())
    )
  }

  
  ### barplot
  ## determine duplicated sequences
  raws = as.factor(sort(as.character(unique(d_evd$fc.raw.file))))

  ## plot overview: percent of duplicate identifications (exclusion not "long" enough)
  percent_duplicates = sapply(raws, function(rf) { 
    idx = which(d_evd$fc.raw.file==rf) ## subset of certain raw.file
    d = d_evd[idx,c("raw.file","modified.sequence", "charge", "match.time.difference")]
    nrDuplicated = sum(duplicated(d) ) # | duplicated(d, fromLast=TRUE)) ## depending on how we want to count...
    return (nrDuplicated/nrow(d)*100)
  })
  d_dups = data.frame(name = as.character(raws), 
                      dups = percent_duplicates)
  twinThresh = 100 ## disabled for now... (much too slow)
  print(
    ggplot(d_dups) + geom_bar(stat="identity", aes_string(x = "name", y = "dups")) +
                     xlab("") +
                     ylab("percent") +
                     ggtitle(paste0("EVD: Percent twin sequences (same sequence, q, rawfile)\n(more details when >", twinThresh, "%)")) + 
                     theme(axis.text.x = element_text(angle=90))
  )
  if (max(percent_duplicates)>twinThresh)
  { ## warn:: very!! slow!!
    d_evd$duplicateMinRTDiff = NA;
    #install.packages("foreach")
    #install.packages("doParallel")
    #library(doParallel)
    #require(foreach)
    #registerDoParallel(cores=3)
    s = Sys.time();
    for (rf in raws) 
    {
      cat(rf)
      idx = which(d_evd$fc.raw.file==rf) ## subset of certain raw.file
      d_string = sapply(idx, function(x) 
        ## MTD is important to not consider inferred evidence by match between runs
        paste0(d_evd[x,c("raw.file","modified.sequence", "charge", "match.time.difference")],collapse=""))
      groups = Filter(function(x) length(x)>1, split(idx, d_string))
      head(groups)
      ## for each group: get minimal RT difference between all elements
      names(groups) = sapply(groups, function(g) return (g[1]))
      minRTs = unlist(lapply(groups, function(g) {
        RT_min = min(diff(sort(d_evd$retention.time[g])))
        return (RT_min)
      }))
      ## minRTs is now a list of minimal RT differences, with element names giving the index of a first group member
      head(minRTs)
      d_evd$duplicateMinRTDiff[as.numeric(names(minRTs))] = minRTs
    }
    s - Sys.time()
    
    ## plot histograms of time differences
    plotTimeDiff = function(d_sub)
    {
      print(ggplot(d_sub) +
            geom_histogram(aes_string(x = "duplicateMinRTDiff"), binwidth = 0.05) +
              xlim(-1,5) + 
              facet_wrap(~fc.raw.file) +
              xlab("retention delta between twin identifications") +
              ggtitle("EVD: Dynamic Exclusion Performance")
          )
    }
    pp = byXflex(d_evd, d_evd$fc.raw.file, raws_perPlot, plotTimeDiff, sort_indices=F)
  }  
  
}  


######
######  msms.txt ...
######

enabled_msms = getYAML(yaml_obj, "File$MsMs$enabled", TRUE)
if (enabled_msms)
{
  ### missed cleavages (again)
  ### this is the real missed cleavages estimate ... but slow
  #d_msms = readMQ(txt_files$msms, type="msms", nrows=10)
  #colnames(d_msms)
  d_msms = readMQ(txt_files$msms, type="msms", col_subset=c("Missed\\.cleavages", "^Raw.file$"))
  
  
  ## missed cleavages per Raw file
  smr_msmsMC = summary(d_msms$missed.cleavages)
  fcMCRTSubset <- function(d_sub, smr_msmsMC)
  {
    st_bin.m = melt(d_sub, id.vars = c("fc.raw.file"))
    pl = 
      ggplot(data = st_bin.m, aes_string(x = "factor(fc.raw.file)", y = "value", fill = "variable")) + 
                geom_bar(stat="identity") +
                xlab("RAW file") +  
                ylab("missed cleavages [%]") + 
                theme(legend.title=element_blank()) +
                scale_fill_manual(values = rep(c("#99d594", "#ffffbf", "#fc8d59", "#ff0000"), 10)) +
                geom_abline(alpha = 0.5, intercept = 0.75, slope = 0, colour = "black", linetype = "dashed", size = 1.5) +
                coord_flip()
      pl = addGGtitle(pl, "MSMS: Missed cleavages per RAW file", "(includes contaminants)")
    print(pl)
    return(pl)
  }
  max_mc = max(d_msms$missed.cleavages)
  st_bin = ddply(d_msms, "fc.raw.file", .fun = function(x) {
    t = table(x$missed.cleavages)/nrow(x)
    r = rep(0, max_mc + 1)
    names(r) = as.character(0:max_mc)
    r[names(t)] = t
    return (r)
  })
  pp = byXflex(st_bin, st_bin$fc.raw.file, 25, fcMCRTSubset, smr_msmsMC=smr_msmsMC)
  
  mcZero = st_bin[, "0"] * 100
  mcZero_stat = 100 - rev(quantile(mcZero, probs=c(0,0.5,1)))
  cat(pastet("missedCleavages>0 (min,median,max) [%]", paste0(mcZero_stat, collapse=",")), file=stats_file, append=T, sep="\n")
  
}

######
######  msmsScans.txt ...
######

enabled_msmsscans = getYAML(yaml_obj, "File$MsMsScans$enabled", TRUE)
if (enabled_msmsscans)
{
  #d_msmsScan = readMQ(txt_files$msmsScan, type="msms", nrows=10)
  d_msmsScan = readMQ(txt_files$msmsScan, type="msms", col_subset=c("^Identified", "Scan.event.number", "Raw.file", "Elapsed.Time", "Ion.Injection.Time"))
  #colnames(d_msmsScan)
  #head(d_msmsScan)
  #unique(d_msmsScan$Identified)
  
  ## scan event number
  scan.event.number = NULL ## make R check happy
  #require(plyr)
  DF = ddply(d_msmsScan, c("scan.event.number", "identified"), summarise, n = length(scan.event.number))
  DF$n1 = (DF$n)+1
  ratio = sapply(sort(unique(DF$scan.event.number)), function(x) {
      subs = DF[DF$scan.event.number==x,]  
      v = subs$n[subs$identified=="+"] * 100 / sum(subs$n)
      v = ifelse(length(v), v, 0) ## replace empty with 0
      return (v)
      }
    )
  df.ratio = data.frame(ratio=unlist(ratio))
  df.ratio$x = 1:nrow(df.ratio)
  df.ratio
  print(
    ggplot(df.ratio, aes_string(x = "x", y = "ratio")) +
      geom_bar(stat="identity") +
      xlab("scan event") +
      ylab("percent identified") +
      ggtitle(paste0("MSMSscans: Scan event performance"))
  )
  
#   print(
#     ggplot(DF, aes_string(x = "scan.event.number", y = "n1", fill = "identified")) + 
#       geom_bar(stat="identity") +
#       scale_y_log10() +
#       facet_grid(. ~ identified) +
#       xlab("scan event number") + ggtitle("Scan event performance") + ylab("count (log scale)")
#   )
#   #   ggplot(d_msmsScan, aes_string(x = "Elapsed.Time", "Ion.Injection.Time")) +
  #     #geom_bar(binwidth = 1) +
  #     geom_point() + stat_density2d(geom="tile", aes_string(fill = "..density.."), contour = FALSE)
  #   
  #   print(ggplot(d_msmsScan, aes_string(x = "Scan.event.number", y = "Ion.Injection.Time")) +
  #           #geom_bar(binwidth = 1) +
  #           geom_point() +
  #           xlab("scan number") + ggtitle("Peak width histogram") +
  #           #geom_density2d() +
  #           stat_density2d(geom="tile", aes_string(fill = "..density.."), contour = FALSE)
  #         )
  #   
  #   hist(d_msmsScan$Elapsed.Time)
  #   cor(d_msmsScan$Elapsed.Time, d_msmsScan$Ion.Injection.Time)
  #   
  #   d_msmsScan$Scan.event.number2 = as.numeric(as.character(d_msmsScan$Scan.event.number))
  #   d_msmsScan$Ion.Injection.Time2 = as.numeric(as.character(d_msmsScan$Ion.Injection.Time))
  #   d_msmsScan$Identified2 = (as.character(d_msmsScan$Ion.Injection.Time))
  #   
  #   ggplot(d_msmsScan, aes_string(x = "Scan.event.number2", y = "Ion.Injection.Time2", z = "Identified2")) + stat_contour()
}

### close PDF
dev.off();

### write YAML config
yaml.user.warning = 
"# This is a configuration file for PTXQC reporting.
# One such file is generated automatically every time a report PDF is created.
# You can make a copy of this file, then modify its values and use the copy as an input to another round of report generation,
# e.g., to exclude/include certain plots or change some global settings.
#
# It is recommended to work on a copy of this file, such that this original configuration reflects the content of the report.
# 
# Note that upon report generation, this file will be overwritten again (with potentially new values, if and depending on the YAML config you provided).
#
# This file has a certain structure, which should be *retained* when editing.
# Note that each parameter level has two more spaces for indentation
# A value is assigned using a colon followed by a space, i.e. ': '
#
# Possible binary values are 'no' and 'yes'.
# In addition, some parameters support other values (e.g. 'auto', which usually relies on a heuristic to decide if something should be plotted).
# By default, parameters which support 'auto' have a name which ends in 'wA' (withAuto).
# Furthermore, there is the SpecialContaminants section, where you can trigger the generation of a plot
# which just shows the fraction of proteins containing a certain string.
# By default we search for 'MYCOPLASMA' in the protein identifier, i.e. your txt should be derived from a 
# run using a database containing these identifiers (the FASTA description is not enough).
# Each of the special contaminants requires has its own section (e.g. 'cont_MYCO:') with two parameters: 
# - a string          = name within the protein identifier
# - an integer number = a threshold in % which will be plotted to visually ease interpretation
# 
#
# With the exception(!) of extra 'SpecialContaminants':
#   Do NOT add extra values (since they are ignored anyway and might even destroy the integrity of this configuration file).
#   Only modify existing values, but not their names. I.e. only change 123 but not 'test'
#   test: 123
#
#
"
cat(paste0(yaml.user.warning, as.yaml(yaml_obj)), file=yaml_file)
cat(paste("Report file created at\n\n    ", txt_folder, "\\", report_file, "\n\n",sep=""))
cat(paste0("\n\nTime elapsed: ", round(as.double(Sys.time() - time_start, units="mins"), 1), " min\n\n"))

## return path to PDF report and YAML config
return (list(report_filename = report_file, yaml_filename = yaml_file))
}
