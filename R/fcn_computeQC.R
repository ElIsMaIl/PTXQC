#' Create a quality control report (in PDF format).
#'
#' This is the main function of the package and the only thing you need to call directly if you are 
#' just interested in getting a QC report.
#' 
#' You need to provide the folder name of the 'txt' output, as generated by MaxQuant and 
#' optionally a YAML configuration object, which allows to (de)activate certain plots and holds other parameters.
#' The yaml_obj is complex and best obtained by running this function once using the default (empty list).
#' A full YAML configuration object will be written in the 'txt' folder you provide and can be loaded using
#' \code{\link[yaml]{yaml.load}}.
#' 
#' The PDF and the config file will be stored in the given txt folder.
#' 
#' @note You need write access to the txt folder!
#' 
#' For updates, bug fixes and feedback please visit \url{http://github.com/cbielow/PTXQC}.
#'
#' @param txt_folder Path to txt output folder of MaxQuant (e.g. "c:/data/Hek293/txt")
#' @param yaml_obj   A nested list object with configuration parameters for the report.
#'                   Useful to switch off certain plots or skip entire sections.
#' @return List with named filename strings, e.g. $yaml_file, $report_file etc..
#'          
#' @importFrom plyr ddply dlply ldply llply adply summarise mapvalues
#' @importFrom reshape2 melt
#' @importFrom rmarkdown render
#' 
#' @export
#'           
createReport = function(txt_folder, yaml_obj = list())
{
  
  ### script starts...
  if (class(yaml_obj) != "list")
  {
    stop(paste0("Argument 'yaml_obj' is not of type list\n"));
  }
  
  ## list of plots
  rep_data = ReportData$new()
  
  ## list of data.frames containing one QC metric per list for each Raw file
  ## used for heat map later on
  QCM = list()
  
  ## determines if a local mqpar.xml should be used to grep all YAML parameters whose name starts with "MQpar_" from the
  ## original mqpar.xml instead of the yaml.config. The "MQpar_..." param from the config
  ## will be ignored and the newly written yaml.config will contain the values from mqpar.xml.
  param_name_PTXQC_UseLocalMQPar = "PTXQC$UseLocalMQPar"
  param_def_PTXQC_UseLocalMQPar = TRUE
  param_useMQPAR = getYAML(yaml_obj, param_name_PTXQC_UseLocalMQPar, param_def_PTXQC_UseLocalMQPar)
  
  time_start = Sys.time()
  
  
  if (!any(file.info(txt_folder)$isdir, na.rm = TRUE))
  {
    stop(paste0("Argument txt_folder with value '", txt_folder, "' is not a valid directory\n"));
  }
  txt_files = list()
  txt_files$param = "parameters.txt"
  txt_files$summary = "summary.txt"
  txt_files$groups = "proteinGroups.txt"
  txt_files$evd = "evidence.txt"
  txt_files$msms = "msms.txt"
  txt_files$msmsScan = "msmsScans.txt"
  txt_files$mqpar = "mqpar.xml"
  txt_files = lapply(txt_files, function(x) paste(txt_folder, x, sep=.Platform$file.sep))
  
  ## create names of output files (report PDF, YAML, stats, etc...)
  fh_out = getReportFilenames(txt_folder)
  use_extended_report_filename = getYAML(yaml_obj, "PTXQC$ReportFilename$extended", TRUE)
  fh_out$report_file = ifelse(use_extended_report_filename, fh_out$report_file_extended, fh_out$report_file_simple)
  
  unlink(fh_out$stats_file)
  cat("Statistics summary:", file=fh_out$stats_file, append = FALSE, sep="\n")
  
  ## prepare for readMQ()
  mq = MQDataReader$new()
  
  ## read manual filename shortening & sorting (if available)
  mq$readMappingFile(fh_out$filename_sorting)
  
  ######
  ######  parameters.txt ...
  ######
  
  enabled_parameters = getYAML(yaml_obj, "File$Parameters$enabled", TRUE)
  if (enabled_parameters)
  {
    d_parAll = mq$readMQ(txt_files$param, type="par")
    qcMetric_PAR$setData(d_parAll)
    rep_data$add(qcMetric_PAR$plots, "params")
  }
  
  add_fs_col = getYAML(yaml_obj, "PTXQC$NameLengthMax_num", 10)
  
  ######
  ######  summary.txt ...
  ######
  
  enabled_summary = getYAML(yaml_obj, "File$Summary$enabled", TRUE)
  if (enabled_summary)
  {
    d_smy = mq$readMQ(txt_files$summary, type="sm", add_fs_col = add_fs_col)
    #colnames(d_smy)
    #colnames(d_smy[[1]])
    
    id_rate_bad = getYAML(yaml_obj, "File$Summary$IDRate$Thresh_bad_num", 20)
    id_rate_great = getYAML(yaml_obj, "File$Summary$IDRate$Thresh_great_num", 35)
    
    ### MS/MS identified [%]
    qcMetric_SM_MSMSIdRate$setData(d_smy$raw, id_rate_bad, id_rate_great)
    rep_data$add(qcMetric_SM_MSMSIdRate$plots)

    QCM[["SM.MS2_ID_rate"]] = qcMetric_SM_MSMSIdRate$qcScores
  }  
  
  
  ######
  ######  proteinGroups.txt ...
  ######
  
  GL_name_min_length = 8
  
  enabled_proteingroups = getYAML(yaml_obj, "File$ProteinGroups$enabled", TRUE)
  enabled_pg_ratioLabIncThresh = getYAML(yaml_obj, "File$ProteinGroups$RatioPlot$LabelIncThresh_num", 4)
  if (enabled_proteingroups)
  {
    
    d_pg = mq$readMQ(txt_files$groups, type="pg", col_subset=NA, filter="R")
      
    param_name_PG_intThresh = "File$ProteinGroups$IntensityThreshLog2_num"
    param_def_PG_intThresh = 25 ## default median intensity in log2 scale
    param_PG_intThresh = getYAML(yaml_obj, param_name_PG_intThresh, param_def_PG_intThresh)
    if (!is.numeric(param_PG_intThresh) || !(param_PG_intThresh %in% 1:100))
    { ## reset if value is weird
      cat("YAML value for '" %+% param_name_PG_intThresh %+% "' is invalid ('" %+% param_PG_intThresh %+% "'). Using default of " %+% param_def_PG_intThresh %+% ".")
      param_PG_intThresh = param_def_PG_intThresh
    }
    
    ##
    ## Raw/LFQ/Reporter intensity boxplots
    ##
    clusterCols = list()
    
    colsSIL = grepv("^intensity\\.[hlm](\\.|$)", colnames(d_pg))
    colsLF = grepv("^intensity\\..", colnames(d_pg))
    colsOneCond = "intensity" ## just one group -- we still want to know what the overall intensity is
    if (length(colsSIL)) {
      ## ignore intensity.l and alike if real groups are present
      plain_channel = grepv("^intensity\\.[hlm]$", colnames(d_pg))
      if (all(plain_channel == colsSIL)) colsW = colsSIL else colsW = setdiff(colsSIL, plain_channel)
    } else if (length(colsLF)) {
      colsW = colsLF
    }  else {
      colsW = colsOneCond
    }
    
    ## a global PG name mapping
    MAP_pg_groups = data.frame(long = colsW)
    MAP_pg_groups$short = shortenStrings(simplifyNames(delLCP(MAP_pg_groups$long, 
                                                              min_out_length = GL_name_min_length, 
                                                              add_dots = TRUE), 
                                                       min_out_length = GL_name_min_length))
    ##
    ## Contaminants plots on Raw intensity
    ##
    qcMetric_PG_Cont$setData(d_pg, colsW, MAP_pg_groups)
    rep_data$add(qcMetric_PG_Cont$plots)
    

    ###
    ### Raw intensity boxplot
    ###
    
    clusterCols$raw.intensity = colsW ## cluster using intensity
    
    qcMetric_PG_RawInt$setData(d_pg, colsW, MAP_pg_groups, param_PG_intThresh)
    rep_data$add(qcMetric_PG_RawInt$plots)
    
    ##
    ## LFQ boxplots
    ##
    colsSIL = grepv("^lfq.intensity\\.[hlm](\\.|$)", colnames(d_pg))
    colsLF = grepv("^lfq.intensity\\..", colnames(d_pg))
    
    ## a global PG name mapping
    MAP_pg_groups_LFQ = NA
    if (length(c(colsSIL, colsLF)) > 0)
    {
      if (length(colsSIL)) {
        ## unlike intensity.l, there is no lfq.intensity.l which we could remove
        colsW = colsSIL
      } else colsW = colsLF
      MAP_pg_groups_LFQ = data.frame(long = colsW)
      MAP_pg_groups_LFQ$short = shortenStrings(simplifyNames(delLCP(MAP_pg_groups_LFQ$long, 
                                                                    min_out_length = GL_name_min_length, 
                                                                    add_dots = TRUE), 
                                                             min_out_length = GL_name_min_length))

      clusterCols$lfq.intensity = colsW ## cluster using LFQ
      
      qcMetric_PG_LFQInt$setData(d_pg, colsW, MAP_pg_groups_LFQ, param_PG_intThresh)
      rep_data$add(qcMetric_PG_LFQInt$plots)
    }
    
    ##
    ## iTRAQ/TMT, reporter ion intensity boxplot
    ##
    ## either "reporter.intensity.0.groupname" or "reporter.intensity.0" (no groups)    
    colsITRAQ = grepv("^reporter.intensity.[0-9].|^reporter.intensity.[0-9]$", colnames(d_pg))
    ## a global PG name mapping
    MAP_pg_groups_ITRAQ = NA
    if (length(colsITRAQ) > 0)
    {
      MAP_pg_groups_ITRAQ = data.frame(long = c(colsITRAQ))
      MAP_pg_groups_ITRAQ$short = shortenStrings(simplifyNames(delLCP(MAP_pg_groups_ITRAQ$long, 
                                                                      min_out_length = GL_name_min_length, 
                                                                      add_dots = TRUE), 
                                                               min_out_length = GL_name_min_length))

      clusterCols$reporter.intensity = colsITRAQ ## cluster using reporters
      
      qcMetric_PG_ITRAQInt$setData(d_pg, colsITRAQ, MAP_pg_groups_ITRAQ, param_PG_intThresh)
      rep_data$add(qcMetric_PG_ITRAQInt$plots)
    }
    
    
    ##
    ## PCA
    ##
    ## some clustering (its based on intensity / lfq.intensity columns..)
    ## todo: maybe add ratios -- requires loading from txt though..
    MAP_pg_groups_ALL = rbind(MAP_pg_groups, MAP_pg_groups_LFQ, MAP_pg_groups_ITRAQ)
    
    qcMetric_PG_PCA$setData(d_pg, clusterCols, MAP_pg_groups_ALL)
    rep_data$add(qcMetric_PG_PCA$plots)
    
    
    ##################################
    ## ratio plots
    ##################################
    ## get ratio column
    ratio_cols = grepv("^ratio\\.[hm]\\.l", colnames(d_pg))  ## e.g. "ratio.m.l.ARK5exp" or "ratio.m.l.variability.ARK5exp"
    ## remove everything else
    ## e.g. we do not want ratio.h.l.variability.ARK5exp, i.e. the 'variability' property
    ratio_cols = grepv("^ratio.[hm].l.normalized", ratio_cols, invert = TRUE)
    ratio_cols = grepv("^ratio.[hm].l.count", ratio_cols, invert = TRUE)
    ratio_cols = grepv("^ratio.[hm].l.variability", ratio_cols, invert = TRUE)
    ratio_cols = grepv("^ratio.[hm].l.significance.a", ratio_cols, invert = TRUE) ## from MQ 1.0.1x
    ratio_cols = grepv("^ratio.[hm].l.significance.b", ratio_cols, invert = TRUE)
    ratio_cols = grepv("^ratio.[hm].l.iso.count", ratio_cols, invert = TRUE) ## from MQ 1.5.1.2
    ratio_cols = grepv("^ratio.[hm].l.type", ratio_cols, invert = TRUE)
    ratio_cols
    
    if (length(ratio_cols) > 0)
    {
      qcMetric_PG_Ratio$setData(d_pg, ratio_cols, enabled_pg_ratioLabIncThresh)
      rep_data$add(qcMetric_PG_Ratio$plots)
    }
  }
  
  ######
  ######  evidence.txt ...
  ######
  
  enabled_evidence = getYAML(yaml_obj, "File$Evidence$enabled", TRUE)
  
  ## get scoring threshold (upper limit)
  param_name_EV_protThresh = "File$Evidence$ProteinCountThresh_num"
  param_def_EV_protThresh = 3500
  param_EV_protThresh = getYAML(yaml_obj, param_name_EV_protThresh, param_def_EV_protThresh)
  if (!is.numeric(param_EV_protThresh) || !(param_EV_protThresh %in% 1:1e5))
  { ## reset if value is weird
    cat("YAML value for '" %+% param_name_EV_protThresh %+% "' is invalid ('" %+% param_EV_protThresh %+% "'). Using default of " %+% param_def_EV_protThresh %+% ".")
    param_EV_protThresh = param_def_EV_protThresh
  }
  
  param_name_EV_intThresh = "File$Evidence$IntensityThreshLog2_num"
  param_def_EV_intThresh = 23 ## default median intensity in log2 scale
  param_EV_intThresh = getYAML(yaml_obj, param_name_EV_intThresh, param_def_EV_intThresh)
  if (!is.numeric(param_EV_intThresh) || !(param_EV_intThresh %in% 1:100))
  { ## reset if value is weird
    cat("YAML value for '" %+% param_name_EV_intThresh %+% "' is invalid ('" %+% param_EV_intThresh %+% "'). Using default of " %+% param_def_EV_intThresh %+% ".")
    param_EV_intThresh = param_def_EV_intThresh
  }
  
  ## get scoring threshold (upper limit)
  param_name_EV_pepThresh = "File$Evidence$PeptideCountThresh_num"
  param_def_EV_pepThresh = 15000
  param_EV_pepThresh = getYAML(yaml_obj, param_name_EV_pepThresh, param_def_EV_pepThresh)
  if (!is.numeric(param_EV_pepThresh) || !(param_EV_pepThresh %in% 1:1e6))
  { ## reset if value is weird
    cat("YAML value for '" %+% param_name_EV_pepThresh %+% "' is invalid ('" %+% param_EV_pepThresh %+% "'). Using default of " %+% param_def_EV_pepThresh %+% ".")
    param_EV_pepThresh = param_def_EV_pepThresh
  }
  
  if (enabled_evidence)
  {
    ## protein.names is only available from MQ 1.4 onwards
    d_evd = mq$readMQ(txt_files$evd, type="ev", filter="R", col_subset=c("proteins",
                                                                         numeric = "Retention.Length",
                                                                         numeric = "retention.time.calibration", 
                                                                         numeric = "Retention.time$", 
                                                                         numeric = "Match.Time.Difference",
                                                                         numeric = "^intensity$", "^Type$",
                                                                         numeric = "Mass\\.Error", 
                                                                         numeric = "^uncalibrated...calibrated." ,
                                                                         numeric = "^m.z$",
                                                                         numeric = "^score$", 
                                                                         numeric = "^fraction$",  ## only available when fractions were given
                                                                         "Raw.file", "^Protein.Group.IDs$", "Contaminant",
                                                                         numeric = "[RK]\\.Count", 
                                                                         numeric = "^Charge$", "modified.sequence",
                                                                         numeric = "^Mass$", "^protein.names$",
                                                                         numeric = "^ms.ms.count$"))

    ### warn of special contaminants!
    ## these need to be in FASTA headers (description is not enough)!
    ## syntax:  list( contaminant1 = c(name, threshold), contaminant2 = c(...), ...)
    ##
    ##  if within the YAML file
    ##    SpecialContaminants: no
    ##  is set, then 'yaml_contaminants' will be 'FALSE'
    ##
    contaminant_default = list("cont_MYCO" = c(name="MYCOPLASMA", threshold=1)) # name (FASTA), threshold for % of unique peptides
    ##yaml_obj = list()
    ##contaminant_default = FALSE ## to switch it off by default
    yaml_contaminants = getYAML(yaml_obj, "File$Evidence$SpecialContaminants", contaminant_default)
    
    if (class(yaml_contaminants) == "list")  ## SC are requested
    {
      if (!enabled_proteingroups)
      {
        ## fail hard; we could hack around this (e.g. by loading fasta headers from evidence.txt), but it wastes a lot of memory and time
        stop(paste0("Error: reporting of special contaminants requires loading of proteinGroups.txt.",
                    "If you don't have this file, please disable contaminant lookup in the YAML file and re-run."))
      } else {
        qcMetric_EVD_UserContaminant$setData(d_evd, d_pg, yaml_contaminants)
        rep_data$add(qcMetric_EVD_UserContaminant$plots)
        ## add heatmap column
        QCM[["EVD.UserContaminant"]] = qcMetric_EVD_UserContaminant$qcScores
      }
    }
    
    ##
    ## intensity of peptides
    ##

    qcMetric_EVD_PeptideInt$setData(d_evd, param_EV_intThresh)
    rep_data$add(qcMetric_EVD_PeptideInt$plots)
    ## add heatmap column
    QCM[["EVD.PepIntensity"]] = qcMetric_EVD_PeptideInt$qcScores
    

    ##
    ## peptide & protein counts
    ##
    
    ## contains NA if 'genuine' ID
    d_evd$hasMTD = !is.na(d_evd$match.time.difference)
    ## report Match-between-runs data only if if it was enabled
    reportMTD = any(d_evd$hasMTD)

    qcMetric_EVD_ProteinCount$setData(d_evd, param_EV_protThresh)
    rep_data$add(qcMetric_EVD_ProteinCount$plots)
    ## add heatmap column
    QCM[["EVD.protCount"]] = qcMetric_EVD_ProteinCount$qcScores
    
    qcMetric_EVD_PeptideCount$setData(d_evd, param_EV_pepThresh)
    rep_data$add(qcMetric_EVD_PeptideCount$plots)
    ## add heatmap column
    QCM[["EVD.pepCount"]] = qcMetric_EVD_PeptideCount$qcScores

    ####
    #### peak length (not supported in MQ 1.0.13)
    ####
    cat("EVD: RT peak width distribution ...\n")
    
    if ("retention.length" %in% colnames(d_evd))  
    {
      qcMetric_EVD_RTPeakWidth$setData(d_evd)
      rep_data$add(qcMetric_EVD_RTPeakWidth$plots)
      ## add heatmap column
      QCM[["EVD.PeakShape"]] = qcMetric_EVD_RTPeakWidth$qcScores
    } ## end retention length (aka peak width)
    
    ##
    ## retention time calibration (to see if window was sufficiently large)
    ## (not supported in MQ 1.0.13)  
    ## Even if MBR=off, this column always contains numbers (usually 0, or very small)
    ##
    
    ## param
    param_name_EV_MatchingTolerance = "File$Evidence$MQpar_MatchingTimeWindow_num"
    param_def_EV_MatchingTolerance = 1
    param_EV_MatchingTolerance = getYAML(yaml_obj, param_name_EV_MatchingTolerance, param_def_EV_MatchingTolerance)
    if (param_useMQPAR) {
      v = getMQPARValue(txt_files$mqpar, "matchingTimeWindow") ## will also warn() if file is missing
      if (!is.null(v)) {
        param_EV_MatchingTolerance = setYAML(yaml_obj, param_name_EV_MatchingTolerance, as.numeric(v))
      }
    }
    param_name_mbr = "File$Evidence$MatchBetweenRuns_wA"
    param_evd_mbr = getYAML(yaml_obj, param_name_mbr, "auto")
    
    if ("retention.time.calibration" %in% colnames(d_evd))
    {
      ## this should enable us to decide if MBR was used (we could also look up parameters.txt -- if present)
      MBR_HAS_DATA = (sum(d_evd$type == "MULTI-MATCH") > 0)

      if ((param_evd_mbr == FALSE) || (MBR_HAS_DATA == FALSE))
      {
        ## MBR is not evaluated
      } else
      {
        qcMetric_EVD_MBRAlign$setData(d_evd, param_EV_MatchingTolerance, mq$raw_file_mapping)
        rep_data$add(qcMetric_EVD_MBRAlign$plots)
        ## add heatmap column
        QCM[["EVD.MBRAlign"]] = qcMetric_EVD_MBRAlign$qcScores

### 
###     MBR: ID transfer
###
        #debug (restore data): qcMetric_EVD_RTPeakWidth$setData(d_evd)
        avg_peak_width = qcMetric_EVD_RTPeakWidth$outData[["avg_peak_width"]]
        if (is.null(avg_peak_width)) {
          stop("RT peak width module did not run, but is required for MBR metrics. Enable it and try again or switch off MBR metrics!")
        } 
        qcMetric_EVD_MBRIdTransfer$setData(d_evd, avg_peak_width)
        rep_data$add(qcMetric_EVD_MBRIdTransfer$plots)
        ## add heatmap column
        QCM[["EVD.MBRIdTransfer"]] = qcMetric_EVD_MBRIdTransfer$qcScores
        
        
        ##
        ## MBR: Tree Clustering (experimental)
        ##  and
        ## MBR: additional evidence by matching MS1 by AMT across files
        ##
        qcMetric_EVD_MBRaux$setData(d_evd)
        rep_data$add(qcMetric_EVD_MBRaux$plots)

      } ## MBR has data
    } ## retention.time.difference column exists
    
    
    ##
    ## charge distribution
    ##
    ##  (this uses genuine peptides only -- no MBR!)
    ## 
    d_charge = mosaicize(d_evd[!d_evd$hasMTD, c("fc.raw.file", "charge")])
    rep_data$add(
      byXflex(d_charge, d_charge$Var1, 30, plot_Charge, sort_indices = FALSE)
    )
    
    ## QC measure for charge centeredness
    qc_charge = ddply(d_evd[!d_evd$hasMTD, c("charge",  "raw.file")], "raw.file", function(x) data.frame(c = (sum(x$charge==2)/nrow(x))))
    cname = "X010X_catPrep_EVD:~Charge"
    qc_charge[, cname] = qualMedianDist(qc_charge$c)
    QCM[["EVD.charge2"]] = qc_charge[, c("raw.file", cname)]
    
    ##
    ## peptides per RT
    ##
    cat("EVD: Peptides over RT ...\n")
    raws_perPlot = 6
    
    rt_range = range(d_evd$retention.time, na.rm = TRUE)
    df_idRT = ddply(d_evd, "fc.raw.file", function(x) {
      h = hist(x$retention.time, breaks=seq(from=rt_range[1]-3, to=rt_range[2]+3, by=3), plot = FALSE)
      return(data.frame(RT = h$mid, counts = h$counts))
    })
    rep_data$add(
      byXflex(df_idRT, df_idRT$fc.raw.file, raws_perPlot, plot_IDsOverRT, sort_indices = FALSE)
    )
    
    ## QC measure for uniform-ness
    QCM[["ID_rate_over_RT"]] = ddply(d_evd[, c("retention.time",  "raw.file")], "raw.file", 
                                     function(x) data.frame("X015X_catLC_EVD:~ID~rate~over~RT" = qualUniform(x$retention.time), 
                                                            check.names = FALSE))
    
          
    ##
    ## barplots of mass error
    ##
    cat("EVD: Precursor Mass Error ...\n")
    
    ## MQ seems to mess up mass recal on some (iTRAQ/TMT) samples, by reporting ppm errors which include modifications
    ## , thus one sees >1e5 ppm, e.g. 144.10 Da
    ##  this affects both 'uncalibrated.mass.error..ppm.'   and
    ##                    'mass.error..ppm.'
    ## HOWEVER, 'uncalibrated...calibrated.m.z..ppm.' seems unaffected, but is not available in all MQ versions :(
    ##    also, 'mass' and 'm/z' columns seem unaffected.
    ## We cannot always reconstruct mass_error[ppm] from 'm/z' and mass columns 
    ## since 'm/z' is just too close to the theoretical value or islacking precision of the stored numbers.
    ##
    ## The MQ list reports one case with high ppm error (8000), where the KR.count was at fault. We cannot
    ## reconstruct this.
    ##
    ## Also, MaxQuant will not report uncalibrated mass errors if the data are too sparse for a given Raw file.
    ## Then, 'uncalibrated.mass.error..ppm.' will be 'NaN' throughout -- but weirdly, calibrated masses will be reported.
    ##
    
    param_name_EV_PrecursorTolPPM = "File$Evidence$MQpar_firstSearchTol_num"
    param_def_EV_PrecursorTolPPM = 20
    param_EV_PrecursorTolPPM = getYAML(yaml_obj, param_name_EV_PrecursorTolPPM, param_def_EV_PrecursorTolPPM)
    if (param_useMQPAR) {
      v = getMQPARValue(txt_files$mqpar, "firstSearchTol") ## will also warn() if file is missing
      if (!is.null(v)) {
        param_EV_PrecursorTolPPM = setYAML(yaml_obj, param_name_EV_PrecursorTolPPM, as.numeric(v))
      }
    }
    
    param_name_EV_PrecursorOutOfCalSD = "File$Evidence$firstSearch_outOfCalWarnSD_num"
    param_def_EV_PrecursorOutOfCalSD = 2
    param_EV_PrecursorOutOfCalSD = getYAML(yaml_obj, param_name_EV_PrecursorOutOfCalSD, param_def_EV_PrecursorOutOfCalSD)
    
    ##
    ## check for MS1-out-of-calibration (i.e. the tol-window being too small)
    ##
    ## heuristic to determine if the instrument is completely out of calibration, 
    ## i.e. all ID's are false positives, since the Precursor mass is wrong
    ## -- we use the SD; if larger than 2ppm, 
    ## then ID's are supposedly random
    ## -- alt: we use the 1%-to-99% quantile range: if > 10ppm
    ## -- uninformative for detection is the distribution (it's still Gaussian for a strange reason)
    MS1_decal_smr = ddply(d_evd, "fc.raw.file", function(x) 
      data.frame(n = nrow(x), 
                 sd = round(sd(x$mass.error..ppm., na.rm = TRUE), 1), 
                 range = diff(quantile(x$mass.error..ppm., c(0.01, 0.99), na.rm = TRUE))))
    ## additionally use MS2-ID rate (should be below 1%)
    if (enabled_summary) {
      MS1_decal_smr = merge(MS1_decal_smr, d_smy$raw[, c("fc.raw.file", "ms.ms.identified....")])
    } else {
      MS1_decal_smr$ms.ms.identified.... = 0 ## upon no info: assume low IDrate
    }
    
    MS1_decal_smr$lowIDRate = MS1_decal_smr$ms.ms.identified.... < 1
    MS1_decal_smr$hasMassErrorBug = FALSE
    MS1_decal_smr$hasMassErrorBug_unfixable = FALSE
    recal_message = ""
    recal_message_post = ""
    ## check each raw file individually (usually its just a few who are affected)
    de_cal = ddply(d_evd, "fc.raw.file", .fun = function(x) data.frame(q = (quantile(abs(x$uncalibrated.mass.error..ppm.), probs = 0.5, na.rm = TRUE) > 1e3)))
    if (any(de_cal$q, na.rm = TRUE))
    {
      recal_message = "MQ bug: data rescued"
      recal_message_post = 'MQ bug: data cannot be rescued'
      
      MS1_decal_smr$hasMassErrorBug[ MS1_decal_smr$fc.raw.file %in% de_cal$fc.raw.file[de_cal$q > 0] ] = TRUE
      
      ## re-compute 'uncalibrated.mass.error..ppm.' and 'mass.error..ppm.'
      d_evd$theomz = d_evd$mass / d_evd$charge + 1.00726
      d_evd$mass.error..ppm.2 = (d_evd$theomz - d_evd$m.z) / d_evd$theomz * 1e6
      d_evd$uncalibrated.mass.error..ppm.2 = d_evd$mass.error..ppm.2 + d_evd$uncalibrated...calibrated.m.z..ppm.
    
      
      ## check if fix worked
      de_cal2 = ddply(d_evd, "raw.file", .fun = function(x)  data.frame(q = (median(abs(x$uncalibrated.mass.error..ppm.2), na.rm = TRUE) > 1e3)))
      if (any(de_cal2$q, na.rm = TRUE))
      { ## fix did not work
        MS1_decal_smr$hasMassErrorBug_unfixable[ MS1_decal_smr$fc.raw.file %in% de_cal2$fc.raw.file[de_cal2$q] ] = TRUE
        recal_message = "m/z recalibration bugfix applied but failed\n(there are still large numbers)"
      }
      
      idx_overwrite = (d_evd$fc.raw.file %in% de_cal$fc.raw.file[de_cal$q > 0])
      ## overwrite original values
      d_evd$mass.error..ppm.[idx_overwrite] = d_evd$mass.error..ppm.2[idx_overwrite]
      d_evd$uncalibrated.mass.error..ppm.[idx_overwrite] = d_evd$uncalibrated.mass.error..ppm.2[idx_overwrite]
    }
    
    MS1_decal_smr$outOfCal = (MS1_decal_smr$sd > param_EV_PrecursorOutOfCalSD) & MS1_decal_smr$lowIDRate & 
                             (MS1_decal_smr$sd < 100)  ## upper bound, to distinguish from MQ bug (which has much larger SD's)
    
    ## report too small search tolerance
    if (any(MS1_decal_smr$outOfCal)) recal_message = "search tolerance too small"
    
    
    ## Raw files where the mass error is obviously wrong (PSM's not substracted etc...)
    affected_raw_files = MS1_decal_smr$fc.raw.file[MS1_decal_smr$outOfCal | MS1_decal_smr$hasMassErrorBug]
    ## some outliers can have ~5000ppm, blowing up the plot margins
    ## --> remove outliers 
    ylim_g = range(boxplot.stats(d_evd$uncalibrated.mass.error..ppm.)$stats[c(1, 5)], c(-param_EV_PrecursorTolPPM, param_EV_PrecursorTolPPM) * 1.05)
    ## PLOT
    rep_data$add(
      byXflex(d_evd, d_evd$fc.raw.file, 20, plot_UncalibratedMSErr, sort_indices = FALSE, 
              MQBug_raw_files = affected_raw_files, 
              y_lim = ylim_g,
              stats = MS1_decal_smr,
              extra_limit = param_EV_PrecursorTolPPM,
              title_sub = recal_message)
    )
    
    ## scores
    qc_MS1deCal = ddply(d_evd[, c("uncalibrated.mass.error..ppm.", "fc.raw.file")], "fc.raw.file", 
                        function(x) {
                          xd = na.omit(x$uncalibrated.mass.error..ppm.)
                          if (length(xd)==0) {
                            r = HEATMAP_NA_VALUE ## if empty, give the Raw file an 'NA' score
                          } else if (MS1_decal_smr$outOfCal[MS1_decal_smr$fc.raw.file == x$fc.raw.file[1]]) {
                            r = 0 ## if we suspect out-of-calibration, give lowest score
                          } else r = qualCenteredRef(xd, param_EV_PrecursorTolPPM)
                          return (data.frame(med_rat = r))
                        })
    
    colnames(qc_MS1deCal) = c("fc.raw.file", "X026X_catMS_EVD:~MS~Cal-Pre~(" %+% param_EV_PrecursorTolPPM %+% ")")
    QCM[["X026X.EVD.MS_Cal-Pre"]] = qc_MS1deCal
    
    
    ##
    ## post calibration
    ##
    cat("EVD: Precursor Mass Error (post calibration) ...\n")
    
    param_name_EV_PrecursorTolPPMmainSearch = "File$Evidence$MQpar_mainSearchTol_num"
    param_def_EV_PrecursorTolPPMmainSearch = NA  ## we do not dare to have a default, since it ranges from 6 - 4.5 ppm across MQ versions
    param_EV_PrecursorTolPPMmainSearch = getYAML(yaml_obj, param_name_EV_PrecursorTolPPMmainSearch, param_def_EV_PrecursorTolPPMmainSearch)
    if (param_useMQPAR) {
      v = getMQPARValue(txt_files$mqpar, "mainSearchTol") ## will also warn() if file is missing
      if (!is.null(v)) {
        param_EV_PrecursorTolPPMmainSearch = setYAML(yaml_obj, param_name_EV_PrecursorTolPPMmainSearch, as.numeric(v))
      }
    }
    if (is.na(param_EV_PrecursorTolPPMmainSearch))
    {
      warning("PTXQC: Cannot draw borders for calibrated mass error, since neither 'File$Evidence$MQpar_mainSearchTol_num' is set nor a mqpar.xml file is present!", immediate. = TRUE)
    }
    
    ylim_g = range(na.rm = TRUE, boxplot.stats(d_evd$mass.error..ppm.)$stats[c(1, 5)], c(-param_EV_PrecursorTolPPMmainSearch, param_EV_PrecursorTolPPMmainSearch) * 1.05)
    ## PLOT
    rep_data$add(
      byXflex(d_evd, d_evd$fc.raw.file, 20, plot_CalibratedMSErr, sort_indices = FALSE,
              MQBug_raw_files = affected_raw_files,
              y_lim = ylim_g,
              stats = MS1_decal_smr,
              extra_limit = param_EV_PrecursorTolPPMmainSearch,
              title_sub = recal_message_post
              )
    )
    
    ## QC measure for post-calibration ppm error
    ## .. assume 0 centered and StdDev of observed data
    obs_par = ddply(d_evd[, c("mass.error..ppm.", "fc.raw.file")], "fc.raw.file", 
                    function(x) data.frame(mu = mean(x$mass.error..ppm., na.rm = TRUE), sd = sd(x$mass.error..ppm., na.rm = TRUE)))
    qc_MS1Cal = data.frame(fc.raw.file = obs_par$fc.raw.file, 
                           val = sapply(1:nrow(obs_par), function(x) qualGaussDev(obs_par$mu[x], obs_par$sd[x])))
    ## if we suspect out-of-calibration, give lowest score
    qc_MS1Cal$val[qc_MS1Cal$fc.raw.file %in% MS1_decal_smr$fc.raw.file[ MS1_decal_smr$outOfCal ]] = 0 
    ## MQ mass bugfix will not work for postCalibration, since values are always too low
    qc_MS1Cal$val[qc_MS1Cal$fc.raw.file %in% MS1_decal_smr$fc.raw.file[ MS1_decal_smr$hasMassErrorBug ]] = HEATMAP_NA_VALUE
    cname = "X027X_catMS_EVD:~MS~Cal-Post"
    colnames(qc_MS1Cal)[colnames(qc_MS1Cal) == "val"] = cname
    QCM[["X027X.EVD.MS_Cal-Post"]] = qc_MS1Cal
    
    
    
    
    ## compute how well calibration worked
    cal_medians = as.vector(by(d_evd$mass.error..ppm., d_evd$raw.file, median, na.rm = TRUE))
    cal_stats = quantile(cal_medians, probs=c(0,0.5,1))
    cat(pastet("medianCalibratedMassError(min,median,max) [ppm]", paste(cal_stats, collapse=",")), file=fh_out$stats_file, append = TRUE, sep="\n") 
    
    ##
    ## elaborate contaminant fraction per Raw.file (this is not possible from PG, since raw files could be merged)
    ## find top 5 contaminants (globally)
    ##
    cat("EVD: Contaminants per Raw file ...\n")
    
    
    ## if possible, work on protein names (since MQ1.4), else use proteinIDs
    if ("protein.names" %in% colnames(d_evd))
    {
      evd_pname = "protein.names"        
    } else {
      evd_pname = "proteins" 
    }
    ## protein.names are sometimes not unique, e.g. if a contaminant is involved:
    ## "P02768;CON__P02768-1" and "P02768" will both give the same name (since contaminant name is empty)
    ## Thus, the distribution of bars will look slightly different (but summed percentages are identical)
    
    ## some protein.names are empty (usually the CON__ ones) ... so we substitute with ID
    d_evd$pname = d_evd[, evd_pname];
    d_evd$pname[d_evd$pname==""] = d_evd$proteins[d_evd$pname==""] ## a NOP if it already is 'proteins', but ok
    
    d_evd.totalInt = sum(as.numeric(d_evd$intensity), na.rm = TRUE)
    d_evd.cont.only = d_evd[d_evd$contaminant,]
    cont.top = by(d_evd.cont.only, d_evd.cont.only$pname, function(x) sum(as.numeric(x$intensity), na.rm = TRUE) / d_evd.totalInt*100)
    cont.top.sort = sort(cont.top, decreasing = TRUE)
    #head(cont.top.sort)
    cont.top5.names = names(cont.top.sort)[1:5]
    
    
    if (is.null(cont.top5.names))
    {
      pl_cont = ggText("EVD: Contaminant per Raw file",
                       paste0("No contaminants found in any sample.\n\nIncorporating contaminants during search is highly recommended!"),
                       "red")
      rep_data$add(pl_cont)  
    } else {
      rep_data$add(
        byXflex(d_evd[, c("intensity", "pname", "fc.raw.file", "contaminant")], d_evd$fc.raw.file, 40, sort_indices = FALSE, 
                plot_ContEVD, top5=cont.top5.names)
      )
    }
    
    ## QC measure for contamination
    qc_contaminants = ddply(d_evd[, c("intensity", "contaminant", "fc.raw.file")], "fc.raw.file", 
                            function(x) {
                              v = ifelse(is.null(cont.top5.names), 
                                         HEATMAP_NA_VALUE, ## use NA in heatmap if there are no contaminants
                                         1-qualLinThresh(sum(as.numeric(x$intensity[x$contaminant]), na.rm = TRUE)/
                                                           sum(as.numeric(x$intensity), na.rm = TRUE)))
                              data.frame("X001X_catPrep_EVD:~Contaminants" = v, check.names = FALSE)})
    QCM[["EVD.Contaminants"]] = qc_contaminants

    ##
    ## Oversampling: determine peaks repeatedly sequenced
    ##
    cat("EVD: MS2 oversampling ...\n")
    
    d_dups = ddply(d_evd, "fc.raw.file", function(x) {
      tt = as.data.frame(table(x$ms.ms.count), stringsAsFactors = FALSE)
      tt$Count = as.numeric(tt$Var1)
      ## remove "0", since this would be MBR-features
      tt = tt[tt$Count!=0,]
      ## summarize everything above 3 counts
      if (any(tt$Count >= 3)) {
        tt$Count[tt$Count >= 3] = "3+"
        tt = ddply(tt, "Count", function(x) data.frame(Freq=sum(x$Freq)))
      }
      ## make counts relative
      fraction = tt$Freq / sum(tt$Freq) * 100
      return (data.frame(n=as.character(tt$Count), fraction = fraction))
    })
    
    rep_data$add(
      byXflex(d_dups, d_dups$fc.raw.file, 30, plot_MS2Oversampling, sort_indices = FALSE)
    )
    ## QC measure for centered-ness of MS2-calibration
    qc_evd_twin = d_dups[d_dups$n==1,]
    cname = "X025X_catMS_EVD:~MS^2~Oversampling"
    qc_evd_twin[, cname] = qualLinThresh(qc_evd_twin$fraction/100)
    QCM[["EVD.Oversampling"]] = qc_evd_twin[, c("fc.raw.file", cname)]
    
    ## trim down to the absolute required (we need to identify contaminants in MSMS.txt later on)
    if (!exists("DEBUG_PTXQC")) d_evd = d_evd[, c("id", "contaminant")]
    
}


######
######  msms.txt ...
######

enabled_msms = getYAML(yaml_obj, "File$MsMs$enabled", TRUE)
if (enabled_msms)
{
  ### missed cleavages (again)
  ### this is the real missed cleavages estimate ... but slow
  #d_msms_s = mq$readMQ(txt_files$msms, type="msms", filter = "", nrows=10)
  #colnames(d_msms_s)
  #head(d_msms)
  d_msms = mq$readMQ(txt_files$msms, type="msms", filter = "", col_subset=c(numeric = "Missed\\.cleavages",
                                                                            "^Raw.file$",
                                                                            "^mass.deviations",
                                                                            "^masses$", "^mass.analyzer$", "fragmentation", "reverse",
                                                                            numeric = "^evidence.id$"), check_invalid_lines = FALSE)
  
  d_msms = d_msms[order(match(as.character(d_msms$fc.raw.file), mq$raw_file_mapping$to)),]
  ## sort fc.raw.file's factor values as well
  d_msms$fc.raw.file = factor(d_msms$fc.raw.file, levels = mq$raw_file_mapping$to, ordered = TRUE)
  
  ##
  ##  MS2 fragment decalibration
  ##
  cat("MSMS: MS2 fragment decalibration ...\n")
  ## older MQ versions do not have 'mass.analyzer' or 'mass.deviations..ppm.'
  ## , so we use fragmentation instead (this is a little risky, since you could to CID fragmentation and forward to Orbi, but hey...)
  if (!("mass.analyzer" %in% colnames(d_msms))) d_msms$mass.analyzer = d_msms$fragmentation
  
  
  ms2_decal = ddply(d_msms, c("fc.raw.file", "mass.analyzer"), .fun = function(x) {
    idx_nr = which(!x$reverse)
    ## select a representative subset, otherwise the number of datapoints is just too large
    idx_nr_subset = idx_nr[seq(1,length(idx_nr), by=ceiling(length(idx_nr)/1000))]
    df.ms = getFragmentErrors(x[idx_nr_subset,])
    df.ms$type="forward"
    
    if (any(x$reverse))
    {
      idx_nr = which(x$reverse)
      ## select a representative subset, otherwise the number of datapoints is just too large
      idx_nr_subset = idx_nr[seq(1,length(idx_nr), by=ceiling(length(idx_nr)/1000))]
      df.ms_r = getFragmentErrors(x[idx_nr_subset,])
      df.ms_r$type="decoy"
      
      ## only merge if we have hits (reverse hits might be few and $mass.deviations..da. might be empty)
      if (nrow(df.ms_r)) df.ms = rbind(df.ms, df.ms_r)
    }
    
    return (df.ms)
  })
  
  head(ms2_decal)
  class(ms2_decal$msErr)
  ms2_decal$msErr = as.numeric(as.character(ms2_decal$msErr))
  #ms2_range = diff(range(ms2_decal$msErr, na.rm = TRUE))
  #ms2_binwidth = ms2_range/20
  ## precision (plotting is just so much quicker, despite using a fixed binwidth)
  #ms2_decal$msErr = round(ms2_decal$msErr, digits=ceiling(-log10(ms2_binwidth)+1))
  tail(ms2_decal)
  ms2_decal$file = paste(ms2_decal$fc.raw.file, paste(ms2_decal$mass.analyzer, ms2_decal$unit), sep="\n")
  
  ## separate plots for each mass analyzer, since we want to keep 'fixed' scales for all raw.files (comparability)
  ddply(ms2_decal, "mass.analyzer", function(ms2_decal) {
    rep_data$add(
      byXflex(ms2_decal, ms2_decal$fc.raw.file, 9, plot_MS2Decal, sort_indices = FALSE)
    )
    return(1)
    })
  
  ##
  ## QC measure for centered-ness of MS2-calibration
  ##
  head(ms2_decal)
  for (analyzer in unique(ms2_decal$mass.analyzer)) {
    qc_name = paste0("X028X_catMS_", "MSMS:~MS^2~Cal~(", analyzer, ")")
    qc_MS2_decal = ddply(ms2_decal[ms2_decal$mass.analyzer==analyzer, ], "fc.raw.file", 
                         function(x)
                         {
                           xx = na.omit(x$msErr);
                           data.frame(X1 = qualCentered(xx), check.names = FALSE)
                         })
    ## augment fragmentation methods with -Inf for missing raw files (otherwise they would become 'red'=fail)
    if (length( setdiff(mq$raw_file_mapping$to, qc_MS2_decal$fc.raw.file) )) {
      frag_missing = data.frame(fc.raw.file = setdiff(mq$raw_file_mapping$to, qc_MS2_decal$fc.raw.file), X1=-Inf)
      qc_MS2_decal = rbind(qc_MS2_decal, frag_missing)
    }
    colnames(qc_MS2_decal)[colnames(qc_MS2_decal)=="X1"] = qc_name
    QCM[[qc_name]] = qc_MS2_decal[, c("fc.raw.file", qc_name)]
  }
  if (!exists("DEBUG_PTXQC")) rm("ms2_decal")
  
  ##
  ## missed cleavages per Raw file
  ##
  cat("MSMS: missed cleavages per Raw file ...\n")
  
  max_mc = max(-Inf, d_msms$missed.cleavages, na.rm = TRUE) ## will be -Inf iff enzyme was not specified and columns is 100% NA
  if (!is.infinite(max_mc))
  { ## MC's require an enzyme to be set
    ## remove contaminants
    msg_cont_removed = "(includes contaminants -- no evidence.txt read)"
    if (exists("d_evd")) {
      msg_cont_removed = "(excludes contaminants)"
      d_msms$contaminant = d_evd$contaminant[match(d_msms$evidence.id, d_evd$id)]
      summary(d_msms$contaminant)
    }
    
    st_bin = ddply(d_msms[!d_msms$contaminant, c("missed.cleavages", "fc.raw.file")], "fc.raw.file", .fun = function(x) {
      t = table(x$missed.cleavages)/nrow(x)
      r = rep(0, max_mc + 1)
      names(r) = as.character(0:max_mc)
      r[names(t)] = t
      return (r)
    })
    rep_data$add(
      byXflex(st_bin, st_bin$fc.raw.file, 25, plot_MissedCleavages, title_sub = msg_cont_removed, sort_indices = FALSE)
    )
    
    mcZero = st_bin[, "0"] * 100
    mcZero_stat = 100 - rev(quantile(mcZero, probs=c(0,0.5,1)))
    cat(pastet("missedCleavages>0 (min,median,max) [%]", paste0(mcZero_stat, collapse=",")), file=fh_out$stats_file, append = TRUE, sep="\n")
    
    ## QC measure for missed-cleavages variation
    qc_mc = data.frame(fc.raw.file = st_bin$fc.raw.file, XXX = st_bin[, "0"], check.names = FALSE)
    cname = "X004X_catPrep_MSMS:~MC"
    colnames(qc_mc)[grep("XXX", colnames(qc_mc))] = cname
    QCM[["MSMS.MC"]] = qc_mc
    qc_mc$"X007X_catPrep_MSMS:~MC~Var" = qualMedianDist(qc_mc[, cname])
    QCM[["MSMS.MC_Var"]] = qc_mc
    
    
  } ## end MC check
  
  
  if (!exists("DEBUG_PTXQC")) rm("d_msms")
}

######
######  msmsScans.txt ...
######

enabled_msmsscans = getYAML(yaml_obj, "File$MsMsScans$enabled", TRUE)
if (enabled_msmsscans)
{
  #d_msmsScan_h = mq$readMQ(txt_files$msmsScan, type="msms", filter = "", nrows=2)
  #colnames(d_msmsScan_h)
  #head(d_msmsScan_h)
  d_msmsScan = mq$readMQ(txt_files$msmsScan, type = "msms", filter = "", 
                         col_subset = c(numeric = "^ion.injection.time", 
                                        numeric = "^retention.time$", 
                                        "^Identified", 
                                        "^Scan.event.number", 
                                        "^Raw.file"),
                         check_invalid_lines = FALSE)
  ##
  ## MQ version 1.0.13 has very rudimentary MSMSscans.txt, with no header, so we need to skip the metrics of this file
  ##
  if (ncol(d_msmsScan) > 3)
  {
    #colnames(d_msmsScan)
    #head(d_msmsScan)
    #unique(d_msmsScan$Identified)
    
    d_msmsScan = d_msmsScan[order(match(d_msmsScan$fc.raw.file, mq$raw_file_mapping$to)),]
    ## sort fc.raw.file's factor values as well
    d_msmsScan$fc.raw.file = factor(d_msmsScan$fc.raw.file, levels = mq$raw_file_mapping$to, ordered = TRUE)
    
    # round RT to 2 min intervals
    d_msmsScan$rRT = round(d_msmsScan$retention.time/2)*2
    
    ##
    ## TopN over RT
    ##
    cat("MSMS-Scans: TopN over RT ...\n")
    
    ## maximum scan event over time
    scan.event.number = NULL ## make R check happy
    DFmse = ddply(d_msmsScan, c("fc.raw.file"), function(x) {
      ## sort by RT
      if (is.unsorted(x$retention.time))
      { ## should not happen, but just to make sure
        x = x[, order(x$retention.time)]
      }
      ## only take the highest scan event (SE) in a series
      maxN = getMaxima(x$scan.event.number, thresh_rel = 0.0)
      df.max = x[maxN,]
      ## use median of that within one RT bin
      meanN = ddply(df.max, c("rRT"), summarise, topN = median(scan.event.number))
      return (meanN)    
    })
    
    head(DFmse)
    rep_data$add(
      byXflex(DFmse, DFmse$fc.raw.file, 6, plot_TopNoverRT, sort_indices = FALSE)
    )
    
    ## QC measure for smoothness of TopN over RT
    qc_TopNRT = ddply(DFmse, "fc.raw.file", function(x) data.frame("X012X_catLC_MS^2*Scans:~TopN~over~RT" = qualUniform(x$topN), check.names = FALSE))
    QCM[["MSMSscans.TopN_over_RT"]] = qc_TopNRT
    
    ##
    ## Injection time over RT
    ##
    cat("MSMS-Scans: Injection time over RT ...\n")
    
    param_name_MSMSScans_ionInjThresh = "File$MsMsScans$IonInjectionThresh_num"
    param_def_MSMSScans_ionInjThresh = 10 ## default ion injection threshold in milliseconds
    param_MSMSScans_ionInjThresh = getYAML(yaml_obj, param_name_MSMSScans_ionInjThresh, param_def_MSMSScans_ionInjThresh)
    if (!is.numeric(param_MSMSScans_ionInjThresh))
    { ## reset if value is weird
      cat("YAML value for '" %+% param_name_MSMSScans_ionInjThresh %+% "' is invalid ('" %+% param_MSMSScans_ionInjThresh %+% "'). Using default of " %+% param_def_MSMSScans_ionInjThresh %+% ".")
      param_MSMSScans_ionInjThresh = param_def_MSMSScans_ionInjThresh
    }
    
    ## average injection time over RT
    DFmIIT = ddply(d_msmsScan, c("fc.raw.file"), function(x) {
      meanN = ddply(x, c("rRT"), function(x) data.frame(medIIT = median(x$ion.injection.time)))
      return (meanN) 
    })
    head(DFmIIT)
    ## average injection time overall
    DFmIITglob = ddply(d_msmsScan, c("fc.raw.file"), function(x) {
      return (data.frame(mean = mean(x$ion.injection.time)))
    })
    head(DFmIITglob)
    
    
    rep_data$add(
      byXflex(DFmIIT, DFmIIT$fc.raw.file, 6, plot_IonInjectionTimeOverRT, sort_indices = FALSE,
              stats = DFmIITglob,
              extra_limit = param_MSMSScans_ionInjThresh)
    )
    
    
    ## QC measure for injection times below expected threshold
    DFmIIT_belowThresh = ddply(d_msmsScan, c("fc.raw.file"), function(x) {
      return (data.frame(belowThresh_IIT = sum(x$ion.injection.time < param_MSMSScans_ionInjThresh, na.rm = TRUE) / nrow(x)))
    })
    head(DFmIIT_belowThresh)
    qc_IIT = ddply(DFmIIT_belowThresh, "fc.raw.file", function(x) data.frame("X024X_catMS_MS^2*Scans:~Ion~Inj~Time" = qualLinThresh(x$belowThresh_IIT, t = 1),
                                                                             check.names = FALSE))
    QCM[["MSMSscans.Ion_Inj_Time"]] = qc_IIT
    
    
    ##
    ## TopN counts
    ##
    cat("MSMS-Scans: scan event counts ...\n")
    
    ## check if scan.event.number requires fixing
    ## (e.g. when MS3 events are recorded between MS2 events, there are gaps in the numbering)
    ## we close the gaps by requiring consecutive scan event numbers in MS2
    scan.events = d_msmsScan[, c("scan.event.number", "fc.raw.file")]
    while(TRUE) { ## should be at most max(scan.even.number) iterations
      se_pos = 1 + which(diff(scan.events$scan.event.number) > 1) ## position of gaps>1
      if (length(se_pos) == 0) break;
      scan.events$scan.event.number[se_pos] = scan.events$scan.event.number[se_pos] - 1
    }
    DFc = ddply(scan.events, c("scan.event.number", "fc.raw.file"), summarise, n = length(scan.event.number))
    dfc.ratio = ddply(DFc, "fc.raw.file", function(x, maxn)
    {
      ## sort x by scan event
      event_count = x$n
      ## verify its monotonically increasing
      if (is.unsorted(rev(event_count))) {
        #print(x)
        stop("Scan event distribution is not monotonically increasing!")
      } 
      ## verify that there are no gaps
      if (max(x$scan.event.number) != nrow(x)) {
        #print(x)
        stop("Scan event distribution has unexpected holes...!")
      }
      
      event_pre = c(event_count[-1], 0)
      event_diff = event_count - event_pre
      
      ## build new DF of fixed length
      sn = x$scan.event.number
      if (max(sn) < maxn) 
      {
        event_diff = c(event_diff, rep(0, maxn-max(sn)))
        sn = c(sn, (max(sn)+1):maxn)
      }
      DF.new = data.frame(scan.event.number = sn, n = event_diff)
      return (DF.new)
    }, maxn = max(DFc$scan.event.number))
    head(dfc.ratio)
    
    rep_data$add(
      byXflex(dfc.ratio, dfc.ratio$fc.raw.file, 9, plot_TopN, sort_indices = FALSE)
    )
    
    ## QC measure for always reaching the maximum TopN
    maxTopN = max(dfc.ratio$scan.event.number)
    qc_TopN = ddply(dfc.ratio, "fc.raw.file", function(x) data.frame("X035X_catMS_MS^2*Scans:~TopN~high" = qualHighest(x$n, maxTopN),
                                                                     check.names = FALSE))
    QCM[["MSMSscans.TopN"]] = qc_TopN
    
    
    ##
    ## Scan event: % identified
    ##
    cat("MSMS-Scans: TopN % identified ...\n")
    
    DF = ddply(d_msmsScan, c("scan.event.number", "identified", "fc.raw.file"), summarise, n = length(scan.event.number))
    
    # try KS on underlying data instead of using qualUniform()
    #   DF2= ddply(d_msmsScan, "fc.raw.file", function(rf){
    #     cat(class(rf))
    #     cat(rf$fc.raw.file[1])
    #     idx_p = rf$identified=="+"
    #     cat(length(idx_p) %+% "\n")
    #     kk = ks.test(rf$scan.event.number[idx_p], rf$scan.event.number[-idx_p])
    #     cat(kk$p.value)
    #     kk$statistic  # = 'D' ,,  p.value is much smaller (~0)
    #   })
    #   --> fail, 'D' and p-values are too low
    df.ratio = ddply(DF, c("scan.event.number", "fc.raw.file"), function(x)
    {
      xp = xm = 0
      if ("+" %in% x$identified) xp = x$n[x$identified=="+"]
      if ("-" %in% x$identified) xm = x$n[x$identified=="-"]
      ratio = xp * 100 / sum(xp, xm)
      return (data.frame(ratio = ratio, count = sum(x$n)))
    })
    head(df.ratio)
    
    pl = byXflex(df.ratio, df.ratio$fc.raw.file, 9, plot_ScanIDRate, sort_indices = FALSE)
    for (p in pl) rep_data$add(p)
    
    ## QC measure for constantly identifiying peptides, irrespective of scan event number
    ## -- we weight scan events by their number of occurence
    qc_TopN_ID = ddply(df.ratio, "fc.raw.file", function(x) data.frame("X038X_catMS_MS^2*Scans:~TopN~ID~over~N" = qualUniform(x$ratio, x$count),
                                                                       check.names = FALSE))
    QCM[["MSMSscans.TopN_ID_over_N"]] = qc_TopN_ID
  } ## end MSMSscan from MQ > 1.0.13
}

hm = getQCHeatMap(QCM, raw_file_mapping = mq$raw_file_mapping)
#print(hm[["plot"]])
write.table(hm[["table"]], file = fh_out$heatmap_values_file, quote = TRUE, sep = "\t", row.names = FALSE)
rep_data$add(hm[["plot"]], "heatmap")

## get MQ short name mapping plot (might be NULL if no mapping was required)
rep_data$add(mq$plotNameMapping(), "name_mapping")

##
## plot it!!!
##


out_formats_supported = c("html", "plainPDF")

param_name_PTXQC_OutputFormats = "PTXQC$OutputFormats"
param_def_PTXQC_OutputFormats = out_formats_supported[2]
param_OutputFormats = getYAML(yaml_obj, param_name_PTXQC_OutputFormats, param_def_PTXQC_OutputFormats)

param_name_PTXQC_PageNumbers = "PTXQC$PlainPDF$AddPageNumbers"
param_def_PTXQC_PageNumbers = "on"
param_PageNumbers = getYAML(yaml_obj, param_name_PTXQC_PageNumbers, param_def_PTXQC_PageNumbers)

cat("Creating Report file ...")




#####################################################################
## list of qcMetric objects
lst_qcMetrics = ls(pattern="qcMetric_.*")


#
#param_OutputFormats = "html pdf"
#
out_formats = unlist(strsplit(param_OutputFormats, "[ ,]+"))
out_formats
out_format_requested = out_formats_supported[match(out_formats, out_formats_supported)]
if (any(is.na(out_format_requested)))
{
  stop("Output format(s) not supported: '", paste(out_formats[is.na(out_format_requested)], collapse="', '"), "'")
}

if ("html" %in% out_format_requested)
{
  fh_out$report_file_extension = c(fh_out$report_file_extension, ".html")
  
  #template = "C:/projects/QC/package/PTXQC/inst/reportTemplate/PTXQC_report_template.Rmd"
  #knit2html(template, output = paste0(fh_out$report_file, ".html"))
  template = system.file("./reportTemplate/PTXQC_report_template.Rmd", package="PTXQC")
  template
  ## Rmarkdown: convert to Markdown, and then to HTML or PDF...
  render(template, output_file = paste0(fh_out$report_file, ".html"))
  ##render(template, output_file = paste0(fh_out$report_file, ".pdf"))
}

  
if ("plainPDF" %in% out_format_requested)
{
  fh_out$report_file_extension = c(fh_out$report_file_extension, ".pdf")
  report_file_PDF = paste0(fh_out$report_file, ".pdf")
  ## give the user a chance to close open reports which are currently blocked for writing
  if (!wait_for_writable(report_file_PDF))
  {
    stop("Target file not writable")
  }
  
  if (param_PageNumbers == "on")
  {
    printWithPage = function(gg_obj, page_nr, filename = fh_out$report_file)
    {
      filename = basename(filename)
      printWithFooter(gg_obj, bottom_left = filename, bottom_right = page_nr)
    }
  } else {
    ## no page number and filename at bottom of each page
    printWithPage = function(gg_obj, page_nr, filename = fh_out$report_file)
    {
      print(gg_obj)
    }
  }
  pdf(report_file_PDF)
  printWithPage(rep_data$get("params"), "p. 1")       # parameters
  printWithPage(rep_data$get("name_mapping"), "p. 2") # short file mapping
  printWithPage(rep_data$get("heatmap"), "p. 3")      # summary heatmap
  GPL_lst = rep_data$get("metric")
  pc = 4; ## subsequent pages start at #4
  for (idx in sort(names(GPL_lst)))
  {
    printWithPage(GPL_lst[[idx]], paste("p.", pc))
    pc = pc + 1
  }
  dev.off();
  cat(" done\n")
}

## save plot object (for easier access, in case someone wants high-res plots)
## (...disabled for now until concrete use case pops up)
#cat("Dumping plot objects as Rdata file ...")
#save(file = fh_out$R_plots_file, list = "GPL")
#cat(" done\n")

### write YAML config
writeYAML(fh_out$yaml_file, yaml_obj)

## write shortnames and sorting of filenames
mq$writeMappingFile(fh_out$filename_sorting)

cat(paste("Report file created at\n\n    ", fh_out$report_file, ".*\n\n", sep=""))
cat(paste0("\n\nTime elapsed: ", round(as.double(Sys.time() - time_start, units="mins"), 1), " min\n\n"))

## return path to PDF report and YAML config, etc
return (fh_out)
}
