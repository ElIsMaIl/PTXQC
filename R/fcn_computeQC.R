#' Create a quality control report (in PDF format).
#'
#' This is the main function of the package and the only thing you need to call directly if you are 
#' just interested in getting a QC report.
#' 
#' You need to provide the folder name of the 'txt' output, as generated by MaxQuant and 
#' optionally a YAML configuration object, which allows to (de)activate certain plots and holds other parameters.
#' The yaml_obj is complex and best obtained by running this function once using the default (empty list).
#' A full YAML configuration object will be written in the 'txt' folder you provide and can be loaded using
#' \code{\link[yaml]{yaml.load}}.
#' 
#' The PDF and the config file will be stored in the given txt folder.
#' 
#' @note You need write access to the txt folder!
#' 
#' For updates, bug fixes and feedback please visit \url{http://github.com/cbielow/PTXQC}.
#'
#' @param txt_folder Path to txt output folder of MaxQuant (e.g. "c:/data/Hek293/txt")
#' @param yaml_obj   A nested list object with configuration parameters for the report.
#'                   Useful to switch off certain plots or skip entire sections.
#' @return List with named filename strings, e.g. $yaml_file, $report_file etc..
#'          
#' @importFrom plyr ddply dlply ldply llply adply summarise mapvalues
#' @importFrom reshape2 melt
#' @importFrom rmarkdown render
#' 
#' @export
#'           
createReport = function(txt_folder, yaml_obj = list())
{
  
  ### script starts...
  if (class(yaml_obj) != "list")
  {
    stop(paste0("Argument 'yaml_obj' is not of type list\n"));
  }
  
  ## list of plots
  rep_data = ReportData$new()
  
  ## list of data.frames containing one QC metric per list for each Raw file
  ## used for heat map later on
  QCM = list()
  
  ## determines if a local mqpar.xml should be used to grep all YAML parameters whose name starts with "MQpar_" from the
  ## original mqpar.xml instead of the yaml.config. The "MQpar_..." param from the config
  ## will be ignored and the newly written yaml.config will contain the values from mqpar.xml.
  param_name_PTXQC_UseLocalMQPar = "PTXQC$UseLocalMQPar"
  param_def_PTXQC_UseLocalMQPar = TRUE
  param_useMQPAR = getYAML(yaml_obj, param_name_PTXQC_UseLocalMQPar, param_def_PTXQC_UseLocalMQPar)
  
  time_start = Sys.time()
  
  
  if (!any(file.info(txt_folder)$isdir, na.rm = TRUE))
  {
    stop(paste0("Argument txt_folder with value '", txt_folder, "' is not a valid directory\n"));
  }
  txt_files = list()
  txt_files$param = "parameters.txt"
  txt_files$summary = "summary.txt"
  txt_files$groups = "proteinGroups.txt"
  txt_files$evd = "evidence.txt"
  txt_files$msms = "msms.txt"
  txt_files$msmsScan = "msmsScans.txt"
  txt_files$mqpar = "mqpar.xml"
  txt_files = lapply(txt_files, function(x) paste(txt_folder, x, sep=.Platform$file.sep))
  
  ## create names of output files (report PDF, YAML, stats, etc...)
  fh_out = getReportFilenames(txt_folder)
  use_extended_report_filename = getYAML(yaml_obj, "PTXQC$ReportFilename$extended", TRUE)
  fh_out$report_file = ifelse(use_extended_report_filename, fh_out$report_file_extended, fh_out$report_file_simple)
  
  unlink(fh_out$stats_file)
  cat("Statistics summary:", file=fh_out$stats_file, append = FALSE, sep="\n")
  
  ## prepare for readMQ()
  mq = MQDataReader$new()
  
  ## read manual filename shortening & sorting (if available)
  mq$readMappingFile(fh_out$filename_sorting)
  
  ######
  ######  parameters.txt ...
  ######
  
  enabled_parameters = getYAML(yaml_obj, "File$Parameters$enabled", TRUE)
  if (enabled_parameters)
  {
    d_parAll = mq$readMQ(txt_files$param, type="par")
    qcMetric_param$setData(d_parAll)
    rep_data$add(qcMetric_param$plots, "params")
  }
  
  add_fs_col = getYAML(yaml_obj, "PTXQC$NameLengthMax_num", 10)
  
  ######
  ######  summary.txt ...
  ######
  
  enabled_summary = getYAML(yaml_obj, "File$Summary$enabled", TRUE)
  if (enabled_summary)
  {
    d_smy = mq$readMQ(txt_files$summary, type="sm", add_fs_col = add_fs_col)
    #colnames(d_smy)
    #colnames(d_smy[[1]])
    
    id_rate_bad = getYAML(yaml_obj, "File$Summary$IDRate$Thresh_bad_num", 20)
    id_rate_great = getYAML(yaml_obj, "File$Summary$IDRate$Thresh_great_num", 35)
    
    ### MS/MS identified [%]
    qcMetric_MSMSIdRate$setData(d_smy$raw, id_rate_bad, id_rate_great)
    rep_data$add(qcMetric_MSMSIdRate$plots)

    ## QC measure for ID rate (threshold reached?)
    qc_sm_id = d_smy$raw[, c("raw.file", "ms.ms.identified....")]
    cname = "X030X_catMS_SM:~MS^2~ID~rate (\">" %+% id_rate_great %+% "\")"
    qc_sm_id[, cname] = qualLinThresh(qc_sm_id$ms.ms.identified.... , id_rate_great)
    QCM[["SM.MS2_ID_rate"]] = qc_sm_id[,c("raw.file", cname)]
  }  
  
  
  ######
  ######  proteinGroups.txt ...
  ######
  
  GL_name_min_length = 8
  
  enabled_proteingroups = getYAML(yaml_obj, "File$ProteinGroups$enabled", TRUE)
  enabled_pg_ratioLabIncThresh = getYAML(yaml_obj, "File$ProteinGroups$RatioPlot$LabelIncThresh_num", 4)
  if (enabled_proteingroups)
  {
    
    d_pg = mq$readMQ(txt_files$groups, type="pg", col_subset=NA, filter="R")
      
    clusterCols = list()
    ##
    ## intensity boxplots
    ##
    param_name_PG_intThresh = "File$ProteinGroups$IntensityThreshLog2_num"
    param_def_PG_intThresh = 25 ## default median intensity in log2 scale
    param_PG_intThresh = getYAML(yaml_obj, param_name_PG_intThresh, param_def_PG_intThresh)
    if (!is.numeric(param_PG_intThresh) || !(param_PG_intThresh %in% 1:100))
    { ## reset if value is weird
      cat("YAML value for '" %+% param_name_PG_intThresh %+% "' is invalid ('" %+% param_PG_intThresh %+% "'). Using default of " %+% param_def_PG_intThresh %+% ".")
      param_PG_intThresh = param_def_PG_intThresh
    }
    
    
    colsSIL = grepv("^intensity\\.[hlm](\\.|$)", colnames(d_pg))
    colsLF = grepv("^intensity\\..", colnames(d_pg))
    colsOneCond = "intensity" ## just one group -- we still want to know what the overall intensity is
    if (length(colsSIL)) {
      ## ignore intensity.l and alike if real groups are present
      plain_channel = grepv("^intensity\\.[hlm]$", colnames(d_pg))
      if (all(plain_channel == colsSIL)) colsW = colsSIL else colsW = setdiff(colsSIL, plain_channel)
    } else if (length(colsLF)) {
      colsW = colsLF
    }  else {
      colsW = colsOneCond
    }
    
    ## a global PG name mapping
    MAP_pg_groups = data.frame(long = colsW)
    MAP_pg_groups$short = shortenStrings(simplifyNames(delLCP(MAP_pg_groups$long, 
                                                              min_out_length = GL_name_min_length, 
                                                              add_dots = TRUE), 
                                                       min_out_length = GL_name_min_length))
    ##
    ## Contaminants plots
    ##
    df.con_stats = adply(colsW, .margins=1, function(group) {
      #cat(group)
      return(data.frame(group_long = as.character(group),
                        log10_int  = log10(sum(as.numeric(d_pg[, group]), na.rm = TRUE)),
                        cont_pc    = sum(as.numeric(d_pg[d_pg$contaminant, group]), na.rm = TRUE) /
                          sum(as.numeric(d_pg[, group], na.rm = TRUE))*100
      ))
    })
    df.con_stats$group = MAP_pg_groups$short[match(df.con_stats$group_long, MAP_pg_groups$long)]
    df.con_stats$logAbdClass = getAbundanceClass(df.con_stats$log10_int)
    df.con_stats
    
    pg_plots_cont = byXflex(df.con_stats, 1:nrow(df.con_stats), 90, plot_ContsPG, sort_indices = FALSE)
    for (p in pg_plots_cont) rep_data$add(p);
    
    ##
    ## stats file
    ##
    con_stats_smry = quantile(df.con_stats$cont_pc, probs=c(0,0.5,1))
    cat(pastet("contamination(min,median,max) [%]", paste(con_stats_smry, collapse=",")), file=fh_out$stats_file, append = TRUE, sep="\n")  
    
    ###
    ### intensity boxplot
    ###
    
    clusterCols$raw.intensity = colsW ## cluster using intensity
    #cat("colsW:\n")
    #cat(paste0(colsW, collapse=","))
    ## some stats (for plot title)
    medians_no0 = sort(apply(log2(d_pg[, colsW, drop = FALSE]), 2, function(x) quantile(x[x>0], probs=0.5, na.rm = TRUE))) # + c(0,0,0,0,0,0))
    int_dev_no0 = RSD(medians_no0)
    ## do not remove zeros (but add +1 since RSD is 'NA' when 'inf' is included in log-data)
    medians = sort(apply(log2(d_pg[, colsW, drop = FALSE]+1), 2, quantile, na.rm = TRUE, probs=0.5)) # + c(0,0,0,0,0,0))
    int_dev = RSD(medians)
    int_dev.s = pastet("INT RSD [%]", round(int_dev, 3))
    lpl = boxplotCompare(   data = melt(d_pg[, c(colsW, "contaminant"), drop = FALSE], id.vars=c("contaminant"))[,c(2,3,1)],
                            log2 = TRUE, 
                         mainlab = "PG: intensity distribution",
                            ylab = expression(log[2]*" intensity"),
                          sublab = paste0("RSD ", round(int_dev_no0, 1),"% (w/o zero int.; expected < 5%)\n",
                                          "RSD ", round(int_dev, 1),"% [high RSD --> few peptides])"),
                          abline = param_PG_intThresh,
                           names = MAP_pg_groups)
    #for (pl in lpl) print(pl)
    for (pl in lpl) rep_data$add(pl)
    rm("lpl")          
    cat(int_dev.s, file=fh_out$stats_file, append = TRUE, sep="\n")
    
    ##
    ## LFQ boxplots
    ##
    colsSIL = grepv("^lfq.intensity\\.[hlm](\\.|$)", colnames(d_pg))
    colsLF = grepv("^lfq.intensity\\..", colnames(d_pg))
    
    ## a global PG name mapping
    MAP_pg_groups_LFQ = NA
    if (length(c(colsSIL, colsLF)) > 0)
    {
      if (length(colsSIL)) {
        ## unlike intensity.l, there is no lfq.intensity.l which we could remove
        colsW = colsSIL
      } else colsW = colsLF
      MAP_pg_groups_LFQ = data.frame(long = colsW)
      MAP_pg_groups_LFQ$short = shortenStrings(simplifyNames(delLCP(MAP_pg_groups_LFQ$long, 
                                                                    min_out_length = GL_name_min_length, 
                                                                    add_dots = TRUE), 
                                                             min_out_length = GL_name_min_length))

      clusterCols$lfq.intensity = colsW ## cluster using LFQ
      ## some stats (for plot title)
      medians_no0 = sort(apply(log2(d_pg[, colsW, drop = FALSE]), 2, function(x) quantile(x[x>0], probs=0.5, na.rm = TRUE))) # + c(0,0,0,0,0,0))
      lfq_dev_no0 = RSD(medians_no0)
      ## do not remove zeros (but add +1 since RSD is 'NA' when 'inf' is included in log-data)
      medians = sort(apply(log2(d_pg[, colsW, drop = FALSE]+1), 2, quantile, probs=0.5, na.rm = TRUE)) # + c(0,0,0,0,0,0))
      lfq_dev = RSD(medians)
      lfq_dev.s = pastet("LFQ RSD [%]", round(lfq_dev, 3))
      lpl = boxplotCompare(   data = melt(d_pg[, c(colsW, "contaminant"), drop = FALSE], id.vars=c("contaminant"))[,c(2,3,1)],
                              log2 = TRUE, 
                           mainlab = "PG: LFQ intensity distribution", 
                              ylab = expression(log[2]*" LFQ intensity"),
                            sublab = paste0("RSD ", round(lfq_dev_no0, 1),"% (w/o zero int.; expected < 5%)\n",
                                            "RSD ", round(lfq_dev, 1),"% [high RSD --> few peptides])"),
                            abline = param_PG_intThresh,
                             names = MAP_pg_groups_LFQ)
      #for (pl in lpl) print(pl)
      for (pl in lpl) rep_data$add(pl)
      cat(lfq_dev.s, file=fh_out$stats_file, append = TRUE, sep="\n")
    }
    
    ##
    ## iTRAQ/TMT, reporter ion intensity boxplot
    ##
    ## either "reporter.intensity.0.groupname" or "reporter.intensity.0" (no groups)    
    colsITRAQ = grepv("^reporter.intensity.[0-9].|^reporter.intensity.[0-9]$", colnames(d_pg))
    ## a global PG name mapping
    MAP_pg_groups_ITRAQ = NA
    if (length(colsITRAQ) > 0)
    {
      MAP_pg_groups_ITRAQ = data.frame(long = c(colsITRAQ))
      MAP_pg_groups_ITRAQ$short = shortenStrings(simplifyNames(delLCP(MAP_pg_groups_ITRAQ$long, 
                                                                      min_out_length = GL_name_min_length, 
                                                                      add_dots = TRUE), 
                                                               min_out_length = GL_name_min_length))

      colsW = colsITRAQ
      clusterCols$reporter.intensity = colsW ## cluster using reporters
      ## some stats (for plot title)
      medians_no0 = sort(apply(log2(d_pg[, colsW, drop = FALSE]), 2, function(x) quantile(x[x>0], probs=0.5, na.rm = TRUE))) # + c(0,0,0,0,0,0))
      reprt_dev_no0 = RSD(medians_no0)
      ## do not remove zeros (but add +1 since RSD is 'NA' when 'inf' is included in log-data)
      medians = sort(apply(log2(d_pg[, colsW, drop = FALSE]+1), 2, quantile, probs=0.5, na.rm = TRUE)) # + c(0,0,0,0,0,0))
      reprt_dev = RSD(medians)
      reprt_dev.s = pastet("Reporter RSD [%]", round(reprt_dev, 3))
      lpl = boxplotCompare(   data = melt(d_pg[, c(colsW, "contaminant"), drop = FALSE], id.vars=c("contaminant"))[,c(2,3,1)],
                              log2 = TRUE, 
                              ylab = expression(log[2]*" reporter intensity"),
                           mainlab = "PG: reporter intensity distribution",
                            sublab = paste0("RSD ", round(reprt_dev_no0, 1),"% (w/o zero int.; expected < 5%)\n",
                                            "RSD ", round(reprt_dev, 1),"% [high RSD --> few peptides])"),
                            abline = param_PG_intThresh,
                             names = MAP_pg_groups_ITRAQ)
      #for (pl in lpl) print(pl)
      for (pl in lpl) rep_data$add(pl)
      cat(reprt_dev.s, file=fh_out$stats_file, append = TRUE, sep="\n")
    }
    
    
    ##
    ## PCA
    ##
    ## some clustering (its based on intensity / lfq.intensity columns..)
    ## todo: maybe add ratios -- requires loading from txt though..
    MAP_pg_groups_ALL = rbind(MAP_pg_groups, MAP_pg_groups_LFQ, MAP_pg_groups_ITRAQ)
    for (cond in names(clusterCols))
    {
      #cond = names(clusterCols)[3]
      #print(clusterCols[cond])
      if (length(clusterCols[[cond]]) <= 1) 
      { ## only one condition.. PCA does not make sense (and will not work)
        next;
      }
      ## remove contaminants
      data = t(d_pg[!d_pg$contaminant, unlist(clusterCols[cond]), drop = FALSE])
      ## remove constant/zero columns (== dimensions == proteins)
      data = data[, colSums(data, na.rm = TRUE) > 0, drop = FALSE]
      rownames(data) = MAP_pg_groups_ALL$short[match(rownames(data), MAP_pg_groups_ALL$long)]
      lpl = try(getPCA(data = data,
                       gg_layer = addGGtitle(paste0("PG: PCA of '", sub(".", " ", cond, fixed = TRUE), "'"), "(excludes contaminants)")
      )[["plots"]]
      )
      #print(lpl)
      if (!inherits(lpl, "try-error")) for (pl in lpl) rep_data$add(pl);
    }
    
    
    ##################################
    ## ratio plots
    ##################################
    ## get ratio column
    ratio_cols = grepv("^ratio\\.[hm]\\.l", colnames(d_pg))  ## e.g. "ratio.m.l.ARK5exp" or "ratio.m.l.variability.ARK5exp"
    ## remove everything else
    ## e.g. we do not want ratio.h.l.variability.ARK5exp, i.e. the 'variability' property
    ratio_cols = grepv("^ratio.[hm].l.normalized", ratio_cols, invert = TRUE)
    ratio_cols = grepv("^ratio.[hm].l.count", ratio_cols, invert = TRUE)
    ratio_cols = grepv("^ratio.[hm].l.variability", ratio_cols, invert = TRUE)
    ratio_cols = grepv("^ratio.[hm].l.significance.a", ratio_cols, invert = TRUE) ## from MQ 1.0.1x
    ratio_cols = grepv("^ratio.[hm].l.significance.b", ratio_cols, invert = TRUE)
    ratio_cols = grepv("^ratio.[hm].l.iso.count", ratio_cols, invert = TRUE) ## from MQ 1.5.1.2
    ratio_cols = grepv("^ratio.[hm].l.type", ratio_cols, invert = TRUE)
    ratio_cols
    
    if (length(ratio_cols) > 0)
    {
      colnames(d_pg)
      
      ## remove reverse and contaminants (might skew the picture)
      idx_row = !d_pg$contaminant & !d_pg$reverse
      d_sub = log2(d_pg[idx_row, ratio_cols, drop = FALSE])
      ## rename "ratio.h.l" to "h.l" (same for m.l in tripleSILAC)
      idx_globalRatio = grep("ratio\\.[hm]\\.l$", colnames(d_sub))
      if (length(idx_globalRatio)) colnames(d_sub)[idx_globalRatio] = gsub("^ratio\\.", "", colnames(d_sub)[idx_globalRatio])
      ## simplify the rest
      if (ncol(d_sub) > length(idx_globalRatio))
      {
        idx_other = setdiff(1:ncol(d_sub), idx_globalRatio)
        colnames(d_sub)[idx_other] = shortenStrings(simplifyNames(delLCP(colnames(d_sub)[idx_other], 
                                                                         min_out_length = GL_name_min_length, 
                                                                         add_dots = TRUE), 
                                                                  min_out_length = GL_name_min_length))
      }
      #summary(d_sub)
      # 
      # plot(density(d_sub[,1], bw = "SJ", adjust=1, na.rm = TRUE, n=128))
      # plot(d_sub[,1])
      # h = density(d_sub[,1], bw = "SJ", adjust=1, na.rm = TRUE, n=128)
      
      
      ## get ranges to fix breaks for density intervals
      # breaks = seq(min(d_sub, na.rm = TRUE), max(d_sub, na.rm = TRUE), length.out=(max(dd, na.rm = TRUE)-min(dd, na.rm = TRUE))/0.5)
      # mid = hist(d_sub[, 1], breaks = breaks)$mids
      ratio.densities = do.call(rbind, (lapply(1:ncol(d_sub), function(x) {
        name = colnames(d_sub)[x]
        ## density estimation can fail if not enough data
        h = try(density(na.omit(d_sub[ ,x]), bw = "SJ", adjust=2, na.rm = TRUE))
        if (inherits(h, "try-error")) return (data.frame(x = 1, y = 1, col = name, multimodal = FALSE))
        count = sum(getMaxima(h$y))
        if (count > 1) name = paste(name, "*")
        df = data.frame(x = h$x, y = h$y, col = name, multimodal = (count>1))
        return (df)
      })))
      ratio.densities$alpha = c(0.8, 1)[ratio.densities$multimodal+1]
      ratio.densities$ltype = c("dotted", "solid")[ratio.densities$multimodal+1]
      #head((ratio.densities))
      
      
      ## compute label incorporation?
      ratio.mode = ddply(ratio.densities, "col", .fun = function(x) {
        mode = x$x[which.max(x$y)]
        return (data.frame(mode = mode))
      })
      
      ## on more than ratio 1:8 or 8:1 ratio, report label incorporation
      # enabled_pg_ratioLabIncThresh == 8 by default
      if (max(abs(ratio.mode$mode)) > abs(log2(enabled_pg_ratioLabIncThresh))) {
        cat(paste0("Maximum ratio (log2) was ", round(max(abs(ratio.mode$mode)),1) , ", reaching the threshold of ", abs(log2(enabled_pg_ratioLabIncThresh)), " for label-incorporation computation.\nComputing ratios ...\n"))
        ## back to normal scale
        ratio.norm = 2^ratio.mode$mode
        ## compute incorporation
        ratio.inc =  ratio.norm / (ratio.norm+1) * 100
        ## round
        ratio.mode$li = round(ratio.inc)
        ## new label
        ratio.mode$col_new = ratio.mode$col %+% " (" %+% ratio.mode$li %+% "%)"
        ## replace column names in data.frame
        ratio.densities$col = ratio.mode$col_new[match(ratio.densities$col, ratio.mode$col)]
        ## notify user via legend title
        legend_title = "group\n(with label inc)"
      } else
      {
        cat(paste0("Maximum ratio (log2) was ", max(abs(ratio.mode$mode)), ", NOT reaching the threshold of ", abs(log2(enabled_pg_ratioLabIncThresh)), " for label-incorporation computation.\nSkipping ratios ...\n"))
        legend_title = "group"
      }
      
      main_title = "PG: ratio density\n(w/o contaminants)"
      main_col = "black"
      if (any(ratio.densities$multimodal))
      {
        main_title = paste0(main_title, "\nWarning: multimodal densities detected")
        main_col = "red"
      }
      ##
      ## plot ratios
      ##
      rep_data$add(
        byXflex(ratio.densities, ratio.densities$col, 5, plot_RatiosPG, sort_indices = FALSE, d_range = range(d_sub, na.rm=TRUE), main_title, main_col, legend_title)
      )
      
    }
    ## rm("d_pg") required in evidence....
  }
  
  ######
  ######  evidence.txt ...
  ######
  
  enabled_evidence = getYAML(yaml_obj, "File$Evidence$enabled", TRUE)
  if (enabled_evidence)
  {
    #d_evd_s = mq$readMQ(txt_files$evd, type="ev", filter = "", nrows=100)
    #d_evd_s = mq$readMQ(txt_files$evd, type="ev", filter = "")
    #head(d_evd_s)
    #colnames(d_evd_s)
    #table(d_evd_s$reverse)
    #[grep("ount", colnames(d_evd))]
    
    ## protein.names is only available from MQ 1.4 onwards
    d_evd = mq$readMQ(txt_files$evd, type="ev", filter="R", col_subset=c("proteins", "Retention.Length", "retention.time.calibration", 
                                                                         "Retention.time$", "Match.Time.Difference", "^intensity$", "^Type$",
                                                                         "Mass\\.Error", "^uncalibrated...calibrated." , "^m.z$",
                                                                         "^score$", 
                                                                         "^fraction$",  ## only available when fractions were given
                                                                         "Raw.file", "^Protein.Group.IDs$", "Contaminant", "[RK]\\.Count", 
                                                                         "^Charge$", "modified.sequence", "^Mass$", "^protein.names$", "^ms.ms.count$"))
    ##
    ## sort by rawfile as shown in the summary.txt (or whatever the first txt file was)
    ##
    d_evd = d_evd[order(match(as.character(d_evd$fc.raw.file), mq$raw_file_mapping$to)),]
    ## sort fc.raw.file's factor values as well
    d_evd$fc.raw.file = factor(d_evd$fc.raw.file, levels = mq$raw_file_mapping$to, ordered = TRUE)
    
    #d_evd = mq$readMQ(txt_files$evd, type="ev", filter="R", col_subset=c("labeling.state", "Match.Time.Difference", "fasta.headers", "^intensity$", "Raw.file", "^Protein.Group.IDs$"))
    #summary(head(d_evd))
    #head(d_evd)
    #colnames(d_evd)

    ### warn of special contaminants!
    ## these need to be in FASTA headers (description is not enough)!
    ## syntax:  list( contaminant1 = c(name, threshold), contaminant2 = c(...), ...)
    ##
    ##  if within the YAML file
    ##    SpecialContaminants: no
    ##  is set, then 'yaml_contaminants' will be 'FALSE'
    ##
    contaminant_default = list("cont_MYCO" = c(name="MYCOPLASMA", threshold=1)) # name (FASTA), threshold for % of unique peptides
    ## contaminant_default = FALSE ## to switch it off by default
    yaml_contaminants = getYAML(yaml_obj, "File$Evidence$SpecialContaminants", contaminant_default)
    
    #stop(yaml_contaminants)
    
    for (ca_entry in yaml_contaminants)
    {
      ca = ca_entry[1]
      ## 
      if (ca == FALSE) {
        cat("No special contaminants requested!\n")
        break;
      }
      
      ca_thresh = as.numeric(ca_entry[2])
      
      not_found = TRUE
      
      if (enabled_proteingroups)
      {
        pg_id = d_pg$id[grep(ca, d_pg$fasta.headers, ignore.case = TRUE)]
      } else {
        ## fail hard; we could hack around this (e.g. by loading fasta headers from evidence.txt), but it
        ## wastes a lot of memory and time
        stop(paste0("Error: reporting of special contaminants (", ca, ") requires loading of proteinGroups.txt. ",
                    "If you don't have this file, please disable contaminant lookup in the YAML file and re-run."))
      } 
      
      
      if (length(pg_id) > 0)
      {
        
        ## we might or might not have found something... we plot it anyways, so the user can be sure that we searched for it
        
        ## find peptides which only have one group (ignoring razor peptides where we cannot be sure)
        evd_uniqueGroup = !grepl(";", d_evd$protein.group.ids)
        ## do not trust MBR here. We want real evidence!
        evd_realMS = !grepl("MATCH", d_evd$type)
        ## for each Raw file: find unique peptides of our contaminant
        cont_data.l = dlply(d_evd[evd_uniqueGroup & evd_realMS, 
                                c("score", "intensity", "fc.raw.file", "protein.group.ids")],
                          "fc.raw.file",
                          function(x) {
          if (length(grep(";", x$protein.group.ids))) stop("more than one proteinGroup for supposedly unique peptide...")
          
          x$idx_cont = x$protein.group.ids %in% pg_id
          
          sc = sum(x$idx_cont) / nrow(x) * 100
          int = sum(as.numeric(x$intensity[x$idx_cont]), na.rm = TRUE) / sum(as.numeric(x$intensity), na.rm = TRUE) * 100
          
          above.thresh = (sc > ca_thresh) | (int > ca_thresh)
          cont_scoreECDF = ddply(x, "idx_cont", function(xx) {
            if (length(unique(xx$score)) < 2) return(NULL) ## not enough data for ECDF
            r = getECDF(xx$score)
            r$condition = c("sample", "contaminant")[xx$idx_cont[1]+1]
            return(r)
          })
          if (!any(x$idx_cont)){
            ks_p = NA
          } else { ## no contaminant peptide 
            ks_p = suppressWarnings(  ## brags about '-value will be approximate in the presence of ties'
                      ks.test(x$score[x$idx_cont], x$score[!x$idx_cont], alternative = "greater")$p.value
                   )
          }
          return (list(cont_data = data.frame(spectralCount = sc, intensity = int,
                                              above.thresh = above.thresh, fc.raw.file = x$fc.raw.file[1],
                                              score_KS = ks_p),
                       cont_scoreECDF = cont_scoreECDF))
        })
        head(cont_data.l)
        
        ## melt
        cont_data = ldply(cont_data.l, function(l) { l$cont_data })
        cont_data.long = melt(cont_data, id.vars="fc.raw.file")
        
        not_found = all(cont_data.long$value[cont_data.long$variable == "above.thresh"] == FALSE)
      }
      
      if (not_found)
      { ## identifier was not found in any sample
        pl_cont = ggText("PG: Contaminants",
                         paste0("Contaminant '", ca, "' was not found in any sample.\n\nDid you use the correct database?"),
                         "red")
        rep_data$add(pl_cont)
      } else {
        ## plot User-Contaminants
        rep_data$add(
          byXflex(data = cont_data.long, indices = cont_data.long$fc.raw.file, subset_size = 120, 
                FUN = plot_ContUser, sort_indices = FALSE, name_contaminant = ca, extra_limit = ca_thresh)
        )
        
        ## plot Andromeda score distribution of contaminant vs. sample
        llply(cont_data.l, function(l)
        {
          if (l$cont_data$above.thresh == FALSE) return(NULL)
          p = plot_ContUserScore(l$cont_scoreECDF, l$cont_data$fc.raw.file, l$cont_data$score_KS)
          rep_data$add(p)
          #print(p)
          return(NULL)
        })
        
        ## add heatmap column
        cname = paste0("X002X_catPrep_EVD:Contaminant~(", ca, ")")
        cont_data[,cname] = as.numeric(!cont_data$above.thresh) ## inverse (0 is 'bad')
        QCM[[paste0("EVD.Contaminant_",ca)]] = cont_data[, c("fc.raw.file", cname)]
        
        
        report_short = pastet("Contaminant:", ca, paste0(sum(cont_data$above.thres),"/",nrow(cont_data)," Raw files"))
        report_samples  = pastet("Contaminant-details (name, raw.file, spectralCount%): " , ca, paste(cont_data$fc.raw.file, collapse=";"), paste(cont_data$spectralCount, collapse=";"))
        report_samples2 = pastet("Contaminant-details (name, raw.file, intensity%): " , ca, paste(cont_data$fc.raw.file, collapse=";"), paste(cont_data$intensity, collapse=";"))
        cat(pasten(report_short, report_samples, report_samples2), file=fh_out$stats_file, append=TRUE, sep="\n")
        cat(pastet("contamination-proteins:", ca, paste((d_pg$majority.protein.ids[pg_id]), collapse=",")), file=fh_out$stats_file, append=TRUE, sep="\n") 
      }
      
    } ## contaminant loop
    
    ## ms.ms.count is always 0 when mtd has a number; 'type' is always "MULTI-MATCH" and ms.ms.ids is empty!
    #dsub = d_evd[,c("ms.ms.count", "match.time.difference")]
    #head(dsub[is.na(dsub[,2]),])
    #sum(0==(dsub[,1]) & is.na(dsub[,2]))
    ##
    ## MQ1.4 MTD is either: NA or a number
    ##
    
    ## intensity of peptides
    param_name_EV_intThresh = "File$Evidence$IntensityThreshLog2_num"
    param_def_EV_intThresh = 23 ## default median intensity in log2 scale
    param_EV_intThresh = getYAML(yaml_obj, param_name_EV_intThresh, param_def_EV_intThresh)
    if (!is.numeric(param_EV_intThresh) || !(param_EV_intThresh %in% 1:100))
    { ## reset if value is weird
      cat("YAML value for '" %+% param_name_EV_intThresh %+% "' is invalid ('" %+% param_EV_protThresh %+% "'). Using default of " %+% param_def_EV_intThresh %+% ".")
      param_EV_intThresh = param_def_EV_intThresh
    }
    
    colnames(d_evd)
    medians_pep = ddply(d_evd[ ,c("fc.raw.file", "intensity")], "fc.raw.file",
                        function(x) data.frame(med = log2(quantile(x$intensity, probs=0.5, na.rm = TRUE))))
    
    int_dev_pep = RSD((medians_pep$med))
    int_dev.s = pastet("INT RSD [%]", round(int_dev_pep, 3))
    lpl = boxplotCompare(data = d_evd[, c("fc.raw.file", "intensity", "contaminant")],
                         log2 = TRUE, 
                         mainlab="EVD: peptide intensity distribution",
                         ylab = expression(log[2]*" intensity"),
                         sublab=paste0("RSD ", round(int_dev_pep, 1),"% (expected < 5%)\n"),
                         abline = param_EV_intThresh)
    #for (pl in lpl) print(pl)
    for (pl in lpl) rep_data$add(pl)
    ## QC measure for peptide intensity
    qc_pepint = medians_pep
    cname = "X003X_catPrep_EVD:~Pep~Intensity~(\">" %+% param_def_EV_intThresh %+% "\")"
    qc_pepint[,cname] = qualLinThresh(2^qc_pepint$med, 2^param_def_EV_intThresh) ## use non-log space 
    QCM[["EVD.PepIntensity"]] = qc_pepint[, c("fc.raw.file", cname)]
    
    ## only count protein groups from non-inferred evidence
    # get only the column without MTDs
    #   contains NA if 'genuine' ID
    d_evd$hasMTD = !is.na(d_evd$match.time.difference)
    
    pgc = getProteinAndPeptideCounts(d_evd[, c("protein.group.ids", "fc.raw.file", "modified.sequence", "match.time.difference")])
    head(pgc)
    
    ## re-order (ddply somehow reorders, even if we use ordered factors...)
    pgc$fc.raw.file = factor(pgc$fc.raw.file, levels = mq$raw_file_mapping$to, ordered = TRUE)
    #levels(pgc$fc.raw.file)
    ## report Match-between-runs data only if if it was enabled
    reportMTD = any(d_evd$hasMTD)
    
    ## show Prot & Pep stats
    pgc$block = factor(assignBlocks(pgc$fc.raw.file, 30))
    max_prot = max(unlist(dlply(pgc, "fc.raw.file", function(x) sum(x$proteinCounts))))
    ## average gain in percent
    gain_text = ifelse(reportMTD, sprintf("MBR gain: +%.0f%%", mean(pgc$proteinMBRgain, na.rm = TRUE)), "")
    
    ## get scoring threshold (upper limit)
    param_name_EV_protThresh = "File$Evidence$ProteinCountThresh_num"
    param_def_EV_protThresh = 3500
    param_EV_protThresh = getYAML(yaml_obj, param_name_EV_protThresh, param_def_EV_protThresh)
    if (!is.numeric(param_EV_protThresh) || !(param_EV_protThresh %in% 1:1e5))
    { ## reset if value is weird
      cat("YAML value for '" %+% param_name_EV_protThresh %+% "' is invalid ('" %+% param_EV_protThresh %+% "'). Using default of " %+% param_def_EV_protThresh %+% ".")
      param_EV_protThresh = param_def_EV_protThresh
    }
    ##
    ## PROTEIN counts
    ##
    ddply(pgc, "block", .fun = function(x)
    {
      x$counts = x$proteinCounts
      p = plot_CountData(data = x, 
                         y_max = max(param_EV_protThresh, max_prot)*1.1,
                         thresh_line = param_EV_protThresh,
                         title = c("EVD: ProteinGroups count", gain_text))
      #print(p)
      rep_data$add(p)
      return (NULL)
    })
    ## QC measure for protein ID performance
    qc_protc = ddply(pgc[grep("^genuine", pgc$category), ], "fc.raw.file", function(x){data.frame(genuineAll = sum(x$proteinCounts))})
    cname = "X045X_catGen_EVD:~Prot~Count~(\">" %+% param_EV_protThresh %+% "\")"
    qc_protc[,cname] = qualLinThresh(qc_protc$genuineAll, param_EV_protThresh)
    QCM[["EVD.ProtCount"]] = qc_protc[, c("fc.raw.file", cname)]
    
    
    ##
    ## EVD: peptide count
    ##
    max_pep = max(unlist(dlply(pgc, "fc.raw.file", function(x) sum(x$peptideCounts))))
    ## average gain in percent
    gain_text = ifelse(reportMTD, sprintf("MBR gain: +%.0f%%", mean(pgc$peptideMBRgain, na.rm = TRUE)), "")
          
    ## get scoring threshold (upper limit)
    param_name_EV_pepThresh = "File$Evidence$PeptideCountThresh_num"
    param_def_EV_pepThresh = 15000
    param_EV_pepThresh = getYAML(yaml_obj, param_name_EV_pepThresh, param_def_EV_pepThresh)
    if (!is.numeric(param_EV_pepThresh) || !(param_EV_pepThresh %in% 1:1e6))
    { ## reset if value is weird
      cat("YAML value for '" %+% param_name_EV_pepThresh %+% "' is invalid ('" %+% param_EV_pepThresh %+% "'). Using default of " %+% param_def_EV_pepThresh %+% ".")
      param_EV_pepThresh = param_def_EV_pepThresh
    }
    
    #require(RColorBrewer)
    ddply(pgc, "block", .fun = function(x)
    {
      x$counts = x$peptideCounts
      p = plot_CountData(data = x, 
                         y_max = max(param_EV_pepThresh, max_pep)*1.1,
                         thresh_line = param_EV_pepThresh,
                         title = c("EVD: Peptide ID count", gain_text))
      #print(p)
      rep_data$add(p)
      return (1)
    })
    
    ## QC measure for peptide ID performance
    qc_pepc = ddply(pgc[grep("^genuine", pgc$category), ], "fc.raw.file", function(x){data.frame(genuineAll = sum(x$peptideCounts))})
    cname = "X040X_catGen_EVD:~Pep~Count~(\">" %+% param_EV_pepThresh %+% "\")"
    qc_pepc[,cname] = qualLinThresh(qc_pepc$genuineAll, param_EV_pepThresh)
    QCM[["EVD.PepCount"]] = qc_pepc[, c("fc.raw.file", cname)]
    
    ####
    #### peak length (not supported in MQ 1.0.13)
    ####
    cat("EVD: RT peak width distribution ...\n")
    
    if ("retention.length" %in% colnames(d_evd))  
    {
      ## compute some summary stats before passing data to ggplot (performance issue for large experiments) 
      d_evd.m.d = ddply(d_evd[,c("retention.time", "retention.length", "fc.raw.file")], "fc.raw.file", .fun = peakWidthOverTime)
      head(d_evd.m.d)
      ## median peak width
      d_evd.m.d_avg = ddply(d_evd[,c("retention.length","fc.raw.file")], "fc.raw.file", .fun = function(x) {
        #fcr = as.character(x$fc.raw.file[1])
        #cat(fcr)
        m = median(x$retention.length, na.rm = TRUE);
        return(data.frame(median = m))
      })
      d_evd.m.d_avg$fc.raw.file_aug = paste0(d_evd.m.d_avg$fc.raw.file, " (~", round(d_evd.m.d_avg$median, 1)," min)")
      ## augment Raw filename with avg. RT peak width
      d_evd.m.d$fc.raw.file = mapvalues(d_evd.m.d$fc.raw.file, d_evd.m.d_avg$fc.raw.file, d_evd.m.d_avg$fc.raw.file_aug)
      d_evd.m.d$block = factor(assignBlocks(d_evd.m.d$fc.raw.file, 6)) ## color set is 9, so do not increase this (6*150%)
      ## identical limits for all plots
      d_evd.xlim = range(d_evd.m.d$RT, na.rm = TRUE)
      d_evd.ylim = c(0, quantile(d_evd.m.d$peakWidth, 0.99, na.rm = TRUE)) ## ignore top peaks, since they are usually early non-peptide eluents
      
      ## plot peak width        
      for (bl in unique(d_evd.m.d$block))
      { ## needs to be within a function, otherwise rep_data$add and print() somehow have delayed eval's which confused ggplot...
        rep_data$add(plot_RTPeakWidth(data = d_evd.m.d[d_evd.m.d$block==bl,], x_lim = d_evd.xlim, y_lim = d_evd.ylim))
      }
      
      ## QC measure for reproducibility of peak shape
      ##.. create a list of distributions
      l_dists = dlply(d_evd[,c("retention.length","fc.raw.file")], "fc.raw.file", function(x) return(x$retention.length))
      qc_evd_PeakShape = qualBestKS(l_dists)
      colnames(qc_evd_PeakShape) = c("fc.raw.file", "X017X_catLC_EVD:~RT~Peak~Width")
      QCM[["EVD.PeakShape"]] = qc_evd_PeakShape
    } ## end retention length (aka peak width)
    
    ##
    ## retention time calibration (to see if window was sufficiently large)
    ## (not supported in MQ 1.0.13)  
    ## Even if MBR=off, this column always contains numbers (usually 0, or very small)
    ##
    cat("EVD: Match-between-runs ...\n")
    if ("retention.time.calibration" %in% colnames(d_evd))
    {
      ## this should enable us to decide if MBR was used (we could also look up parameters.txt -- if present)
      MBR_HAS_DATA = (sum(d_evd$type == "MULTI-MATCH") > 0)
      
      param_name_mbr = "File$Evidence$MatchBetweenRuns_wA"
      param_evd_mbr = getYAML(yaml_obj, param_name_mbr, "auto")
      if ((param_evd_mbr == FALSE) || (MBR_HAS_DATA == FALSE))
      {
        ## MBR is not evaluated
      } else
      {
        ## find reference
        if (('fraction' %in% colnames(d_evd)) && (length(unique(d_evd$fraction)) > 1)) {
          ## fractions: there must be more than one, otherwise MQ will treat the samples as unfractionated
          refRaw = NA
          col_fraction = "fraction"
          txt_subtitle = "fraction: neighbour comparison"
          evd_has_fractions = TRUE
          d_evd$fraction[is.na(d_evd$fraction)] = 32000
        } else {
          refRaw = findAlignReference(d_evd)
          col_fraction = c()
          txt_subtitle = paste("alignment reference:", refRaw)
          evd_has_fractions = FALSE
        } 
        if (length(refRaw) != 1) {
          ggText("EVD: Alignment check", paste0("Cannot find a unique reference Raw file (files: ",paste(refRaw, collapse=", "), ")"))
        } else {
          
          ## find RT curve based on genuine 3D peaks (should be flat)
          d_alignQ = alignmentCheck(d_evd[(d_evd$type %in% c("MULTI-MSMS")), 
                                          c("calibrated.retention.time", 
                                            "id", "raw.file", col_fraction, "modified.sequence", "charge")], 
                                    referenceFile = refRaw)
          ## augment more columns
          d_alignQ$retention.time.calibration = d_evd$retention.time.calibration[match(d_alignQ$id, d_evd$id)]
          
          if (nrow(d_alignQ)==0)
          { ## very unusual case: reference contains no evidence -- e.g. pull-down experiment
            rep_data$add(
              ggText("EVD: RT Distance of peptides from reference after alignment", "Alignment cannot be verfied -- no data.")
            )
          } else {
            ## filter data (reduce PDF file size)
            evd_RT_t = thinOutBatch(d_alignQ,
                                    "calibrated.retention.time",
                                    "raw.file")
            
            evd_RT_t$fc.raw.file = renameFile(evd_RT_t$raw.file, mq$raw_file_mapping)
            
            ## param
            param_name_EV_MatchingTolerance = "File$Evidence$MQpar_MatchingTimeWindow_num"
            param_def_EV_MatchingTolerance = 1
            param_EV_MatchingTolerance = getYAML(yaml_obj, param_name_EV_MatchingTolerance, param_def_EV_MatchingTolerance)
            if (param_useMQPAR) {
              v = getMQPARValue(txt_files$mqpar, "matchingTimeWindow") ## will also warn() if file is missing
              if (!is.null(v)) {
                param_EV_MatchingTolerance = setYAML(yaml_obj, param_name_EV_MatchingTolerance, as.numeric(v))
              }
            }
                       
            ## QC measure for alignment quality
            ## compute % of matches within matching boundary (1 min by default)
            qcAlign = ScoreInAlignWindow(d_alignQ, param_EV_MatchingTolerance)
            if (!is.na(refRaw)) { ## rescue reference file (it will not show up in fraction-less data, and would otherwise be scored 'red')
              qcAlign = rbind(qcAlign, data.frame(raw.file=refRaw, withinRT=1))
            }
            cname = "X021X_catLC_EVD:~MBR~Align"
            qcAlign[, cname] = qcAlign$withinRT
            QCM[["EVD.MBR_Align"]] = qcAlign[, c("raw.file", cname)]
            
            qcAlign$fc.raw.file = renameFile(qcAlign$raw.file, mq$raw_file_mapping)
            qcAlign$newlabel = qcAlign$fc.raw.file
            if (evd_has_fractions)
            { ## amend fc.raw.file with fraction number
              qcAlign$fraction = d_evd$fraction[match(qcAlign$fc.raw.file, d_evd$fc.raw.file)]
              qcAlign$newlabel = paste0(qcAlign$fc.raw.file, " - frc", qcAlign$fraction)
            }
            ## amend fc.raw.file with % good ID pairs
            qcAlign$newlabel = paste0(qcAlign$newlabel, " (", round(qcAlign$withinRT*100), "% good)")
            evd_RT_t$fc.raw.file_ext = mapvalues(evd_RT_t$fc.raw.file, qcAlign$fc.raw.file, qcAlign$newlabel)

            evd_RT_t$RTdiff_in = c("green", "red")[(abs(evd_RT_t$rtdiff) > param_EV_MatchingTolerance)+1]
            
            ## plot alignment result
            y_lim = quantile(c(evd_RT_t$rtdiff, evd_RT_t$retention.time.calibration), probs = c(0.01,0.99), na.rm = TRUE) * 1.1
            rep_data$add(
              byX(evd_RT_t, evd_RT_t$fc.raw.file, 3*3, plot_MBRAlign, sort_indices = FALSE, 
                  y_lim = y_lim, title_sub = txt_subtitle, match_tol = param_EV_MatchingTolerance)
            )

            ## save some memory
            if (!exists("DEBUG_PTXQC")) {
              rm("evd_RT_t")
              rm("proj_align_h")
            }
          } ## no data
        } ## ambigous reference file

### 
###     MBR: ID transfer
###

        ## increase of segmentation by MBR:
        ## three values returned: single peaks(%) in genuine, transferred and all(combined)
        qMBR = peakSegmentation(d_evd)
        head(qMBR)
        ## for groups: get their RT-spans
        ## ... genuine ID's only (as 'rtdiff_genuine') 
        ##  or genuine+transferred (as 'rtdiff_mixed'))
        ## Could be empty (i.e. no groups, just singlets) if data is really sparse ..
        qMBRSeg_Dist = idTransferCheck(d_evd)
        #head(qMBRSeg_Dist)
        #head(qMBRSeg_Dist[qMBRSeg_Dist$fc.raw.file=="file 13",])
        

        ## Check which fraction of ID-pairs belong to the 'in-width' group.
        ## The allowed RT delta is given in 'd_evd.m.d_med' (estimated from global peak width for each file)
        qMBRSeg_Dist_inGroup = inMatchWindow(qMBRSeg_Dist, df.allowed.deltaRT = d_evd.m.d_avg)
        ## puzzle together final picture
        scoreMBRMatch = computeMatchRTFractions(qMBR, qMBRSeg_Dist_inGroup)
        #head(scoreMBRMatch)
        #scoreMBRMatch[scoreMBRMatch$fc.raw.file=="file 3",]
        
        qualMBR.m = merge(scoreMBRMatch[scoreMBRMatch$sample=="genuine",], 
                          scoreMBRMatch[scoreMBRMatch$sample=="transferred",], by="fc.raw.file")
        qualMBR.m = merge(qualMBR.m, scoreMBRMatch[scoreMBRMatch$sample=="all",], by="fc.raw.file")
        cname = "X022X_catLC_EVD:~MBR~ID-Transfer"
        qualMBR.m[, cname] = 1 - qualMBR.m$multi.outRT.y # could be NaN if: no-transfer at all, or: no groups but only singlets transferred
        qualMBR.m[is.na(qualMBR.m$multi.outRT.y) & !is.na(qualMBR.m$single.y), cname] = 1 ## only singlets transferred, wow...
        qualMBR.m[is.na(qualMBR.m[, cname]), cname] = HEATMAP_NA_VALUE
        QCM[["EVD.MBR_IDTransfer"]] = qualMBR.m[, c("fc.raw.file", cname)]
        QCM[["EVD.MBR_IDTransfer"]]
       
        ## plot ID-transfer
        rep_data$add(
          byX(scoreMBRMatch, scoreMBRMatch$fc.raw.file, 12, plot_MBRIDtransfer, sort_indices = FALSE)
        )
        
        ##
        ## MBR: Tree Clustering (experimental)
        ##
        rep_data$add(
        #print(  
          RTalignmentTree(d_evd[(d_evd$type %in% c("MULTI-MSMS")), 
                                c("calibrated.retention.time", "fc.raw.file", col_fraction, "modified.sequence", "charge")],
                          col_fraction = col_fraction)
        )
        
        ##
        ## MBR: additional evidence by matching MS1 by AMT across files
        ##
        if (any(!is.na(d_evd$match.time.difference))) {
          ## gain for each raw file: absolute gain, and percent gain
          mtr.df = ddply(d_evd, "fc.raw.file", function(x) {
            match_count_abs = sum(!is.na(x$match.time.difference))
            match_count_pc  = round(100*match_count_abs/(nrow(x)-match_count_abs)) ## newIDs / oldIDs
            return (data.frame(abs = match_count_abs, pc = match_count_pc))
          })
          rep_data$add(
            plot_MBRgain(data = mtr.df, title_sub = gain_text)
          )
        }
      
      } ## MBR has data

    } ## retention.time.difference column exists
    
    
    ##
    ## charge distribution
    ##
    ##  (this uses genuine peptides only -- no MBR!)
    ## 
    d_charge = mosaicize(d_evd[!d_evd$hasMTD, c("fc.raw.file", "charge")])
    rep_data$add(
      byXflex(d_charge, d_charge$Var1, 30, plot_Charge, sort_indices = FALSE)
    )
    
    ## QC measure for charge centeredness
    qc_charge = ddply(d_evd[!d_evd$hasMTD, c("charge",  "raw.file")], "raw.file", function(x) data.frame(c = (sum(x$charge==2)/nrow(x))))
    cname = "X010X_catPrep_EVD:~Charge"
    qc_charge[, cname] = qualMedianDist(qc_charge$c)
    QCM[["EVD.charge2"]] = qc_charge[, c("raw.file", cname)]
    
    ##
    ## peptides per RT
    ##
    cat("EVD: Peptides over RT ...\n")
    raws_perPlot = 6
    
    rt_range = range(d_evd$retention.time, na.rm = TRUE)
    df_idRT = ddply(d_evd, "fc.raw.file", function(x) {
      h = hist(x$retention.time, breaks=seq(from=rt_range[1]-3, to=rt_range[2]+3, by=3), plot = FALSE)
      return(data.frame(RT = h$mid, counts = h$counts))
    })
    rep_data$add(
      byXflex(df_idRT, df_idRT$fc.raw.file, raws_perPlot, plot_IDsOverRT, sort_indices = FALSE)
    )
    
    ## QC measure for uniform-ness
    QCM[["ID_rate_over_RT"]] = ddply(d_evd[, c("retention.time",  "raw.file")], "raw.file", 
                                     function(x) data.frame("X015X_catLC_EVD:~ID~rate~over~RT" = qualUniform(x$retention.time), 
                                                            check.names = FALSE))
    
          
    ##
    ## barplots of mass error
    ##
    cat("EVD: Precursor Mass Error ...\n")
    
    ## MQ seems to mess up mass recal on some (iTRAQ/TMT) samples, by reporting ppm errors which include modifications
    ## , thus one sees >1e5 ppm, e.g. 144.10 Da
    ##  this affects both 'uncalibrated.mass.error..ppm.'   and
    ##                    'mass.error..ppm.'
    ## HOWEVER, 'uncalibrated...calibrated.m.z..ppm.' seems unaffected, but is not available in all MQ versions :(
    ##    also, 'mass' and 'm/z' columns seem unaffected.
    ## We cannot always reconstruct mass_error[ppm] from 'm/z' and mass columns 
    ## since 'm/z' is just too close to the theoretical value or islacking precision of the stored numbers.
    ##
    ## The MQ list reports one case with high ppm error (8000), where the KR.count was at fault. We cannot
    ## reconstruct this.
    ##
    ## Also, MaxQuant will not report uncalibrated mass errors if the data are too sparse for a given Raw file.
    ## Then, 'uncalibrated.mass.error..ppm.' will be 'NaN' throughout -- but weirdly, calibrated masses will be reported.
    ##
    
    param_name_EV_PrecursorTolPPM = "File$Evidence$MQpar_firstSearchTol_num"
    param_def_EV_PrecursorTolPPM = 20
    param_EV_PrecursorTolPPM = getYAML(yaml_obj, param_name_EV_PrecursorTolPPM, param_def_EV_PrecursorTolPPM)
    if (param_useMQPAR) {
      v = getMQPARValue(txt_files$mqpar, "firstSearchTol") ## will also warn() if file is missing
      if (!is.null(v)) {
        param_EV_PrecursorTolPPM = setYAML(yaml_obj, param_name_EV_PrecursorTolPPM, as.numeric(v))
      }
    }
    
    param_name_EV_PrecursorOutOfCalSD = "File$Evidence$firstSearch_outOfCalWarnSD_num"
    param_def_EV_PrecursorOutOfCalSD = 2
    param_EV_PrecursorOutOfCalSD = getYAML(yaml_obj, param_name_EV_PrecursorOutOfCalSD, param_def_EV_PrecursorOutOfCalSD)
    
    ##
    ## check for MS1-out-of-calibration (i.e. the tol-window being too small)
    ##
    ## heuristic to determine if the instrument is completely out of calibration, 
    ## i.e. all ID's are false positives, since the Precursor mass is wrong
    ## -- we use the SD; if larger than 2ppm, 
    ## then ID's are supposedly random
    ## -- alt: we use the 1%-to-99% quantile range: if > 10ppm
    ## -- uninformative for detection is the distribution (it's still Gaussian for a strange reason)
    MS1_decal_smr = ddply(d_evd, "fc.raw.file", function(x) 
      data.frame(n = nrow(x), 
                 sd = round(sd(x$mass.error..ppm., na.rm = TRUE), 1), 
                 range = diff(quantile(x$mass.error..ppm., c(0.01, 0.99), na.rm = TRUE))))
    ## additionally use MS2-ID rate (should be below 1%)
    if (enabled_summary) {
      MS1_decal_smr = merge(MS1_decal_smr, d_smy$raw[, c("fc.raw.file", "ms.ms.identified....")])
    } else {
      MS1_decal_smr$ms.ms.identified.... = 0 ## upon no info: assume low IDrate
    }
    
    MS1_decal_smr$lowIDRate = MS1_decal_smr$ms.ms.identified.... < 1
    MS1_decal_smr$hasMassErrorBug = FALSE
    MS1_decal_smr$hasMassErrorBug_unfixable = FALSE
    recal_message = ""
    recal_message_post = ""
    ## check each raw file individually (usually its just a few who are affected)
    de_cal = ddply(d_evd, "fc.raw.file", .fun = function(x) data.frame(q = (quantile(abs(x$uncalibrated.mass.error..ppm.), probs = 0.5, na.rm = TRUE) > 1e3)))
    if (any(de_cal$q, na.rm = TRUE))
    {
      recal_message = "MQ bug: data rescued"
      recal_message_post = 'MQ bug: data cannot be rescued'
      
      MS1_decal_smr$hasMassErrorBug[ MS1_decal_smr$fc.raw.file %in% de_cal$fc.raw.file[de_cal$q > 0] ] = TRUE
      
      ## re-compute 'uncalibrated.mass.error..ppm.' and 'mass.error..ppm.'
      d_evd$theomz = d_evd$mass / d_evd$charge + 1.00726
      d_evd$mass.error..ppm.2 = (d_evd$theomz - d_evd$m.z) / d_evd$theomz * 1e6
      d_evd$uncalibrated.mass.error..ppm.2 = d_evd$mass.error..ppm.2 + d_evd$uncalibrated...calibrated.m.z..ppm.
    
      
      ## check if fix worked
      de_cal2 = ddply(d_evd, "raw.file", .fun = function(x)  data.frame(q = (median(abs(x$uncalibrated.mass.error..ppm.2), na.rm = TRUE) > 1e3)))
      if (any(de_cal2$q, na.rm = TRUE))
      { ## fix did not work
        MS1_decal_smr$hasMassErrorBug_unfixable[ MS1_decal_smr$fc.raw.file %in% de_cal2$fc.raw.file[de_cal2$q] ] = TRUE
        recal_message = "m/z recalibration bugfix applied but failed\n(there are still large numbers)"
      }
      
      idx_overwrite = (d_evd$fc.raw.file %in% de_cal$fc.raw.file[de_cal$q > 0])
      ## overwrite original values
      d_evd$mass.error..ppm.[idx_overwrite] = d_evd$mass.error..ppm.2[idx_overwrite]
      d_evd$uncalibrated.mass.error..ppm.[idx_overwrite] = d_evd$uncalibrated.mass.error..ppm.2[idx_overwrite]
    }
    
    MS1_decal_smr$outOfCal = (MS1_decal_smr$sd > param_EV_PrecursorOutOfCalSD) & MS1_decal_smr$lowIDRate & 
                             (MS1_decal_smr$sd < 100)  ## upper bound, to distinguish from MQ bug (which has much larger SD's)
    
    ## report too small search tolerance
    if (any(MS1_decal_smr$outOfCal)) recal_message = "search tolerance too small"
    
    
    ## Raw files where the mass error is obviously wrong (PSM's not substracted etc...)
    affected_raw_files = MS1_decal_smr$fc.raw.file[MS1_decal_smr$outOfCal | MS1_decal_smr$hasMassErrorBug]
    ## some outliers can have ~5000ppm, blowing up the plot margins
    ## --> remove outliers 
    ylim_g = range(boxplot.stats(d_evd$uncalibrated.mass.error..ppm.)$stats[c(1, 5)], c(-param_EV_PrecursorTolPPM, param_EV_PrecursorTolPPM) * 1.05)
    ## PLOT
    rep_data$add(
      byXflex(d_evd, d_evd$fc.raw.file, 20, plot_UncalibratedMSErr, sort_indices = FALSE, 
              MQBug_raw_files = affected_raw_files, 
              y_lim = ylim_g,
              stats = MS1_decal_smr,
              extra_limit = param_EV_PrecursorTolPPM,
              title_sub = recal_message)
    )
    
    ## scores
    qc_MS1deCal = ddply(d_evd[, c("uncalibrated.mass.error..ppm.", "fc.raw.file")], "fc.raw.file", 
                        function(x) {
                          xd = na.omit(x$uncalibrated.mass.error..ppm.)
                          if (length(xd)==0) {
                            r = HEATMAP_NA_VALUE ## if empty, give the Raw file an 'NA' score
                          } else if (MS1_decal_smr$outOfCal[MS1_decal_smr$fc.raw.file == x$fc.raw.file[1]]) {
                            r = 0 ## if we suspect out-of-calibration, give lowest score
                          } else r = qualCenteredRef(xd, param_EV_PrecursorTolPPM)
                          return (data.frame(med_rat = r))
                        })
    
    colnames(qc_MS1deCal) = c("fc.raw.file", "X026X_catMS_EVD:~MS~Cal-Pre~(" %+% param_EV_PrecursorTolPPM %+% ")")
    QCM[["X026X.EVD.MS_Cal-Pre"]] = qc_MS1deCal
    
    
    ##
    ## post calibration
    ##
    cat("EVD: Precursor Mass Error (post calibration) ...\n")
    
    param_name_EV_PrecursorTolPPMmainSearch = "File$Evidence$MQpar_mainSearchTol_num"
    param_def_EV_PrecursorTolPPMmainSearch = NA  ## we do not dare to have a default, since it ranges from 6 - 4.5 ppm across MQ versions
    param_EV_PrecursorTolPPMmainSearch = getYAML(yaml_obj, param_name_EV_PrecursorTolPPMmainSearch, param_def_EV_PrecursorTolPPMmainSearch)
    if (param_useMQPAR) {
      v = getMQPARValue(txt_files$mqpar, "mainSearchTol") ## will also warn() if file is missing
      if (!is.null(v)) {
        param_EV_PrecursorTolPPMmainSearch = setYAML(yaml_obj, param_name_EV_PrecursorTolPPMmainSearch, as.numeric(v))
      }
    }
    if (is.na(param_EV_PrecursorTolPPMmainSearch))
    {
      warning("PTXQC: Cannot draw borders for calibrated mass error, since neither 'File$Evidence$MQpar_mainSearchTol_num' is set nor a mqpar.xml file is present!", immediate. = TRUE)
    }
    
    ylim_g = range(na.rm = TRUE, boxplot.stats(d_evd$mass.error..ppm.)$stats[c(1, 5)], c(-param_EV_PrecursorTolPPMmainSearch, param_EV_PrecursorTolPPMmainSearch) * 1.05)
    ## PLOT
    rep_data$add(
      byXflex(d_evd, d_evd$fc.raw.file, 20, plot_CalibratedMSErr, sort_indices = FALSE,
              MQBug_raw_files = affected_raw_files,
              y_lim = ylim_g,
              stats = MS1_decal_smr,
              extra_limit = param_EV_PrecursorTolPPMmainSearch,
              title_sub = recal_message_post
              )
    )
    
    ## QC measure for post-calibration ppm error
    ## .. assume 0 centered and StdDev of observed data
    obs_par = ddply(d_evd[, c("mass.error..ppm.", "fc.raw.file")], "fc.raw.file", 
                    function(x) data.frame(mu = mean(x$mass.error..ppm., na.rm = TRUE), sd = sd(x$mass.error..ppm., na.rm = TRUE)))
    qc_MS1Cal = data.frame(fc.raw.file = obs_par$fc.raw.file, 
                           val = sapply(1:nrow(obs_par), function(x) qualGaussDev(obs_par$mu[x], obs_par$sd[x])))
    ## if we suspect out-of-calibration, give lowest score
    qc_MS1Cal$val[qc_MS1Cal$fc.raw.file %in% MS1_decal_smr$fc.raw.file[ MS1_decal_smr$outOfCal ]] = 0 
    ## MQ mass bugfix will not work for postCalibration, since values are always too low
    qc_MS1Cal$val[qc_MS1Cal$fc.raw.file %in% MS1_decal_smr$fc.raw.file[ MS1_decal_smr$hasMassErrorBug ]] = HEATMAP_NA_VALUE
    cname = "X027X_catMS_EVD:~MS~Cal-Post"
    colnames(qc_MS1Cal)[colnames(qc_MS1Cal) == "val"] = cname
    QCM[["X027X.EVD.MS_Cal-Post"]] = qc_MS1Cal
    
    
    
    
    ## compute how well calibration worked
    cal_medians = as.vector(by(d_evd$mass.error..ppm., d_evd$raw.file, median, na.rm = TRUE))
    cal_stats = quantile(cal_medians, probs=c(0,0.5,1))
    cat(pastet("medianCalibratedMassError(min,median,max) [ppm]", paste(cal_stats, collapse=",")), file=fh_out$stats_file, append = TRUE, sep="\n") 
    
    ##
    ## elaborate contaminant fraction per Raw.file (this is not possible from PG, since raw files could be merged)
    ## find top 5 contaminants (globally)
    ##
    cat("EVD: Contaminants per Raw file ...\n")
    
    
    ## if possible, work on protein names (since MQ1.4), else use proteinIDs
    if ("protein.names" %in% colnames(d_evd))
    {
      evd_pname = "protein.names"        
    } else {
      evd_pname = "proteins" 
    }
    ## protein.names are sometimes not unique, e.g. if a contaminant is involved:
    ## "P02768;CON__P02768-1" and "P02768" will both give the same name (since contaminant name is empty)
    ## Thus, the distribution of bars will look slightly different (but summed percentages are identical)
    
    ## some protein.names are empty (usually the CON__ ones) ... so we substitute with ID
    d_evd$pname = d_evd[, evd_pname];
    d_evd$pname[d_evd$pname==""] = d_evd$proteins[d_evd$pname==""] ## a NOP if it already is 'proteins', but ok
    
    d_evd.totalInt = sum(as.numeric(d_evd$intensity), na.rm = TRUE)
    d_evd.cont.only = d_evd[d_evd$contaminant,]
    cont.top = by(d_evd.cont.only, d_evd.cont.only$pname, function(x) sum(as.numeric(x$intensity), na.rm = TRUE) / d_evd.totalInt*100)
    cont.top.sort = sort(cont.top, decreasing = TRUE)
    #head(cont.top.sort)
    cont.top5.names = names(cont.top.sort)[1:5]
    
    
    if (is.null(cont.top5.names))
    {
      pl_cont = ggText("EVD: Contaminant per Raw file",
                       paste0("No contaminants found in any sample.\n\nIncorporating contaminants during search is highly recommended!"),
                       "red")
      rep_data$add(pl_cont)  
    } else {
      rep_data$add(
        byXflex(d_evd[, c("intensity", "pname", "fc.raw.file", "contaminant")], d_evd$fc.raw.file, 40, sort_indices = FALSE, 
                plot_ContEVD, top5=cont.top5.names)
      )
    }
    
    ## QC measure for contamination
    qc_contaminants = ddply(d_evd[, c("intensity", "contaminant", "fc.raw.file")], "fc.raw.file", 
                            function(x) {
                              v = ifelse(is.null(cont.top5.names), 
                                         HEATMAP_NA_VALUE, ## use NA in heatmap if there are no contaminants
                                         1-qualLinThresh(sum(as.numeric(x$intensity[x$contaminant]), na.rm = TRUE)/
                                                           sum(as.numeric(x$intensity), na.rm = TRUE)))
                              data.frame("X001X_catPrep_EVD:~Contaminants" = v, check.names = FALSE)})
    QCM[["EVD.Contaminants"]] = qc_contaminants

    ##
    ## Oversampling: determine peaks repeatedly sequenced
    ##
    cat("EVD: MS2 oversampling ...\n")
    
    d_dups = ddply(d_evd, "fc.raw.file", function(x) {
      tt = as.data.frame(table(x$ms.ms.count), stringsAsFactors = FALSE)
      tt$Count = as.numeric(tt$Var1)
      ## remove "0", since this would be MBR-features
      tt = tt[tt$Count!=0,]
      ## summarize everything above 3 counts
      if (any(tt$Count >= 3)) {
        tt$Count[tt$Count >= 3] = "3+"
        tt = ddply(tt, "Count", function(x) data.frame(Freq=sum(x$Freq)))
      }
      ## make counts relative
      fraction = tt$Freq / sum(tt$Freq) * 100
      return (data.frame(n=as.character(tt$Count), fraction = fraction))
    })
    
    rep_data$add(
      byXflex(d_dups, d_dups$fc.raw.file, 30, plot_MS2Oversampling, sort_indices = FALSE)
    )
    ## QC measure for centered-ness of MS2-calibration
    qc_evd_twin = d_dups[d_dups$n==1,]
    cname = "X025X_catMS_EVD:~MS^2~Oversampling"
    qc_evd_twin[, cname] = qualLinThresh(qc_evd_twin$fraction/100)
    QCM[["EVD.Oversampling"]] = qc_evd_twin[, c("fc.raw.file", cname)]
    
    ## trim down to the absolute required (we need to identify contaminants in MSMS.txt later on)
    if (!exists("DEBUG_PTXQC")) d_evd = d_evd[, c("id", "contaminant")]
    
}


######
######  msms.txt ...
######

enabled_msms = getYAML(yaml_obj, "File$MsMs$enabled", TRUE)
if (enabled_msms)
{
  ### missed cleavages (again)
  ### this is the real missed cleavages estimate ... but slow
  #d_msms_s = mq$readMQ(txt_files$msms, type="msms", filter = "", nrows=10)
  #colnames(d_msms_s)
  #head(d_msms)
  d_msms = mq$readMQ(txt_files$msms, type="msms", filter = "", col_subset=c("Missed\\.cleavages", "^Raw.file$", "^mass.deviations", "^masses$", "^mass.analyzer$", "fragmentation", "reverse", "^evidence.id$"), check_invalid_lines = FALSE)
  
  d_msms = d_msms[order(match(as.character(d_msms$fc.raw.file), mq$raw_file_mapping$to)),]
  ## sort fc.raw.file's factor values as well
  d_msms$fc.raw.file = factor(d_msms$fc.raw.file, levels = mq$raw_file_mapping$to, ordered = TRUE)
  
  ##
  ##  MS2 fragment decalibration
  ##
  cat("MSMS: MS2 fragment decalibration ...\n")
  ## older MQ versions do not have 'mass.analyzer' or 'mass.deviations..ppm.'
  ## , so we use fragmentation instead (this is a little risky, since you could to CID fragmentation and forward to Orbi, but hey...)
  if (!("mass.analyzer" %in% colnames(d_msms))) d_msms$mass.analyzer = d_msms$fragmentation
  
  
  ms2_decal = ddply(d_msms, c("fc.raw.file", "mass.analyzer"), .fun = function(x) {
    idx_nr = which(!x$reverse)
    ## select a representative subset, otherwise the number of datapoints is just too large
    idx_nr_subset = idx_nr[seq(1,length(idx_nr), by=ceiling(length(idx_nr)/1000))]
    df.ms = getFragmentErrors(x[idx_nr_subset,])
    df.ms$type="forward"
    
    if (any(x$reverse))
    {
      idx_nr = which(x$reverse)
      ## select a representative subset, otherwise the number of datapoints is just too large
      idx_nr_subset = idx_nr[seq(1,length(idx_nr), by=ceiling(length(idx_nr)/1000))]
      df.ms_r = getFragmentErrors(x[idx_nr_subset,])
      df.ms_r$type="decoy"
      
      ## only merge if we have hits (reverse hits might be few and $mass.deviations..da. might be empty)
      if (nrow(df.ms_r)) df.ms = rbind(df.ms, df.ms_r)
    }
    
    return (df.ms)
  })
  
  head(ms2_decal)
  class(ms2_decal$msErr)
  ms2_decal$msErr = as.numeric(as.character(ms2_decal$msErr))
  #ms2_range = diff(range(ms2_decal$msErr, na.rm = TRUE))
  #ms2_binwidth = ms2_range/20
  ## precision (plotting is just so much quicker, despite using a fixed binwidth)
  #ms2_decal$msErr = round(ms2_decal$msErr, digits=ceiling(-log10(ms2_binwidth)+1))
  tail(ms2_decal)
  ms2_decal$file = paste(ms2_decal$fc.raw.file, paste(ms2_decal$mass.analyzer, ms2_decal$unit), sep="\n")
  
  ## separate plots for each mass analyzer, since we want to keep 'fixed' scales for all raw.files (comparability)
  ddply(ms2_decal, "mass.analyzer", function(ms2_decal) {
    rep_data$add(
      byXflex(ms2_decal, ms2_decal$fc.raw.file, 9, plot_MS2Decal, sort_indices = FALSE)
    )
    return(1)
    })
  
  ##
  ## QC measure for centered-ness of MS2-calibration
  ##
  head(ms2_decal)
  for (analyzer in unique(ms2_decal$mass.analyzer)) {
    qc_name = paste0("X028X_catMS_", "MSMS:~MS^2~Cal~(", analyzer, ")")
    qc_MS2_decal = ddply(ms2_decal[ms2_decal$mass.analyzer==analyzer, ], "fc.raw.file", 
                         function(x)
                         {
                           xx = na.omit(x$msErr);
                           data.frame(X1 = qualCentered(xx), check.names = FALSE)
                         })
    ## augment fragmentation methods with -Inf for missing raw files (otherwise they would become 'red'=fail)
    if (length( setdiff(mq$raw_file_mapping$to, qc_MS2_decal$fc.raw.file) )) {
      frag_missing = data.frame(fc.raw.file = setdiff(mq$raw_file_mapping$to, qc_MS2_decal$fc.raw.file), X1=-Inf)
      qc_MS2_decal = rbind(qc_MS2_decal, frag_missing)
    }
    colnames(qc_MS2_decal)[colnames(qc_MS2_decal)=="X1"] = qc_name
    QCM[[qc_name]] = qc_MS2_decal[, c("fc.raw.file", qc_name)]
  }
  if (!exists("DEBUG_PTXQC")) rm("ms2_decal")
  
  ##
  ## missed cleavages per Raw file
  ##
  cat("MSMS: missed cleavages per Raw file ...\n")
  
  max_mc = max(-Inf, d_msms$missed.cleavages, na.rm = TRUE) ## will be -Inf iff enzyme was not specified and columns is 100% NA
  if (!is.infinite(max_mc))
  { ## MC's require an enzyme to be set
    ## remove contaminants
    msg_cont_removed = "(includes contaminants -- no evidence.txt read)"
    if (exists("d_evd")) {
      msg_cont_removed = "(excludes contaminants)"
      d_msms$contaminant = d_evd$contaminant[match(d_msms$evidence.id, d_evd$id)]
      summary(d_msms$contaminant)
    }
    
    st_bin = ddply(d_msms[!d_msms$contaminant, c("missed.cleavages", "fc.raw.file")], "fc.raw.file", .fun = function(x) {
      t = table(x$missed.cleavages)/nrow(x)
      r = rep(0, max_mc + 1)
      names(r) = as.character(0:max_mc)
      r[names(t)] = t
      return (r)
    })
    rep_data$add(
      byXflex(st_bin, st_bin$fc.raw.file, 25, plot_MissedCleavages, title_sub = msg_cont_removed, sort_indices = FALSE)
    )
    
    mcZero = st_bin[, "0"] * 100
    mcZero_stat = 100 - rev(quantile(mcZero, probs=c(0,0.5,1)))
    cat(pastet("missedCleavages>0 (min,median,max) [%]", paste0(mcZero_stat, collapse=",")), file=fh_out$stats_file, append = TRUE, sep="\n")
    
    ## QC measure for missed-cleavages variation
    qc_mc = data.frame(fc.raw.file = st_bin$fc.raw.file, XXX = st_bin[, "0"], check.names = FALSE)
    cname = "X004X_catPrep_MSMS:~MC"
    colnames(qc_mc)[grep("XXX", colnames(qc_mc))] = cname
    QCM[["MSMS.MC"]] = qc_mc
    qc_mc$"X007X_catPrep_MSMS:~MC~Var" = qualMedianDist(qc_mc[, cname])
    QCM[["MSMS.MC_Var"]] = qc_mc
    
    
  } ## end MC check
  
  
  if (!exists("DEBUG_PTXQC")) rm("d_msms")
}

######
######  msmsScans.txt ...
######

enabled_msmsscans = getYAML(yaml_obj, "File$MsMsScans$enabled", TRUE)
if (enabled_msmsscans)
{
  #d_msmsScan_h = mq$readMQ(txt_files$msmsScan, type="msms", filter = "", nrows=2)
  #colnames(d_msmsScan_h)
  #head(d_msmsScan_h)
  d_msmsScan = mq$readMQ(txt_files$msmsScan, type = "msms", filter = "", 
                         col_subset = c("^ion.injection.time", 
                                        "^retention.time$", 
                                        "^Identified", 
                                        "^Scan.event.number", 
                                        "^Raw.file"),
                         check_invalid_lines = FALSE)
  ##
  ## MQ version 1.0.13 has very rudimentary MSMSscans.txt, with no header, so we need to skip the metrics of this file
  ##
  if (ncol(d_msmsScan) > 3)
  {
    #colnames(d_msmsScan)
    #head(d_msmsScan)
    #unique(d_msmsScan$Identified)
    
    d_msmsScan = d_msmsScan[order(match(d_msmsScan$fc.raw.file, mq$raw_file_mapping$to)),]
    ## sort fc.raw.file's factor values as well
    d_msmsScan$fc.raw.file = factor(d_msmsScan$fc.raw.file, levels = mq$raw_file_mapping$to, ordered = TRUE)
    
    # round RT to 2 min intervals
    d_msmsScan$rRT = round(d_msmsScan$retention.time/2)*2
    
    ##
    ## TopN over RT
    ##
    cat("MSMS-Scans: TopN over RT ...\n")
    
    ## maximum scan event over time
    scan.event.number = NULL ## make R check happy
    DFmse = ddply(d_msmsScan, c("fc.raw.file"), function(x) {
      ## sort by RT
      if (is.unsorted(x$retention.time))
      { ## should not happen, but just to make sure
        x = x[, order(x$retention.time)]
      }
      ## only take the highest scan event (SE) in a series
      maxN = getMaxima(x$scan.event.number, thresh_rel = 0.0)
      df.max = x[maxN,]
      ## use median of that within one RT bin
      meanN = ddply(df.max, c("rRT"), summarise, topN = median(scan.event.number))
      return (meanN)    
    })
    
    head(DFmse)
    rep_data$add(
      byXflex(DFmse, DFmse$fc.raw.file, 6, plot_TopNoverRT, sort_indices = FALSE)
    )
    
    ## QC measure for smoothness of TopN over RT
    qc_TopNRT = ddply(DFmse, "fc.raw.file", function(x) data.frame("X012X_catLC_MS^2*Scans:~TopN~over~RT" = qualUniform(x$topN), check.names = FALSE))
    QCM[["MSMSscans.TopN_over_RT"]] = qc_TopNRT
    
    ##
    ## Injection time over RT
    ##
    cat("MSMS-Scans: Injection time over RT ...\n")
    
    param_name_MSMSScans_ionInjThresh = "File$MsMsScans$IonInjectionThresh_num"
    param_def_MSMSScans_ionInjThresh = 10 ## default ion injection threshold in milliseconds
    param_MSMSScans_ionInjThresh = getYAML(yaml_obj, param_name_MSMSScans_ionInjThresh, param_def_MSMSScans_ionInjThresh)
    if (!is.numeric(param_MSMSScans_ionInjThresh))
    { ## reset if value is weird
      cat("YAML value for '" %+% param_name_MSMSScans_ionInjThresh %+% "' is invalid ('" %+% param_MSMSScans_ionInjThresh %+% "'). Using default of " %+% param_def_MSMSScans_ionInjThresh %+% ".")
      param_MSMSScans_ionInjThresh = param_def_MSMSScans_ionInjThresh
    }
    
    ## average injection time over RT
    DFmIIT = ddply(d_msmsScan, c("fc.raw.file"), function(x) {
      meanN = ddply(x, c("rRT"), function(x) data.frame(medIIT = median(x$ion.injection.time)))
      return (meanN) 
    })
    head(DFmIIT)
    ## average injection time overall
    DFmIITglob = ddply(d_msmsScan, c("fc.raw.file"), function(x) {
      return (data.frame(mean = mean(x$ion.injection.time)))
    })
    head(DFmIITglob)
    
    
    rep_data$add(
      byXflex(DFmIIT, DFmIIT$fc.raw.file, 6, plot_IonInjectionTimeOverRT, sort_indices = FALSE,
              stats = DFmIITglob,
              extra_limit = param_MSMSScans_ionInjThresh)
    )
    
    
    ## QC measure for injection times below expected threshold
    DFmIIT_belowThresh = ddply(d_msmsScan, c("fc.raw.file"), function(x) {
      return (data.frame(belowThresh_IIT = sum(x$ion.injection.time < param_MSMSScans_ionInjThresh, na.rm = TRUE) / nrow(x)))
    })
    head(DFmIIT_belowThresh)
    qc_IIT = ddply(DFmIIT_belowThresh, "fc.raw.file", function(x) data.frame("X024X_catMS_MS^2*Scans:~Ion~Inj~Time" = qualLinThresh(x$belowThresh_IIT, t = 1),
                                                                             check.names = FALSE))
    QCM[["MSMSscans.Ion_Inj_Time"]] = qc_IIT
    
    
    ##
    ## TopN counts
    ##
    cat("MSMS-Scans: scan event counts ...\n")
    
    ## check if scan.event.number requires fixing
    ## (e.g. when MS3 events are recorded between MS2 events, there are gaps in the numbering)
    ## we close the gaps by requiring consecutive scan event numbers in MS2
    scan.events = d_msmsScan[, c("scan.event.number", "fc.raw.file")]
    while(TRUE) { ## should be at most max(scan.even.number) iterations
      se_pos = 1 + which(diff(scan.events$scan.event.number) > 1) ## position of gaps>1
      if (length(se_pos) == 0) break;
      scan.events$scan.event.number[se_pos] = scan.events$scan.event.number[se_pos] - 1
    }
    DFc = ddply(scan.events, c("scan.event.number", "fc.raw.file"), summarise, n = length(scan.event.number))
    dfc.ratio = ddply(DFc, "fc.raw.file", function(x, maxn)
    {
      ## sort x by scan event
      event_count = x$n
      ## verify its monotonically increasing
      if (is.unsorted(rev(event_count))) {
        #print(x)
        stop("Scan event distribution is not monotonically increasing!")
      } 
      ## verify that there are no gaps
      if (max(x$scan.event.number) != nrow(x)) {
        #print(x)
        stop("Scan event distribution has unexpected holes...!")
      }
      
      event_pre = c(event_count[-1], 0)
      event_diff = event_count - event_pre
      
      ## build new DF of fixed length
      sn = x$scan.event.number
      if (max(sn) < maxn) 
      {
        event_diff = c(event_diff, rep(0, maxn-max(sn)))
        sn = c(sn, (max(sn)+1):maxn)
      }
      DF.new = data.frame(scan.event.number = sn, n = event_diff)
      return (DF.new)
    }, maxn = max(DFc$scan.event.number))
    head(dfc.ratio)
    
    rep_data$add(
      byXflex(dfc.ratio, dfc.ratio$fc.raw.file, 9, plot_TopN, sort_indices = FALSE)
    )
    
    ## QC measure for always reaching the maximum TopN
    maxTopN = max(dfc.ratio$scan.event.number)
    qc_TopN = ddply(dfc.ratio, "fc.raw.file", function(x) data.frame("X035X_catMS_MS^2*Scans:~TopN~high" = qualHighest(x$n, maxTopN),
                                                                     check.names = FALSE))
    QCM[["MSMSscans.TopN"]] = qc_TopN
    
    
    ##
    ## Scan event: % identified
    ##
    cat("MSMS-Scans: TopN % identified ...\n")
    
    DF = ddply(d_msmsScan, c("scan.event.number", "identified", "fc.raw.file"), summarise, n = length(scan.event.number))
    
    # try KS on underlying data instead of using qualUniform()
    #   DF2= ddply(d_msmsScan, "fc.raw.file", function(rf){
    #     cat(class(rf))
    #     cat(rf$fc.raw.file[1])
    #     idx_p = rf$identified=="+"
    #     cat(length(idx_p) %+% "\n")
    #     kk = ks.test(rf$scan.event.number[idx_p], rf$scan.event.number[-idx_p])
    #     cat(kk$p.value)
    #     kk$statistic  # = 'D' ,,  p.value is much smaller (~0)
    #   })
    #   --> fail, 'D' and p-values are too low
    df.ratio = ddply(DF, c("scan.event.number", "fc.raw.file"), function(x)
    {
      xp = xm = 0
      if ("+" %in% x$identified) xp = x$n[x$identified=="+"]
      if ("-" %in% x$identified) xm = x$n[x$identified=="-"]
      ratio = xp * 100 / sum(xp, xm)
      return (data.frame(ratio = ratio, count = sum(x$n)))
    })
    head(df.ratio)
    
    pl = byXflex(df.ratio, df.ratio$fc.raw.file, 9, plot_ScanIDRate, sort_indices = FALSE)
    for (p in pl) rep_data$add(p)
    
    ## QC measure for constantly identifiying peptides, irrespective of scan event number
    ## -- we weight scan events by their number of occurence
    qc_TopN_ID = ddply(df.ratio, "fc.raw.file", function(x) data.frame("X038X_catMS_MS^2*Scans:~TopN~ID~over~N" = qualUniform(x$ratio, x$count),
                                                                       check.names = FALSE))
    QCM[["MSMSscans.TopN_ID_over_N"]] = qc_TopN_ID
  } ## end MSMSscan from MQ > 1.0.13
}

hm = getQCHeatMap(QCM, raw_file_mapping = mq$raw_file_mapping)
#print(hm[["plot"]])
write.table(hm[["table"]], file = fh_out$heatmap_values_file, quote = TRUE, sep = "\t", row.names = FALSE)
rep_data$add(hm[["plot"]], "heatmap")

## get MQ short name mapping plot (might be NULL if no mapping was required)
rep_data$add(mq$plotNameMapping(), "name_mapping")

##
## plot it!!!
##


out_formats_supported = c("html", "plainPDF")

param_name_PTXQC_OutputFormats = "PTXQC$OutputFormats"
param_def_PTXQC_OutputFormats = out_formats_supported[2]
param_OutputFormats = getYAML(yaml_obj, param_name_PTXQC_OutputFormats, param_def_PTXQC_OutputFormats)

param_name_PTXQC_PageNumbers = "PTXQC$PlainPDF$AddPageNumbers"
param_def_PTXQC_PageNumbers = "on"
param_PageNumbers = getYAML(yaml_obj, param_name_PTXQC_PageNumbers, param_def_PTXQC_PageNumbers)

cat("Creating Report file ...")


#
#param_OutputFormats = "html pdf"
#
out_formats = unlist(strsplit(param_OutputFormats, "[ ,]+"))
out_formats
out_format_requested = out_formats_supported[match(out_formats, out_formats_supported)]
if (any(is.na(out_format_requested)))
{
  stop("Output format(s) not supported: '", paste(out_formats[is.na(out_format_requested)], collapse="', '"), "'")
}

if ("html" %in% out_format_requested)
{
  fh_out$report_file_extension = c(fh_out$report_file_extension, ".html")
  
  #template = "C:/projects/QC/package/PTXQC/inst/reportTemplate/PTXQC_report_template.Rmd"
  #knit2html(template, output = paste0(fh_out$report_file, ".html"))
  template = system.file("./reportTemplate/PTXQC_report_template.Rmd", package="PTXQC")
  template
  ## Rmarkdown: convert to Markdown, and then to HTML or PDF...
  render(template, output_file = paste0(fh_out$report_file, ".html"))
  ##render(template, output_file = paste0(fh_out$report_file, ".pdf"))
}

  
if ("plainPDF" %in% out_format_requested)
{
  fh_out$report_file_extension = c(fh_out$report_file_extension, ".pdf")
  report_file_PDF = paste0(fh_out$report_file, ".pdf")
  ## give the user a chance to close open reports which are currently blocked for writing
  if (!wait_for_writable(report_file_PDF))
  {
    stop("Target file not writable")
  }
  
  if (param_PageNumbers == "on")
  {
    printWithPage = function(gg_obj, page_nr, filename = fh_out$report_file)
    {
      filename = basename(filename)
      printWithFooter(gg_obj, bottom_left = filename, bottom_right = page_nr)
    }
  } else {
    ## no page number and filename at bottom of each page
    printWithPage = function(gg_obj, page_nr, filename = fh_out$report_file)
    {
      print(gg_obj)
    }
  }
  pdf(report_file_PDF)
  printWithPage(rep_data$get("params"), "p. 1")       # parameters
  printWithPage(rep_data$get("name_mapping"), "p. 2") # short file mapping
  printWithPage(rep_data$get("heatmap"), "p. 3")      # summary heatmap
  GPL_lst = rep_data$get("metric")
  pc = 4; ## subsequent pages start at #4
  for (idx in sort(names(GPL_lst)))
  {
    printWithPage(GPL_lst[[idx]], paste("p.", pc))
    pc = pc + 1
  }
  dev.off();
  cat(" done\n")
}

## save plot object (for easier access, in case someone wants high-res plots)
## (...disabled for now until concrete use case pops up)
#cat("Dumping plot objects as Rdata file ...")
#save(file = fh_out$R_plots_file, list = "GPL")
#cat(" done\n")

### write YAML config
writeYAML(fh_out$yaml_file, yaml_obj)

## write shortnames and sorting of filenames
mq$writeMappingFile(fh_out$filename_sorting)

cat(paste("Report file created at\n\n    ", fh_out$report_file, ".*\n\n", sep=""))
cat(paste0("\n\nTime elapsed: ", round(as.double(Sys.time() - time_start, units="mins"), 1), " min\n\n"))

## return path to PDF report and YAML config, etc
return (fh_out)
}
