#' Create a quality control report (in PDF format).
#'
#' This is the main function of the package and the only thing you need to call directly if you are 
#' just interested in getting a QC report.
#' 
#' You need to provide the folder name of the 'txt' output, as generated by MaxQuant and 
#' optionally a YAML configuration object, which allows to (de)activate certain plots and holds other parameters.
#' The yaml_obj is complex and best obtained by running this function once using the default (empty list).
#' A full YAML configuration object will be written in the 'txt' folder you provide and can be loaded using
#' \code{\link[yaml]{yaml.load}}.
#' 
#' The PDF and the config file will be stored in the given txt folder.
#' 
#' @note You need write access to the txt folder!
#' 
#' For updates, bug fixes and feedback please visit \url{http://github.com/cbielow/PTXQC}.
#'
#' @param txt_folder Path to txt output folder of MaxQuant (e.g. "c:/data/Hek293/txt")
#' @param yaml_obj   A nested list object with configuration parameters for the report.
#'                   Useful to switch off certain plots or skip entire sections.
#' @return List with named filename strings, e.g. $yaml_file, $report_file etc..
#'          
#' @import ggplot2
#' @import directlabels
#' @importFrom plyr ddply dlply adply summarise
#' @importFrom grid unit
#' @importFrom reshape2 melt
#' @importFrom RColorBrewer brewer.pal
#' @importFrom rmarkdown render
#' @export
#'           
createReport = function(txt_folder, yaml_obj = list())
{
  
  ### script starts...
  if (class(yaml_obj) != "list")
  {
    stop(paste0("Argument 'yaml_obj' is not of type list\n"));
  }
  
  ## list of plots
  rep_data = ReportData$new()
  
  ## list of data.frames containing one QC metric per list for each Raw file
  ## used for heat map later on
  QCM = list()
  
  ## determines if a local mqpar.xml should be used to grep all YAML parameters whose name starts with "MQpar_" from the
  ## original mqpar.xml instead of the yaml.config. The "MQpar_..." param from the config
  ## will be ignored and the newly written yaml.config will contain the values from mqpar.xml.
  param_name_PTXQC_UseLocalMQPar = "PTXQC$UseLocalMQPar"
  param_def_PTXQC_UseLocalMQPar = TRUE
  param_useMQPAR = getYAML(yaml_obj, param_name_PTXQC_UseLocalMQPar, param_def_PTXQC_UseLocalMQPar)
  
  time_start = Sys.time()
  
  
  if (!any(file.info(txt_folder)$isdir, na.rm=T))
  {
    stop(paste0("Argument txt_folder with value '", txt_folder, "' is not a valid directory\n"));
  }
  txt_files = list()
  txt_files$param = "parameters.txt"
  txt_files$summary = "summary.txt"
  txt_files$groups = "proteinGroups.txt"
  txt_files$evd = "evidence.txt"
  txt_files$msms = "msms.txt"
  txt_files$msmsScan = "msmsScans.txt"
  txt_files$mqpar = "mqpar.xml"
  txt_files = lapply(txt_files, function(x) paste(txt_folder, x, sep=.Platform$file.sep))
  
  ## create names of output files (report PDF, YAML, stats, etc...)
  fh_out = getReportFilenames(txt_folder)
  use_extended_report_filename = getYAML(yaml_obj, "PTXQC$ReportFilename$extended", TRUE)
  fh_out$report_file = ifelse(use_extended_report_filename, fh_out$report_file_extended, fh_out$report_file_simple)
  
  unlink(fh_out$stats_file)
  cat("Statistics summary:", file=fh_out$stats_file, append=F, sep="\n")
  
  ## prepare for readMQ()
  mq = MQDataReader$new()
  
  ## read manual filename shortening & sorting (if available)
  mq$readMappingFile(fh_out$filename_sorting)
  
  ######
  ######  parameters.txt ...
  ######
  
  enabled_parameters = getYAML(yaml_obj, "File$Parameters$enabled", TRUE)
  if (enabled_parameters)
  {
    d_parAll = mq$readMQ(txt_files$param, type="par")
    
    line_break = "\n"; ## use space to make it work with table
    ## remove AIF stuff
    d_parAll = d_parAll[!grepl("^AIF ", d_parAll$parameter),]
    d_parAll$value = gsub(";", line_break, d_parAll$value)
    ## seperate FASTA files (usually they destroy the layout)
    idx_fastafile = grepl("fasta file", d_parAll$parameter, ignore.case = T)
    d_par_file = d_parAll[idx_fastafile, ]
    fasta_files = sapply(unlist(strsplit(d_par_file$value, "\n")), function(x) rev(strsplit(x,"\\", fixed=T)[[1]])[1])
    d_par = d_parAll[!idx_fastafile, ]
    ## remove duplicates
    d_par = d_par[!duplicated(d_par$parameter),]
    rownames(d_par) = d_par$parameter
    
    ## trim long param names (the user should know what they mean)
    d_par$parameter = sapply(d_par$parameter, function (s) {
      allowed_len = nchar("Min. score for unmodified .."); 
      if (nchar(s) > allowed_len) {
        s = paste(substring(s, 1, allowed_len), "..", collapse = "", sep="")
      }
      return (s)
    })
    ## break long values into multiple lines (to preserve table width)
    d_par$value = sapply(d_par$value, function (s) 
    {
      allowed_len = nchar("Use least modified peptide"); ## this is a typical entry -- everything which is longer gets split
      r = paste(sapply(unlist(strsplit(s, line_break, fixed=T)), function(s1) {
        if (nchar(s1) > allowed_len) {
          s_beg = seq(1, nchar(s1) - 1, allowed_len)
          s1 = paste(unlist(substring(s1, s_beg, s_beg + allowed_len)), collapse = line_break)
        }
        return(s1)
      }), collapse = line_break)
      return (r)
    })
    
    ## two column layout
    mid = ceiling(nrow(d_par)/2)
    d_par$page = 1
    d_par$page[1:mid] = 0
    
    d_par$ypos = -c(1:mid, (1:mid)[1:(nrow(d_par)-mid)])
    head(d_par)
    d_par.long = melt(d_par, id.vars = c("ypos", "page"), measure.vars=c("parameter", "value"))
    head(d_par.long)
    d_par.long$variable = as.character(d_par.long$variable)
    d_par.long$variable[d_par.long$variable=="parameter"] = 10
    d_par.long$variable[d_par.long$variable=="value"] = 5
    par_pl = ggplot(d_par.long, aes_string(x = "variable", y = "ypos"))  +
      coord_cartesian(xlim=c(2, 0)) + 
      geom_text(aes_string(label = "value", colour = "variable"), family="mono", hjust=1, size=2) +
      facet_wrap(~ page, ncol=2) +
      scale_colour_manual(values=c("#000000", "#5F0000")) +
      theme_bw() +
      theme(plot.margin = unit(c(1,1,1,1), "cm"), line = element_blank(), axis.title = element_blank(), panel.border = element_blank(),
            axis.text = element_blank(), strip.text = element_blank(), legend.position="none") +
      ggtitle("PAR: parameters") +
      geom_text(data = data.frame(variable=0, ypos=-mid-2, page=0), label = paste(fasta_files, collapse=line_break), size=2, hjust=0)
    rep_data$add(par_pl, "params")
    ##todo: read in mqpar.xml to get group information and ppm tolerances for all groups (parameters.txt just gives Group1)
  }
  
  add_fs_col = getYAML(yaml_obj, "PTXQC$NameLengthMax_num", 10)
  
  ######
  ######  summary.txt ...
  ######
  
  enabled_summary = getYAML(yaml_obj, "File$Summary$enabled", TRUE)
  if (enabled_summary)
  {
    d_smy = mq$readMQ(txt_files$summary, type="sm", add_fs_col = add_fs_col)
    #colnames(d_smy)
    #colnames(d_smy[[1]])
    
    id_rate_bad = getYAML(yaml_obj, "File$Summary$IDRate$Thresh_bad_num", 20)
    id_rate_great = getYAML(yaml_obj, "File$Summary$IDRate$Thresh_great_num", 35)
    
    ### MS/MS identified [%]
    dms = d_smy$raw$"ms.ms.identified...."
    dms[is.na(dms)] = 0  ## ID rate can be NaN for some raw files if NOTHING was aquired
    lab_IDd = c("red", 
                "blue", 
                "green")
    names(lab_IDd) = c("bad (<" %+% id_rate_bad %+% "%)", 
                       "ok (" %+% id_rate_bad %+% "-" %+% id_rate_great %+% "%)",
                       "great (>" %+% id_rate_great %+% "%)")
    d_smy[[1]]$color = factor(cut(dms, breaks=c(-1, id_rate_bad, id_rate_great, 100), labels=names(lab_IDd)))
    
    
    d_smy[[1]]$fc.raw.file = mq$raw_file_mapping$to[match(d_smy[[1]]$raw.file, mq$raw_file_mapping$from)]
    ## needs to be a factor for 'scale_y_discrete_reverse' below, but lets to the sorting manually...
    d_smy[[1]]$fc.raw.file = factor(d_smy[[1]]$fc.raw.file, levels=unique(d_smy[[1]]$fc.raw.file), ordered=T)
    
    d_smy[[1]]$x = 1:nrow(d_smy[[1]])
    p = 
      ggplot(d_smy[[1]], aes_string(y = "fc.raw.file", x = "ms.ms.identified....")) +
        geom_point(aes_string(colour = "color")) +
        geom_vline(xintercept = id_rate_bad, color=(lab_IDd)[1]) +
        geom_vline(xintercept = id_rate_great, color=(lab_IDd)[3]) +
        ylab("") + 
        xlab("MS/MS identified [%]") +
        scale_colour_manual(values=lab_IDd) + 
        ggtitle("SM: MS/MS identified per Raw file") + 
        xlim(0, max(dms, id_rate_great)*1.1) + 
        guides(color=guide_legend(title="ID class")) +
        scale_y_discrete_reverse(d_smy[[1]]$fc.raw.file, breaks = ggAxisLabels)
    rep_data$add(p)
    ## QC measure for contamination
    qc_sm_id = d_smy[[1]][, c("raw.file", "ms.ms.identified....")]
    cname = "X030X_catMS_SM:~MS^2~ID~rate (\">" %+% id_rate_great %+% "\")"
    qc_sm_id[, cname] = qualLinThresh(qc_sm_id$ms.ms.identified.... , id_rate_great)
    QCM[["SM.MS2_ID_rate"]] = qc_sm_id[,c("raw.file", cname)]
    
    ## table of files with 'bad' MS/MS id rate
    bad_id_count = sum(d_smy[[1]]$color==lab_IDd[1])
    if (bad_id_count>0)
    {
      sm_badID = d_smy[[1]][d_smy[[1]]$color==lab_IDd[1],c("raw.file","ms.ms.identified....")]
      if (nrow(sm_badID) > 40)
      {
        sm_badID[40, "raw.file"] = paste(nrow(sm_badID) - 39, "more ...");
        sm_badID[40, "ms.ms.identified...."] = ""
        sm_badID = sm_badID[1:40, ]
      }
      sm_badID$ypos = -(1:nrow(sm_badID))
      head(sm_badID)
      sm_badID.long = melt(sm_badID, id.vars = c("ypos"), measure.vars=c("raw.file","ms.ms.identified...."))
      head(sm_badID.long)
      sm_badID.long$variable = as.character(sm_badID.long$variable)
      sm_badID.long$col = "#000000";
      sm_badID.long$col[sm_badID.long$variable=="ms.ms.identified...."] = "#5F0000"
      sm_badID.long$variable[sm_badID.long$variable=="raw.file"] = "6"
      sm_badID.long$variable[sm_badID.long$variable=="ms.ms.identified...."] = "8"
      sm_badID.long$variable = as.numeric(sm_badID.long$variable)
      sm_badID.long$size = 2
      sm_badID.long2 = rbind(data.frame(ypos=0, variable=c(6, 8), value=c("raw file", "% identified"), col="#000000", size=3), sm_badID.long)
      smbad_pl = ggplot(sm_badID.long2, aes_string(x = "variable", y = "ypos"))  +
        xlim(0, 11) + 
        geom_text(aes_string(label = "value"), color = sm_badID.long2$col, hjust=1, size=sm_badID.long2$size) +
        theme_bw() +
        theme(plot.margin = unit(c(1,1,1,1), "cm"), line = element_blank(), axis.title = element_blank(), panel.border = element_blank(),
              axis.text = element_blank(), strip.text = element_blank(), legend.position="none") +
        ggtitle(paste0("SM: Files with '", lab_IDd[1], "' ID rate (", round(bad_id_count*100/nrow(d_smy[[1]])),"% of samples)"))
      
      rep_data$add(smbad_pl)
    }
  }  
  
  
  ######
  ######  proteinGroups.txt ...
  ######
  
  GL_name_min_length = 8
  
  enabled_proteingroups = getYAML(yaml_obj, "File$ProteinGroups$enabled", TRUE)
  enabled_pg_ratioLabIncThresh = getYAML(yaml_obj, "File$ProteinGroups$RatioPlot$LabelIncThresh_num", 4)
  if (enabled_proteingroups)
  {
    
    d_pg = mq$readMQ(txt_files$groups, type="pg", col_subset=NA, filter="R")
      
    clusterCols = list()
    ##
    ## intensity boxplots
    ##
    param_name_PG_intThresh = "File$ProteinGroups$IntensityThreshLog2_num"
    param_def_PG_intThresh = 25 ## default median intensity in log2 scale
    param_PG_intThresh = getYAML(yaml_obj, param_name_PG_intThresh, param_def_PG_intThresh)
    if (!is.numeric(param_PG_intThresh) || !(param_PG_intThresh %in% 1:100))
    { ## reset if value is weird
      cat("YAML value for '" %+% param_name_PG_intThresh %+% "' is invalid ('" %+% param_PG_intThresh %+% "'). Using default of " %+% param_def_PG_intThresh %+% ".")
      param_PG_intThresh = param_def_PG_intThresh
    }
    
    
    colsSIL = grepv("^intensity\\.[hlm](\\.|$)", colnames(d_pg))
    colsLF = grepv("^intensity\\.[^hlm]", colnames(d_pg))
    colsOneCond = "intensity" ## just one group -- we still want to know what the overall intensity is
    if (length(colsSIL)) {
      ## ignore intensity.l and alike if real groups are present
      plain_channel = grepv("^intensity\\.[hlm]$", colnames(d_pg))
      if (all(plain_channel == colsSIL)) colsW = colsSIL else colsW = setdiff(colsSIL, plain_channel)
    } else if (length(colsLF)) {
      colsW = colsLF
    }  else {
      colsW = colsOneCond
    }
    
    ## a global PG name mapping
    MAP_pg_groups = data.frame(long = colsW)
    MAP_pg_groups$short = shortenStrings(simplifyNames(delLCP(MAP_pg_groups$long, 
                                                              min_out_length = GL_name_min_length, 
                                                              add_dots = T), 
                                                       min_out_length = GL_name_min_length))
    
    ## Contaminants stats
    df.con_stats = adply(colsW, .margins=1, function(group) {
      #cat(group)
      return(data.frame(group_long = as.character(group),
                        log10_int  = log10(sum(as.numeric(d_pg[, group]), na.rm=T)),
                        cont_pc    = sum(as.numeric(d_pg[d_pg$contaminant, group]), na.rm=T) /
                          sum(as.numeric(d_pg[, group], na.rm=T))*100
      ))
    })
    df.con_stats$group = MAP_pg_groups$short[match(df.con_stats$group_long, MAP_pg_groups$long)]
    df.con_stats$logAbdClass = getAbundanceClass(df.con_stats$log10_int)
    df.con_stats
    
    plotContsPG = function(datav) {
      datav$section = as.integer(seq(0, nrow(datav)/correctSetSize(nrow(datav),30)*0.999, length.out=nrow(datav)))
      pl = 
        ggplot(data=datav, aes_string(x = "group", y = "cont_pc", alpha="logAbdClass")) +
        scale_alpha_discrete(range = c(c(0.3, 1)[(length(unique(datav$logAbdClass))==1) + 1], 1.0), ## ordering of range is critical!
                             name = "Abundance\nclass") +
        geom_bar(stat="identity") +
        theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
        xlab("")  +
        ggtitle("PG: Contaminant per condition") +
        ylab("contaminant (% intensity)") +
        geom_hline(aes_string(yintercept = "5"), linetype = 'dashed')
      if (length(unique(datav$section))>1) pl = pl + facet_wrap(~ section, ncol = 1, scales="free_x")
      #print(pl)
      return (pl)
    }
    pg_plots_cont = byXflex(df.con_stats, 1:nrow(df.con_stats), 90, plotContsPG, sort_indices=F)
    for (p in pg_plots_cont) rep_data$add(p);
    
    ##
    ## stats file
    ##
    con_stats_smry = quantile(df.con_stats$cont_pc, probs=c(0,0.5,1))
    cat(pastet("contamination(min,median,max) [%]", paste(con_stats_smry, collapse=",")), file=fh_out$stats_file, append=T, sep="\n")  
    
    ###
    ### intensity boxplot
    ###
    
    clusterCols$raw.intensity = colsW ## cluster using intensity
    #cat("colsW:\n")
    #cat(paste0(colsW, collapse=","))
    ## some stats (for plot title)
    medians_no0 = sort(apply(log2(d_pg[, colsW, drop=F]), 2, function(x) quantile(x[x>0], probs=0.5, na.rm=T))) # + c(0,0,0,0,0,0))
    int_dev_no0 = RSD(medians_no0)
    ## do not remove zeros (but add +1 since RSD is 'NA' when 'inf' is included in log-data)
    medians = sort(apply(log2(d_pg[, colsW, drop=F]+1), 2, quantile, na.rm=T, probs=0.5)) # + c(0,0,0,0,0,0))
    int_dev = RSD(medians)
    int_dev.s = pastet("INT RSD [%]", round(int_dev, 3))
    lpl = boxplotCompare(   data = melt(d_pg[, c(colsW, "contaminant"), drop=F], id.vars=c("contaminant"))[,c(2,3,1)],
                            log2 = T, 
                         mainlab = "PG: intensity distribution",
                            ylab = expression(log[2]*" intensity"),
                          sublab = paste0("RSD ", round(int_dev_no0, 1),"% (w/o zero int.; expected < 5%)\n",
                                          "RSD ", round(int_dev, 1),"% [high RSD --> few peptides])"),
                          abline = param_PG_intThresh,
                           names = MAP_pg_groups)
    #for (pl in lpl) print(pl)
    for (pl in lpl) rep_data$add(pl)
    rm("lpl")          
    cat(int_dev.s, file=fh_out$stats_file, append=T, sep="\n")
    
    ##
    ## LFQ boxplots
    ##
    colsSIL = grepv("^lfq.intensity\\.[hlm](\\.|$)", colnames(d_pg))
    colsLF = grepv("^lfq.intensity\\.[^hlm]", colnames(d_pg))
    
    ## a global PG name mapping
    MAP_pg_groups_LFQ = NA
    if (length(c(colsSIL, colsLF)) > 0)
    {
      if (length(colsSIL)) {
        ## unlike intensity.l, there is no lfq.intensity.l which we could remove
        colsW = colsSIL
      } else colsW = colsLF
      MAP_pg_groups_LFQ = data.frame(long = colsW)
      MAP_pg_groups_LFQ$short = shortenStrings(simplifyNames(delLCP(MAP_pg_groups_LFQ$long, 
                                                                    min_out_length = GL_name_min_length, 
                                                                    add_dots = T), 
                                                             min_out_length = GL_name_min_length))

      clusterCols$lfq.intensity = colsW ## cluster using LFQ
      ## some stats (for plot title)
      medians_no0 = sort(apply(log2(d_pg[, colsW, drop=F]), 2, function(x) quantile(x[x>0], probs=0.5, na.rm=T))) # + c(0,0,0,0,0,0))
      lfq_dev_no0 = RSD(medians_no0)
      ## do not remove zeros (but add +1 since RSD is 'NA' when 'inf' is included in log-data)
      medians = sort(apply(log2(d_pg[, colsW, drop=F]+1), 2, quantile, probs=0.5, na.rm=T)) # + c(0,0,0,0,0,0))
      lfq_dev = RSD(medians)
      lfq_dev.s = pastet("LFQ RSD [%]", round(lfq_dev, 3))
      lpl = boxplotCompare(   data = melt(d_pg[, c(colsW, "contaminant"), drop=F], id.vars=c("contaminant"))[,c(2,3,1)],
                              log2 = T, 
                           mainlab = "PG: LFQ intensity distribution", 
                              ylab = expression(log[2]*" LFQ intensity"),
                            sublab = paste0("RSD ", round(lfq_dev_no0, 1),"% (w/o zero int.; expected < 5%)\n",
                                            "RSD ", round(lfq_dev, 1),"% [high RSD --> few peptides])"),
                            abline = param_PG_intThresh,
                             names = MAP_pg_groups_LFQ)
      #for (pl in lpl) print(pl)
      for (pl in lpl) rep_data$add(pl)
      cat(lfq_dev.s, file=fh_out$stats_file, append=T, sep="\n")
    }
    
    ##
    ## iTRAQ/TMT, reporter ion intensity boxplot
    ##
    ## either "reporter.intensity.0.groupname" or "reporter.intensity.0" (no groups)    
    colsITRAQ = grepv("^reporter.intensity.[0-9].|^reporter.intensity.[0-9]$", colnames(d_pg))
    ## a global PG name mapping
    MAP_pg_groups_ITRAQ = NA
    if (length(colsITRAQ) > 0)
    {
      MAP_pg_groups_ITRAQ = data.frame(long = c(colsITRAQ))
      MAP_pg_groups_ITRAQ$short = shortenStrings(simplifyNames(delLCP(MAP_pg_groups_ITRAQ$long, 
                                                                      min_out_length = GL_name_min_length, 
                                                                      add_dots = T), 
                                                               min_out_length = GL_name_min_length))

      colsW = colsITRAQ
      clusterCols$reporter.intensity = colsW ## cluster using reporters
      ## some stats (for plot title)
      medians_no0 = sort(apply(log2(d_pg[, colsW, drop=F]), 2, function(x) quantile(x[x>0], probs=0.5, na.rm=T))) # + c(0,0,0,0,0,0))
      reprt_dev_no0 = RSD(medians_no0)
      ## do not remove zeros (but add +1 since RSD is 'NA' when 'inf' is included in log-data)
      medians = sort(apply(log2(d_pg[, colsW, drop=F]+1), 2, quantile, probs=0.5, na.rm=T)) # + c(0,0,0,0,0,0))
      reprt_dev = RSD(medians)
      reprt_dev.s = pastet("Reporter RSD [%]", round(reprt_dev, 3))
      lpl = boxplotCompare(   data = melt(d_pg[, c(colsW, "contaminant"), drop=F], id.vars=c("contaminant"))[,c(2,3,1)],
                              log2 = T, 
                              ylab = expression(log[2]*" reporter intensity"),
                           mainlab = "PG: reporter intensity distribution",
                            sublab = paste0("RSD ", round(reprt_dev_no0, 1),"% (w/o zero int.; expected < 5%)\n",
                                            "RSD ", round(reprt_dev, 1),"% [high RSD --> few peptides])"),
                            abline = param_PG_intThresh,
                             names = MAP_pg_groups_ITRAQ)
      #for (pl in lpl) print(pl)
      for (pl in lpl) rep_data$add(pl)
      cat(reprt_dev.s, file=fh_out$stats_file, append = T, sep="\n")
    }
    
    
    ##
    ## PCA
    ##
    ## some clustering (its based on intensity / lfq.intensity columns..)
    ## todo: maybe add ratios -- requires loading from txt though..
    MAP_pg_groups_ALL = rbind(MAP_pg_groups, MAP_pg_groups_LFQ, MAP_pg_groups_ITRAQ)
    for (cond in names(clusterCols))
    {
      #cond = names(clusterCols)[3]
      #print(clusterCols[cond])
      if (length(clusterCols[[cond]]) <= 1) 
      { ## only one condition.. PCA does not make sense (and will not work)
        next;
      }
      ## remove contaminants
      data = t(d_pg[!d_pg$contaminant, unlist(clusterCols[cond]), drop=F])
      ## remove constant/zero columns (== dimensions == proteins)
      data = data[, colSums(data, na.rm=T) > 0, drop=F]
      rownames(data) = MAP_pg_groups_ALL$short[match(rownames(data), MAP_pg_groups_ALL$long)]
      lpl = try(getPCA(data = data,
                       gg_layer = addGGtitle(paste0("PG: PCA of '", sub(".", " ", cond, fixed=T), "'"), "(excludes contaminants)")
      )[["plots"]]
      )
      #print(lpl)
      if (!inherits(lpl, "try-error")) for (pl in lpl) rep_data$add(pl);
    }
    
    
    ##################################
    ## ratio plots
    ##################################
    ## get ratio column
    ratio_cols = grepv("^ratio\\.[hm]\\.l", colnames(d_pg))  ## e.g. "ratio.m.l.ARK5exp" or "ratio.m.l.variability.ARK5exp"
    ## remove everything else
    ## e.g. we do not want ratio.h.l.variability.ARK5exp, i.e. the 'variability' property
    ratio_cols = grepv("^ratio.[hm].l.normalized", ratio_cols, invert=T)
    ratio_cols = grepv("^ratio.[hm].l.count", ratio_cols, invert=T)
    ratio_cols = grepv("^ratio.[hm].l.variability", ratio_cols, invert=T)
    ratio_cols = grepv("^ratio.[hm].l.significance.a", ratio_cols, invert=T) ## from MQ 1.0.1x
    ratio_cols = grepv("^ratio.[hm].l.significance.b", ratio_cols, invert=T)
    ratio_cols = grepv("^ratio.[hm].l.iso.count", ratio_cols, invert=T) ## from MQ 1.5.1.2
    ratio_cols = grepv("^ratio.[hm].l.type", ratio_cols, invert=T)
    ratio_cols
    
    if (length(ratio_cols) > 0)
    {
      colnames(d_pg)
      
      ## remove reverse and contaminants (might skew the picture)
      idx_row = !d_pg$contaminant & !d_pg$reverse
      d_sub = log2(d_pg[idx_row, ratio_cols, drop=F])
      ## rename "ratio.h.l" to "h.l" (same for m.l in tripleSILAC)
      idx_globalRatio = grep("ratio\\.[hm]\\.l$", colnames(d_sub))
      if (length(idx_globalRatio)) colnames(d_sub)[idx_globalRatio] = gsub("^ratio\\.", "", colnames(d_sub)[idx_globalRatio])
      ## simplify the rest
      if (ncol(d_sub) > length(idx_globalRatio))
      {
        idx_other = setdiff(1:ncol(d_sub), idx_globalRatio)
        colnames(d_sub)[idx_other] = shortenStrings(simplifyNames(delLCP(colnames(d_sub)[idx_other], 
                                                                         min_out_length = GL_name_min_length, 
                                                                         add_dots = T), 
                                                                  min_out_length = GL_name_min_length))
      }
      #summary(d_sub)
      # 
      # plot(density(d_sub[,1], bw = "SJ", adjust=1, na.rm=T, n=128))
      # plot(d_sub[,1])
      # h = density(d_sub[,1], bw = "SJ", adjust=1, na.rm=T, n=128)
      
      
      ## get ranges to fix breaks for density intervals
      # breaks = seq(min(d_sub, na.rm=T), max(d_sub, na.rm=T), length.out=(max(dd, na.rm=T)-min(dd, na.rm=T))/0.5)
      # mid = hist(d_sub[, 1], breaks = breaks)$mids
      ratio.densities = do.call(rbind, (lapply(1:ncol(d_sub), function(x) {
        name = colnames(d_sub)[x]
        ## density estimation can fail if not enough data
        h = try(density(na.omit(d_sub[ ,x]), bw = "SJ", adjust=2, na.rm=T))
        if (inherits(h, "try-error")) return (data.frame(x = 1, y = 1, col = name, multimodal = FALSE))
        count = sum(getMaxima(h$y))
        if (count > 1) name = paste(name, "*")
        df = data.frame(x = h$x, y = h$y, col = name, multimodal = (count>1))
        return (df)
      })))
      ratio.densities$alpha = c(0.8, 1)[ratio.densities$multimodal+1]
      ratio.densities$ltype = c("dotted", "solid")[ratio.densities$multimodal+1]
      #head((ratio.densities))
      
      
      legend_title = "group"
      ## compute label incorporation?
      ratio.mode = ddply(ratio.densities, "col", .fun = function(x) {
        mode = x$x[which.max(x$y)]
        return (data.frame(mode = mode))
      })
      
      ## on more than ratio 1:8 or 8:1 ratio, report label incorporation
      # enabled_pg_ratioLabIncThresh == 8 by default
      if (max(abs(ratio.mode$mode)) > abs(log2(enabled_pg_ratioLabIncThresh))) {
        cat(paste0("Maximum ratio (log2) was ", round(max(abs(ratio.mode$mode)),1) , ", reaching the threshold of ", abs(log2(enabled_pg_ratioLabIncThresh)), " for label-incorporation computation.\nComputing ratios ...\n"))
        ## back to normal scale
        ratio.norm = 2^ratio.mode$mode
        ## compute incorporation
        ratio.inc =  ratio.norm / (ratio.norm+1) * 100
        ## round
        ratio.mode$li = round(ratio.inc)
        ## new label
        ratio.mode$col_new = ratio.mode$col %+% " (" %+% ratio.mode$li %+% "%)"
        ## replace column names in data.frame
        ratio.densities$col = ratio.mode$col_new[match(ratio.densities$col, ratio.mode$col)]
        ## notify user via legend title
        legend_title = "group\n(with label inc)"
      } else
      {
        cat(paste0("Maximum ratio (log2) was ", max(abs(ratio.mode$mode)), ", NOT reaching the threshold of ", abs(log2(enabled_pg_ratioLabIncThresh)), " for label-incorporation computation.\nSkipping ratios ...\n"))
      }
      
      title_ratio = "PG: ratio density\n(w/o contaminants)"
      title_col = "black"
      if (any(ratio.densities$multimodal))
      {
        title_ratio = paste0(title_ratio, "\nWarning: multimodal densities detected")
        title_col = "red"
      }
      
      plotRatios = function(df_ratios, d_min, d_max, title_col)
      {
        br = c(2, 5, 10, 20);
        rep_data$add(
        #print(
          ggplot(data = df_ratios, aes_string(x = "x", y = "y", colour = "col")) + 
            facet_grid(col ~ ., scales = "free_y") +
            geom_line(size = 1.2) +
            geom_area(aes_string(alpha = "ltype", fill = "col")) +
            xlab("ratio")  +
            ylab("density")  +
            #facet_grid(col ~ ) +
            scale_fill_manual(values = rep(brewer.pal(6,"Accent"), times=40), guide_legend(legend_title)) + 
            scale_colour_manual(values = rep(brewer.pal(6,"Accent"), times=40)) +
            scale_alpha_discrete(range = c(1, 0.2), 
                                  labels=c("dotted"="unimodal", "solid"="multimodal"),
                                  guide_legend("shape")
            ) +
            scale_x_continuous(limits = c(d_min, d_max), trans = "identity", breaks = c(-br, 0, br), labels=c(paste0("1/",2^(br)), 1, 2^br)) +
            guides(colour=FALSE) +
            theme(plot.title = element_text(colour = title_col)) +
            theme_bw() +
            geom_vline(alpha = 0.5, xintercept = 0, colour = "green", linetype = "dashed", size = 1.5) +
            ggtitle(title_ratio)
        )
        return (1)
      }
      
      byXflex(ratio.densities, ratio.densities$col, 5, plotRatios, sort_indices = F, d_min = quantile(d_sub, na.rm=T, probs=0.00), d_max = quantile(d_sub, na.rm=T, probs=1), title_col)
      
    }
    ## rm("d_pg") required in evidence....
  }
  
  ######
  ######  evidence.txt ...
  ######
  
  enabled_evidence = getYAML(yaml_obj, "File$Evidence$enabled", TRUE)
  if (enabled_evidence)
  {
    #d_evd_s = mq$readMQ(txt_files$evd, type="ev", filter = "", nrows=100)
    #d_evd_s = mq$readMQ(txt_files$evd, type="ev", filter = "")
    #head(d_evd_s)
    #colnames(d_evd_s)
    #table(d_evd_s$reverse)
    #[grep("ount", colnames(d_evd))]
    
    ## protein.names is only available from MQ 1.4 onwards
    d_evd = mq$readMQ(txt_files$evd, type="ev", filter="R", col_subset=c("proteins", "Retention.Length", "retention.time.calibration", 
                                                                         "Retention.time$", "Match.Time.Difference", "^intensity$", "^Type$",
                                                                         "Mass\\.Error", "^uncalibrated...calibrated." , "^m.z$",
                                                                         "^Match.q.value$", 
                                                                         "^fraction$",  ## only available when fractions were given
                                                                         "Raw.file", "^Protein.Group.IDs$", "Contaminant", "[RK]\\.Count", 
                                                                         "^Charge$", "modified.sequence", "^Mass$", "^protein.names$", "^ms.ms.count$"))
    ##
    ## write peptides to stats file (remnant from proteinGroups)
    ##
    
    ##
    ## sort by rawfile as shown in the summary.txt (or whatever the first txt file was)
    ##
    d_evd = d_evd[order(match(as.character(d_evd$fc.raw.file), mq$raw_file_mapping$to)),]
    ## sort fc.raw.file's factor values as well
    d_evd$fc.raw.file = factor(d_evd$fc.raw.file, levels = mq$raw_file_mapping$to, ordered = TRUE)
    
    #d_evd = mq$readMQ(txt_files$evd, type="ev", filter="R", col_subset=c("labeling.state", "Match.Time.Difference", "fasta.headers", "^intensity$", "Raw.file", "^Protein.Group.IDs$"))
    #summary(head(d_evd))
    #head(d_evd)
    #colnames(d_evd)
{
      
      ### warn of special contaminants!
      ## these need to be in FASTA headers (description is not enough)!
      ## syntax:  list( contaminant1 = c(name, threshold), contaminant2 = c(...), ...)
      ##
      ##  if within the YAML file
      ##    SpecialContaminants: no
      ##  is set, then 'yaml_contaminants' will be 'FALSE'
      ##
      contaminant_default = list("cont_MYCO" = c(name="MYCOPLASMA", threshold=1)) # name (FASTA), threshold for % of unique peptides
      ## contaminant_default = FALSE ## to switch it off by default
      yaml_contaminants = getYAML(yaml_obj, "File$Evidence$SpecialContaminants", contaminant_default)
      
      #stop(yaml_contaminants)
      
      for (ca_entry in yaml_contaminants)
      {
        ca = ca_entry[1]
        ## 
        if (ca == FALSE) {
          cat("No special contaminants requested!\n")
          break;
        }
        
        ca_thresh = as.numeric(ca_entry[2])
        
        not_found = T
        
        if (enabled_proteingroups)
        {
          pg_idx = d_pg$id[grep(ca, d_pg$fasta.headers, ignore.case = T)]
        } else {
          ## fail hard; we could hack around this (e.g. by loading fasta headers from evidence.txt), but it
          ## wastes a lot of memory and time
          stop(paste0("Error: reporting of special contaminants (", ca, ") requires loading of proteinGroups.txt.",
                      "If you don't have this file, please disable contaminant lookup in the YAML file and re-run."))
        } 
        
        
        if (length(pg_idx) > 0)
        {
          
          ## we might or might not have found something... we plot it anyways, so the user can be sure that we searched for it
          
          ## find peptides which only have one group (ignoring razor peptides where we cannot be sure)
          evd_uniqueGroup = !grepl(";", d_evd$protein.group.ids)
          ## do not trust MBR here. We want real evidence!
          evd_realMS = !grepl("MATCH", d_evd$type)
          ## for each Raw file: find unique peptides of our contaminant
          cont_data = ddply(d_evd[evd_uniqueGroup & evd_realMS, c("intensity", "fc.raw.file", "protein.group.ids")], "fc.raw.file", function(x) {
            if (length(grep(";", x$protein.group.ids))) stop("more than one proteinGroup for supposedly unique peptide...")
            
            idx_cont = x$protein.group.ids %in% pg_idx
            
            sc = sum(idx_cont) / nrow(x) * 100
            int = sum(as.numeric(x$intensity[idx_cont]), na.rm=T) / sum(as.numeric(x$intensity), na.rm=T) * 100
            
            above.thresh = (sc > ca_thresh) | (int > ca_thresh)
            
            return (data.frame(spectralCount = sc, intensity = int, above.thresh = above.thresh))
          })
          #head(cont_data)
          
          ## melt
          cont_data.long = melt(cont_data[, c("fc.raw.file", "spectralCount", "intensity")], id.vars="fc.raw.file")
          cont_data.long
          
          not_found = all(cont_data$above.thresh==FALSE)
        }
        
        if (not_found)
        { ## identifier was not found in any sample
          pl_cont = ggText("PG: Contaminants",
                           paste0("Contaminant '", ca, "' was not found in any sample.\n\nDid you use the correct database?"),
                           "red")
          rep_data$add(pl_cont)
        } else {
          plotContUser = function(datav, extra_limit) {
            #cat(paste0("CA entry is ", extra_limit, "\n"))
            datav$section = as.integer(seq(0, nrow(datav)/40, length.out = nrow(datav)))
            pr = ggplot(datav, aes_string(x = "fc.raw.file", y = "value")) +
              geom_bar(stat="identity", aes_string(fill = "variable"), position = "dodge", width=.7) +
              ggtitle(paste0("EVD: Contaminant '", ca, "'")) +
              xlab("")  +
              ylab("abundance (%)") +
              ylim(c(0, max(datav$value, extra_limit)*1.1)) +
              theme(plot.title = element_text(colour = "red"),
                    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
              scale_fill_discrete(name = "Method") +
              geom_hline(yintercept = extra_limit, linetype = 'dashed') +
              facet_wrap(~ section, ncol = 1, scales = "free_x")
            rep_data$add(pr)
            #print(pr)
            return(1)
          }
          byXflex(data = cont_data.long, indices = cont_data.long$fc.raw.file, subset_size = 120, FUN = plotContUser, sort_indices=F, extra_limit = ca_thresh)
          
          ## add heatmap column
          cname = paste0("X002X_catPrep_EVD:Contaminant~(", ca, ")")
          cont_data[,cname] = as.numeric(!cont_data$above.thresh) ## inverse (0 is 'bad')
          QCM[[paste0("EVD.Contaminant_",ca)]] = cont_data[, c("fc.raw.file", cname)]
          
          
          report_short = pastet("Contaminant:", ca, paste0(sum(cont_data$above.thres),"/",nrow(cont_data)," Raw files"))
          report_samples  = pastet("Contaminant-details (name, raw.file, spectralCount%): " , ca, paste(cont_data$fc.raw.file, collapse=";"), paste(cont_data$spectralCount, collapse=";"))
          report_samples2 = pastet("Contaminant-details (name, raw.file, intensity%): " , ca, paste(cont_data$fc.raw.file, collapse=";"), paste(cont_data$intensity, collapse=";"))
          cat(pasten(report_short, report_samples, report_samples2), file=fh_out$stats_file, append=T, sep="\n")
          cat(pastet("contamination-proteins:", ca, paste((d_pg$majority.protein.ids[pg_idx]), collapse=",")), file=fh_out$stats_file, append=T, sep="\n") 
        }
        
      } ## contaminant loop
      
      ## ms.ms.count is always 0 when mtd has a number; 'type' is always "MULTI-MATCH" and ms.ms.ids is empty!
      #dsub = d_evd[,c("ms.ms.count", "match.time.difference")]
      #head(dsub[is.na(dsub[,2]),])
      #sum(0==(dsub[,1]) & is.na(dsub[,2]))
      ##
      ## MQ1.4 MTD is either: NA or a number
      ##
      
      ## intensity of peptides
      param_name_EV_intThresh = "File$Evidence$IntensityThreshLog2_num"
      param_def_EV_intThresh = 23 ## default median intensity in log2 scale
      param_EV_intThresh = getYAML(yaml_obj, param_name_EV_intThresh, param_def_EV_intThresh)
      if (!is.numeric(param_EV_intThresh) || !(param_EV_intThresh %in% 1:100))
      { ## reset if value is weird
        cat("YAML value for '" %+% param_name_EV_intThresh %+% "' is invalid ('" %+% param_EV_protThresh %+% "'). Using default of " %+% param_def_EV_intThresh %+% ".")
        param_EV_intThresh = param_def_EV_intThresh
      }
      
      colnames(d_evd)
      medians_pep = ddply(d_evd[ ,c("fc.raw.file", "intensity")], "fc.raw.file",
                          function(x) data.frame(med = log2(quantile(x$intensity, probs=0.5, na.rm=T))))
      
      int_dev_pep = RSD((medians_pep$med))
      int_dev.s = pastet("INT RSD [%]", round(int_dev_pep, 3))
      lpl = boxplotCompare(data = d_evd[, c("fc.raw.file", "intensity", "contaminant")],
                           log2 = T, 
                           mainlab="EVD: peptide intensity distribution",
                           ylab = expression(log[2]*" intensity"),
                           sublab=paste0("RSD ", round(int_dev_pep, 1),"% (expected < 5%)\n"),
                           abline = param_EV_intThresh)
      #for (pl in lpl) print(pl)
      for (pl in lpl) rep_data$add(pl)
      ## QC measure for peptide intensity
      qc_pepint = medians_pep
      cname = "X003X_catPrep_EVD:~Pep~Intensity~(\">" %+% param_def_EV_intThresh %+% "\")"
      qc_pepint[,cname] = qualLinThresh(2^qc_pepint$med, 2^param_def_EV_intThresh) ## use non-log space 
      QCM[["EVD.PepIntensity"]] = qc_pepint[, c("fc.raw.file", cname)]
      
      ## only count protein groups from non-inferred evidence
      # get only the column without MTDs
      #   contains NA if 'genuine' ID
      d_evd$hasMTD = !is.na(d_evd$match.time.difference)
      
      pgc = getProteinAndPeptideCounts(d_evd[, c("protein.group.ids", "fc.raw.file", "modified.sequence", "match.time.difference")])
      head(pgc)
      
      ## re-order (ddply somehow reorders, even if we use ordered factors...)
      pgc$fc.raw.file = factor(pgc$fc.raw.file, levels = mq$raw_file_mapping$to, ordered = TRUE)
      #levels(pgc$fc.raw.file)
      ## report Match-between-runs data only if if it was enabled
      reportMTD = any(d_evd$hasMTD)
      
      ## show Prot & Pep stats
      pgc$block = factor(assignBlocks(pgc$fc.raw.file, 30))
      max_prot = max(unlist(dlply(pgc, "fc.raw.file", function(x) sum(x$proteinCounts))))
      ## average gain in percent
      gain_text = ifelse(reportMTD, sprintf("MBR gain: +%.0f%%", mean(pgc$proteinMBRgain, na.rm=T)), "")
      
      ## get scoring threshold (upper limit)
      param_name_EV_protThresh = "File$Evidence$ProteinCountThresh_num"
      param_def_EV_protThresh = 3500
      param_EV_protThresh = getYAML(yaml_obj, param_name_EV_protThresh, param_def_EV_protThresh)
      if (!is.numeric(param_EV_protThresh) || !(param_EV_protThresh %in% 1:1e5))
      { ## reset if value is weird
        cat("YAML value for '" %+% param_name_EV_protThresh %+% "' is invalid ('" %+% param_EV_protThresh %+% "'). Using default of " %+% param_def_EV_protThresh %+% ".")
        param_EV_protThresh = param_def_EV_protThresh
      }
      
      ddply(pgc, "block", .fun = function(x)
      {
        #print(
        rep_data$add(
                ggplot(x, aes_string(x = "fc.raw.file", y = "proteinCounts", fill = "category")) +
                  geom_bar(stat = "identity", position = "stack") +
                  xlab("") +
                  ylab("count") +
                  scale_x_discrete_reverse(x$fc.raw.file) +
                  ylim(0, max(param_EV_protThresh, max_prot)*1.1) +
                  scale_fill_manual(values = c("green", "#BEAED4", "red")) +
                  addGGtitle("EVD: ProteinGroups count", gain_text) + 
                  geom_abline(alpha = 0.5, intercept = param_EV_protThresh, slope = 0, colour = "black", linetype = "dashed", size = 1.5) +
                  coord_flip()
        )
        return (1)
      })
      ## QC measure for protein ID performance
      qc_protc = ddply(pgc[grep("^genuine", pgc$category), ], "fc.raw.file", function(x){data.frame(genuineAll = sum(x$proteinCounts))})
      cname = "X045X_catGen_EVD:~Prot~Count~(\">" %+% param_EV_protThresh %+% "\")"
      qc_protc[,cname] = qualLinThresh(qc_protc$genuineAll, param_EV_protThresh)
      QCM[["EVD.ProtCount"]] = qc_protc[, c("fc.raw.file", cname)]
      
      
      ##
      ## EVD: peptide count
      ##
      max_pep = max(unlist(dlply(pgc, "fc.raw.file", function(x) sum(x$peptideCounts))))
      ## average gain in percent
      gain_text = ifelse(reportMTD, sprintf("MBR gain: +%.0f%%", mean(pgc$peptideMBRgain, na.rm=T)), "")
            
      ## get scoring threshold (upper limit)
      param_name_EV_pepThresh = "File$Evidence$PeptideCountThresh_num"
      param_def_EV_pepThresh = 15000
      param_EV_pepThresh = getYAML(yaml_obj, param_name_EV_pepThresh, param_def_EV_pepThresh)
      if (!is.numeric(param_EV_pepThresh) || !(param_EV_pepThresh %in% 1:1e6))
      { ## reset if value is weird
        cat("YAML value for '" %+% param_name_EV_pepThresh %+% "' is invalid ('" %+% param_EV_pepThresh %+% "'). Using default of " %+% param_def_EV_pepThresh %+% ".")
        param_EV_pepThresh = param_def_EV_pepThresh
      }
      
      #require(RColorBrewer)
      ddply(pgc, "block", .fun = function(x)
      {
        p = ggplot(x, aes_string(x = "factor(fc.raw.file)", y = "peptideCounts", fill = "category")) +
          geom_bar(stat = "identity", position = "stack") +
          xlab("") +
          ylab("count") +
          scale_x_discrete_reverse(x$fc.raw.file) +
          ylim(0, max(param_EV_pepThresh, max_pep)*1.1) +
          geom_abline(alpha = 0.5, intercept = param_EV_pepThresh, slope = 0, colour = "black", linetype = "dashed", size = 1.5) +
          scale_fill_manual(values = c("green", "#BEAED4", "red")) +
          addGGtitle("EVD: Peptide ID count", gain_text) + 
          coord_flip()
        #print(p)
        rep_data$add(p)
        return (1)
      })
      
      ## QC measure for peptide ID performance
      qc_pepc = ddply(pgc[grep("^genuine", pgc$category), ], "fc.raw.file", function(x){data.frame(genuineAll = sum(x$peptideCounts))})
      cname = "X040X_catGen_EVD:~Pep~Count~(\">" %+% param_EV_pepThresh %+% "\")"
      qc_pepc[,cname] = qualLinThresh(qc_pepc$genuineAll, param_EV_pepThresh)
      QCM[["EVD.PepCount"]] = qc_pepc[, c("fc.raw.file", cname)]
      
      ####
      #### peak length (not supported in MQ 1.0.13)
      ####
      cat("EVD: RT peak width distribution ...\n")
      
      if ("retention.length" %in% colnames(d_evd))  
      {
        ## compute some summary stats before passing data to ggplot (performance issue for large experiments) 
        fcn_peakWidthOverTime = function(x, bin_width = 60) 
        {      
          r = range(x$retention.time)
          brs = seq(from=r[1], to=r[2]+bin_width/60, by=bin_width/60)
          x$bin = cut(x$retention.time, breaks=brs, include.lowest=T)
          retLStats = ddply(x, "bin", .fun = function(xb) {
            data.frame(mid = brs[as.numeric(xb$bin[1])], retlengthAvg = median(xb$retention.length, na.rm=T))
          })
          return(retLStats)
        }
        
        d_evd.m.d = ddply(d_evd[,c("retention.time", "retention.length", "fc.raw.file")], "fc.raw.file", .fun = fcn_peakWidthOverTime)
        head(d_evd.m.d)
        tail(d_evd.m.d)
        ## median peak width
        d_evd.m.d_med = ddply(d_evd[,c("retention.length","fc.raw.file")], "fc.raw.file", .fun = function(x) {
          #fcr = as.character(x$fc.raw.file[1])
          #cat(fcr)
          m = median(x$retention.length, na.rm=T);
          return(data.frame(median = m))
        })
        
        
        d_evd.m.d$block = factor(assignBlocks(d_evd.m.d$fc.raw.file, 8))
        ## identical limits for all plots
        d_evd.xlim = quantile(d_evd.m.d$mid, c(0,1), na.rm=T)
        d_evd.ylim = quantile(d_evd.m.d$retlengthAvg, c(0,1), na.rm=T)
        
        fcn_plotPeakWidth = function(data)
        {
          d_evd.m.d_med_sub = d_evd.m.d_med[ d_evd.m.d_med$fc.raw.file %in% data$fc.raw.file, ]
          ## augment legend with average peak width[m]
          data$fc.raw.file = paste0(data$fc.raw.file, " (~", 
                                    round(d_evd.m.d_med_sub$median[match(data$fc.raw.file, d_evd.m.d_med_sub$fc.raw.file)], 1),
                                    " min)")
          ## manually convert to factor to keep old ordering (otherwise ggplot will sort it, since its a string)
          data$fc.raw.file = factor(data$fc.raw.file, levels = unique(data$fc.raw.file), ordered=T)
          d_evd.m.d_med_sub$fc.raw.file = paste0(d_evd.m.d_med_sub$fc.raw.file, " (~", 
                                                 round(d_evd.m.d_med_sub$median[match(d_evd.m.d_med_sub$fc.raw.file, d_evd.m.d_med_sub$fc.raw.file)], 1),
                                                 " min)")
          pl = ggplot(data) +
            geom_line(aes_string(x = "mid", y = "retlengthAvg", colour = "fc.raw.file"), size=1, alpha=0.7) +
            scale_color_manual(values = brewer.pal(length(unique(data$fc.raw.file)), "Set1")) +
            guides(color = guide_legend(title = "Raw file with\naverage peak width")) +
            xlab("retention time [min]") +
            ylab("peak width [min]") +
            ylim(d_evd.ylim) +
            ggtitle("EVD: Peak width over RT") +
            theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
            pointsPutX(x_range=range(data$mid), x_section=c(0.03,0.08), y=d_evd.m.d_med_sub$median, col=d_evd.m.d_med_sub$fc.raw.file[,drop=T])
          
          #print(pl)
          rep_data$add(pl)
        }
        for (bl in unique(d_evd.m.d$block))
        { ## needs to be within a function, otherwise rep_data$add and print() somehow have delayed eval's which confused ggplot...
          fcn_plotPeakWidth(data = d_evd.m.d[d_evd.m.d$block==bl,])
        }
        
        
        ## QC measure for reproducibility of peak shape
        ##.. create a list of distributions
        l_dists = dlply(d_evd[,c("retention.length","fc.raw.file")], "fc.raw.file", function(x) return(x$retention.length))
        qc_evd_PeakShape = qualBestKS(l_dists)
        colnames(qc_evd_PeakShape) = c("fc.raw.file", "X017X_catLC_EVD:~RT~Peak~Width")
        QCM[["EVD.PeakShape"]] = qc_evd_PeakShape
      } ## end retention length (aka peak width)
      
      ##
      ## retention time calibration (to see if window was sufficiently large)
      ## (not supported in MQ 1.0.13)  
      ## Even if MBR=off, this column always contains numbers (usually 0, or very small)
      ##
      if ("retention.time.calibration" %in% colnames(d_evd))
      {
        ## this should enable us to decide if MBR was used (we could also look up parameters.txt -- if present)
        MBR_HAS_DATA = (sum(d_evd$type == "MULTI-MATCH") > 0)
        
        param_name_mbr = "File$Evidence$MatchBetweenRuns_wA"
        param_evd_mbr = getYAML(yaml_obj, param_name_mbr, "auto")
        if ((param_evd_mbr == FALSE) || (MBR_HAS_DATA == FALSE))
        {
          ## MBR is not evaluated
        } else
        {
          ## find reference
          if ('fraction' %in% colnames(d_evd)) {
            refRaw = NA
            col_fraction = "fraction"
            txt_subtitle = "fraction: neighbour comparison"
            evd_has_fractions = TRUE
            d_evd$fraction[is.na(d_evd$fraction)] = 32000
          } else {
            refRaw = findAlignReference(d_evd)
            col_fraction = c()
            txt_subtitle = ""
            evd_has_fractions = FALSE
          } 
          if (length(refRaw) != 1) {
            ggText("EVD: Alignment check", paste0("Cannot find a unique reference Raw file (files: ",paste(refRaw, collapse=", "), ")"))
          } else {
            
            ## find RT curve based on genuine 3D peaks (should be flat)
            d_alignQ = alignmentCheck(d_evd[(d_evd$type %in% c("MULTI-MSMS")), 
                                            c("calibrated.retention.time", 
                                              "id", "raw.file", col_fraction, "modified.sequence", "charge")], 
                                      referenceFile = refRaw)
            ## augment more columns
            d_alignQ$retention.time.calibration = d_evd$retention.time.calibration[match(d_alignQ$id, d_evd$id)]
            
            if (nrow(d_alignQ)==0)
            { ## very unusual case: reference contains no evidence -- e.g. pull-down experiment
              rep_data$add(
                ggText("EVD: RT Distance of peptides from reference after alignment", "Alignment cannot be verfied -- no data.")
              )
            } else {
              ## filter data (reduce PDF file size)
              evd_RT_t = thinOutBatch(d_alignQ,
                                      "calibrated.retention.time",
                                      "raw.file")
              evd_RT_t$fc.raw.file = renameFile(evd_RT_t$raw.file, mq$raw_file_mapping)
              
              ## param
              param_name_EV_MatchingTolerance = "File$Evidence$MQpar_MatchingTimeWindow_num"
              param_def_EV_MatchingTolerance = 1
              param_EV_MatchingTolerance = getYAML(yaml_obj, param_name_EV_MatchingTolerance, param_def_EV_MatchingTolerance)
              if (param_useMQPAR) {
                v = getMQPARValue(txt_files$mqpar, "matchingTimeWindow") ## will also warn() if file is missing
                if (!is.null(v)) {
                  param_EV_MatchingTolerance = setYAML(yaml_obj, param_name_EV_MatchingTolerance, as.numeric(v))
                }
              }
                         
              ## QC measure for alignment quality
              ## compute % of matches within matching boundary (1 min by default)
              qcAlign = ScoreInAlignWindow(d_alignQ, param_EV_MatchingTolerance)
              if (!is.na(refRaw)) { ## rescue reference file (it will not show up in fraction-less data, and would otherwise be scored 'red')
                qcAlign = rbind(qcAlign, data.frame(raw.file=refRaw, withinRT=1))
              }
              cname = "X021X_catLC_EVD:~MBR~Align"
              qcAlign[, cname] = qcAlign$withinRT
              QCM[["EVD.MBR_Align"]] = qcAlign[, c("raw.file", cname)]
              
              qcAlign$fc.raw.file = renameFile(qcAlign$raw.file, mq$raw_file_mapping)
              qcAlign$newlabel = qcAlign$fc.raw.file
              if (evd_has_fractions)
              { ## amend fc.raw.file with fraction number
                qcAlign$fraction = d_evd$fraction[match(qcAlign$fc.raw.file, d_evd$fc.raw.file)]
                qcAlign$newlabel = paste0(qcAlign$fc.raw.file, " - frc", qcAlign$fraction)
              }
              ## amend fc.raw.file with % good ID pairs
              qcAlign$newlabel = paste0(qcAlign$newlabel, " (", round(qcAlign$withinRT*100), "% good)")
              evd_RT_t$fc.raw.file_augment = evd_RT_t$fc.raw.file
              levels(evd_RT_t$fc.raw.file_augment) = qcAlign$newlabel[match(levels(evd_RT_t$fc.raw.file_augment), qcAlign$fc.raw.file)]

              evd_RT_t$RTdiff_in = c("green", "red")[(abs(evd_RT_t$rtdiff) > param_EV_MatchingTolerance)+1]
              
              ## plot alignment result
  
              splitRTAlignByRawFile = function(RTdata, ylim_g)
              {
                #RTdata = evd_RT_t[ evd_RT_t$fc.raw.file == "file 13",]
                pl = ggplot(RTdata, aes_string(x="calibrated.retention.time", y="retention.time.calibration")) + 
                  ## the MaxQuant correction (plot real data, no spline, since it can be very irregular)
                  geom_line(aes(alpha=0.7), color = "blue") +
                  ## PTXQC correction
                  geom_point(aes_string(x="calibrated.retention.time", y="rtdiff", color="RTdiff_in"), alpha=0.5) + 
                  scale_alpha(name = 'Alignment function', 
                              labels = list(expression("MaxQuant" ~ Delta*"RT")),
                              range=c(1,1)) + 
                  scale_colour_manual(name = expression(bold("ID pairs ("*Delta*"RT to Ref)")), 
                                      values = c("green"="green", "red"="red"),
                                      labels=c("green" = paste0("good (<",param_EV_MatchingTolerance,"min)"), 
                                                 "red" = paste0("bad (>",param_EV_MatchingTolerance,"min)"))) +
                  guides(colour = guide_legend(order = 2), 
                          alpha = guide_legend(order = 1)) +   ## alpha-legend on top, color below
                  ylim(ylim_g) +
                  xlab("corrected RT [min]") +
                  ylab(expression(Delta*"RT [min]")) +
                  facet_wrap(~ fc.raw.file_augment) +
                  addGGtitle("EVD: MBR - alignment", txt_subtitle)  
                #print(pl)
                rep_data$add(pl)
                return(1)
              }
              ylim_g = quantile(c(evd_RT_t$rtdiff, evd_RT_t$retention.time.calibration), probs=c(0.01,0.99), na.rm=T) * 1.1
              byX(evd_RT_t, evd_RT_t$fc.raw.file, 3*3, splitRTAlignByRawFile, sort_indices = F, ylim_g)

              ## test shape of mass-error:
#               vv = ddply(d_evd, "fc.raw.file", function(x) {
#                 ## only matched
#                 xx = x[!is.na(x$match.time.difference),]
#                 h = hist(xx$mass.error..ppm., 100, main=x$fc.raw.file[1], add=T)
#                 data.frame(m = h$mids, d = h$density)
#               })
#               ggplot(vv) + geom_line(aes(x=m, y=d, col=fc.raw.file))
              ## --> not discriminatory :(
              
              
              ## save some memory
              if (!exists("DEBUG_PTXQC")) {
                rm("evd_RT_t")
                rm("proj_align_h")
              }
            } ## no data
          } ## ambigous reference file

### 
###     MBR: ID transfer
###


          ## increase of segmentation by MBR:
          ## three values returned: single peaks(%) in genuine, transferred and all(combined)
          qMBR = peakSegmentation(d_evd)
          head(qMBR)
          ## for groups: get their RT-spans
          ## ... genuine ID's only (as 'rtdiff_genuine') 
          ##  or genuine+transferred (as 'rtdiff_mixed'))
          ## Could be empty (i.e. no groups, just singlets) if data is really sparse ..
          qMBRSeg_Dist = idTransferCheck(d_evd)
          #head(qMBRSeg_Dist)
          #head(qMBRSeg_Dist[qMBRSeg_Dist$fc.raw.file=="file 13",])
          

          ## Check which fraction of ID-pairs belong to the 'in-width' group.
          ## The allowed RT delta is given in 'd_evd.m.d_med' (estimated from global peak width for each file)
          qMBRSeg_Dist_inGroup = inMatchWindow(qMBRSeg_Dist, df.allowed.deltaRT = d_evd.m.d_med)
          ## puzzle together final picture
          scoreMBRMatch = computeMatchRTFractions(qMBR, qMBRSeg_Dist_inGroup)
          #head(scoreMBRMatch)
          #scoreMBRMatch[scoreMBRMatch$fc.raw.file=="file 3",]
          
          qualMBR.m = merge(scoreMBRMatch[scoreMBRMatch$sample=="genuine",], 
                            scoreMBRMatch[scoreMBRMatch$sample=="transferred",], by="fc.raw.file")
          qualMBR.m = merge(qualMBR.m, scoreMBRMatch[scoreMBRMatch$sample=="all",], by="fc.raw.file")
          cname = "X022X_catLC_EVD:~MBR~ID-Transfer"
          qualMBR.m[, cname] = 1 - qualMBR.m$multi.outRT.y # could be NaN if: no-transfer at all, or: no groups but only singlets transferred
          qualMBR.m[is.na(qualMBR.m$multi.outRT.y) & !is.na(qualMBR.m$single.y), cname] = 1 ## only singlets transferred, wow...
          qualMBR.m[is.na(qualMBR.m[, cname]), cname] = HEATMAP_NA_VALUE
          QCM[["EVD.MBR_IDTransfer"]] = qualMBR.m[, c("fc.raw.file", cname)]
          QCM[["EVD.MBR_IDTransfer"]]
          
          uniqueRMatchByRawFile = function(RTdata)
          {
            RTdata.m = melt(RTdata, id.vars=c("fc.raw.file", "sample"))
            RTdata.m$value = RTdata.m$value * 100 ## used to be scores in [0-1]
            pl = ggplot(RTdata.m) + 
              geom_bar(aes_string(x="fc.raw.file", y="value", fill="variable"), stat="identity", position="stack") + 
              scale_fill_manual("peak class", 
                                values = c("single"="green", "multi.inRT"="lightgreen", "multi.outRT"="red"),
                                labels=c("single", "group (in width)", "group (out width)")) +
              ylim(0, 100.1) + ## ggplot might not show the last (red) group upon 100.0
              xlab("") +
              ylab("fraction of 3D-peaks [%]") +
              coord_flip() + 
              scale_x_discrete_reverse(factor(RTdata$fc.raw.file)) +
              ggtitle("EVD: MBR - ID Transfer") + 
              facet_wrap(~sample)
            #print(pl)
            rep_data$add(pl)
            return(1)
          }

          byX(scoreMBRMatch, scoreMBRMatch$fc.raw.file, 12, uniqueRMatchByRawFile, sort_indices = F)
          
          ##
          ## MBR: Tree Clustering
          ##
          rep_data$add(
          #print(  
            RTalignmentTree(d_evd[(d_evd$type %in% c("MULTI-MSMS")), 
                                  c("calibrated.retention.time", "fc.raw.file", col_fraction, "modified.sequence", "charge")],
                            col_fraction = col_fraction)
          )
          
          ##
          ## MBR: additional evidence by matching MS1 by AMT across files
          ##
          if (any(d_evd$match.time.difference, na.rm=T)) {
            ## scatter plot: for each raw file give median time diff and # peptides used for matching
            mtr.df = ddply(d_evd, "fc.raw.file", function(x) {
              match_count_abs = sum(!is.na(x$match.time.difference))
              match_count_pc  = round(100*sum(!is.na(x$match.time.difference))/nrow(x))
              return (data.frame(abs = match_count_abs, pc = match_count_pc))
            })
            
            p_amt = ggplot(data=mtr.df, aes_string(x = "abs", y = "pc", col = "fc.raw.file")) + 
              geom_point(size=2) + 
              #geom_text(size=2, vjust=1, aes_string(alpha=0.5)) + 
              ggtitle(paste0("EVD: Peptides inferred by AMT-matching\n", round(100*sum(!is.na(d_evd$match.time.difference))/nrow(d_evd)) ,"% average" )) +
              xlab("inferred by MS1 [count]") +
              ylab("inferred by MS1 [%]") +
              xlim(0, max(mtr.df$abs, na.rm=T)*1.1) +
              ylim(0, max(mtr.df$pc, na.rm=T)*1.1)
            #install.packages("directlabels")
            #require(directlabels)
            rep_data$add(direct.label(p_amt, list(cex=0.5, "smart.grid")))
            #print(p_amt)
          } ## AMT 
        
        } ## MBR has data

      } ## retention.time.difference column exists
      
      
      ##
      ## charge distribution
      ##
      ##  (this uses genuine peptides only -- no MBR!)
      ## 
      fcChargePlot = function(d_sub)
      {
        rep_data$add(
          #print(
          mosaicPlot(d_sub$fc.raw.file, d_sub$charge) +
            xlab("Raw file") +
            ylab("fraction [%]") +
            guides(fill=guide_legend(title="charge"), color=FALSE) + # avoid black line in legend
            scale_x_reverse() +
            coord_flip() +
            theme(axis.text.y=element_blank(), axis.ticks=element_blank()) +
            ggtitle("EVD: charge distribution")
        )
        return (1);
      }
      byXflex(d_evd[!d_evd$hasMTD, c("fc.raw.file", "charge")], d_evd$fc.raw.file[!d_evd$hasMTD],
              30, fcChargePlot, sort_indices = FALSE)
      
      ## QC measure for charge centeredness
      qc_charge = ddply(d_evd[!d_evd$hasMTD, c("charge",  "raw.file")], "raw.file", function(x) data.frame(c = (sum(x$charge==2)/nrow(x))))
      cname = "X010X_catPrep_EVD:~Charge"
      qc_charge[, cname] = qualMedianDist(qc_charge$c)
      QCM[["EVD.charge2"]] = qc_charge[, c("raw.file", cname)]
      
      ##
      ## peptides per RT
      ##
      cat("EVD: Peptides over RT ...\n")
      raws_perPlot = 8
      smr_evdRT = summary(d_evd$retention.time)
      max_y = max(by(d_evd$retention.time, d_evd$fc.raw.file,  function(d) max(hist(d, breaks=seq(from=min(d)-3, to=max(d)+3, by=3), plot=F)$counts)))
      fcRTSubset <- function(d_sub, smr_evdRT)
      {
        nrOfRaws = length(unique(d_sub$fc.raw.file))
        qp = ggplot(data = d_sub, aes_string(x = "retention.time", colour = "fc.raw.file", linetype = "fc.raw.file")) +
          geom_freqpoly(binwidth = 3) +
          xlim(from = smr_evdRT["Min."] - 1, to = smr_evdRT["Max."] + 2) +
          xlab("RT [min]") + 
          ylim(from = 0, to = max_y) +
          ylab("ID count") +
          ggtitle("EVD: IDs over RT") +
          theme(legend.title=element_blank()) +
          scale_linetype_manual(values = rep_len(c("solid", "dashed"), nrOfRaws)) +
          scale_color_manual(values = brewer.pal(nrOfRaws, "Set1")) 
        #print(qp)
        rep_data$add(qp)
        return (1)
      }
      byXflex(d_evd, d_evd$raw.file, raws_perPlot, fcRTSubset, smr_evdRT=smr_evdRT, sort_indices = FALSE)
      
      ## QC measure for uniform-ness
      QCM[["ID_rate_over_RT"]] = ddply(d_evd[, c("retention.time",  "raw.file")], "raw.file", 
                                       function(x) data.frame("X015X_catLC_EVD:~ID~rate~over~RT" = qualUniform(x$retention.time), 
                                                              check.names = F))
      
      
##
## barplots of mass error
##
cat("EVD: Precursor Mass Error ...\n")

## MQ seems to mess up mass recal on some (iTRAQ/TMT) samples, by reporting ppm errors which include modifications
## , thus one sees >1e5 ppm, e.g. 144.10 Da
##  this affects both 'uncalibrated.mass.error..ppm.'   and
##                    'mass.error..ppm.'
## HOWEVER, 'uncalibrated...calibrated.m.z..ppm.' seems unaffected, but is not available in all MQ versions :(
##    also, 'mass' and 'm/z' columns seem unaffected.
## We cannot always reconstruct mass_error[ppm] from 'm/z' and mass columns 
## since 'm/z' is just too close to the theoretical value or islacking precision of the stored numbers.
##
## The MQ list reports one case with high ppm error (8000), where the KR.count was at fault. We cannot
## reconstruct this.
##
## Also, MaxQuant will not report uncalibrated mass errors if the data are too sparse for a given Raw file.
## Then, 'uncalibrated.mass.error..ppm.' will be 'NaN' throughout -- but weirdly, calibrated masses will be reported.
##

param_name_EV_PrecursorTolPPM = "File$Evidence$MQpar_firstSearchTol_num"
param_def_EV_PrecursorTolPPM = 20
param_EV_PrecursorTolPPM = getYAML(yaml_obj, param_name_EV_PrecursorTolPPM, param_def_EV_PrecursorTolPPM)
if (param_useMQPAR) {
  v = getMQPARValue(txt_files$mqpar, "firstSearchTol") ## will also warn() if file is missing
  if (!is.null(v)) {
    param_EV_PrecursorTolPPM = setYAML(yaml_obj, param_name_EV_PrecursorTolPPM, as.numeric(v))
  }
}

param_name_EV_PrecursorOutOfCalSD = "File$Evidence$firstSearch_outOfCalWarnSD_num"
param_def_EV_PrecursorOutOfCalSD = 2
param_EV_PrecursorOutOfCalSD = getYAML(yaml_obj, param_name_EV_PrecursorOutOfCalSD, param_def_EV_PrecursorOutOfCalSD)

##
## check for MS1-out-of-calibration (i.e. the tol-window being too small)
##
## heuristic to determine if the instrument is completely out of calibration, 
## i.e. all ID's are false positives, since the Precursor mass is wrong
## -- we use the SD; if larger than 2ppm, 
## then ID's are supposedly random
## -- alt: we use the 1%-to-99% quantile range: if > 10ppm
## -- uninformative for detection is the distribution (it's still Gaussian for a strange reason)
MS1_decal_smr = ddply(d_evd, "raw.file", function(x) 
  data.frame(n = nrow(x), 
             sd = round(sd(x$mass.error..ppm., na.rm=T), 1), 
             range = diff(quantile(x$mass.error..ppm., c(0.01, 0.99), na.rm=T))))
## additionally use MS2-ID rate (should be below 1%)
if (enabled_summary) {
  MS1_decal_smr = merge(MS1_decal_smr, d_smy$raw[, c("raw.file", "ms.ms.identified....")])
} else {
  MS1_decal_smr$ms.ms.identified.... = 0 ## upon no info: assume low IDrate
}

MS1_decal_smr$lowIDRate = MS1_decal_smr$ms.ms.identified.... < 1
MS1_decal_smr$hasMassErrorBug = FALSE
MS1_decal_smr$hasMassErrorBug_unfixable = FALSE
recal_message = ""
recal_message_post = ""
## check each raw file individually (usually its just a few who are affected)
de_cal = ddply(d_evd, "raw.file", .fun = function(x) data.frame(q = (quantile(abs(x$uncalibrated.mass.error..ppm.), probs = 0.5, na.rm=T) > 1e3)))
if (any(de_cal$q, na.rm=T))
{
  recal_message = "MQ bug: data rescued"
  recal_message_post = 'MQ bug: data cannot be rescued'
  
  de_cal$fc.raw.file = renameFile(de_cal$raw.file, mq$raw_file_mapping)
  MS1_decal_smr$hasMassErrorBug[ MS1_decal_smr$raw.file %in% de_cal$raw.file[de_cal$q > 0] ] = TRUE
  
  ## re-compute 'uncalibrated.mass.error..ppm.' and 'mass.error..ppm.'
  d_evd$theomz = d_evd$mass / d_evd$charge + 1.00726
  d_evd$mass.error..ppm.2 = (d_evd$theomz - d_evd$m.z) / d_evd$theomz * 1e6
  d_evd$uncalibrated.mass.error..ppm.2 = d_evd$mass.error..ppm.2 + d_evd$uncalibrated...calibrated.m.z..ppm.

  
  ## check if fix worked
  de_cal2 = ddply(d_evd, "raw.file", .fun = function(x)  data.frame(q = (median(abs(x$uncalibrated.mass.error..ppm.2), na.rm=T) > 1e3)))
  if (any(de_cal2$q))
  { ## fix did not work
    MS1_decal_smr$hasMassErrorBug_unfixable[ MS1_decal_smr$raw.file %in% de_cal2$raw.file[de_cal2$q] ] = TRUE
    recal_message = "m/z recalibration bugfix applied but failed\n(there are still large numbers)"
  }
  
  idx_overwrite = (d_evd$raw.file %in% de_cal$raw.file[de_cal$q > 0])
  ## overwrite original values
  d_evd$mass.error..ppm.[idx_overwrite] = d_evd$mass.error..ppm.2[idx_overwrite]
  d_evd$uncalibrated.mass.error..ppm.[idx_overwrite] = d_evd$uncalibrated.mass.error..ppm.2[idx_overwrite]
}

MS1_decal_smr$outOfCal = (MS1_decal_smr$sd > param_EV_PrecursorOutOfCalSD) & MS1_decal_smr$lowIDRate & 
                         (MS1_decal_smr$sd < 100)  ## upper bound, to distinguish from MQ bug (which has much larger SD's)

## report too small search tolerance
if (any(MS1_decal_smr$outOfCal)) recal_message = "search tolerance too small"


## Raw files where the mass error is obviously wrong (PSM's not substracted etc...)
affected_raw_files = MS1_decal_smr$raw.file[MS1_decal_smr$outOfCal | MS1_decal_smr$hasMassErrorBug]

plotPCUnCal = function(d_sub, affected_raw_files, ylim_g)
{
  d_sub$col = "default"
  if (length(affected_raw_files) > 0) d_sub$col = c("default", "MQ bug")[(d_sub$raw.file %in% affected_raw_files) + 1]
  ## add 'out-of-calibration' Raw files:
  ooc_raw = MS1_decal_smr$raw.file[MS1_decal_smr$outOfCal]
  d_sub$col[d_sub$raw.file %in% ooc_raw] = "out-of-search-tol"
  ## only show legend if special things happen  
  showColLegend = ifelse(length(setdiff(d_sub$col, "default")) > 0, "legend", "none")
  
  ## amend SD to fc.raw.file
  d_sub$fc.raw.file = paste0(d_sub$fc.raw.file, " (sd = ", MS1_decal_smr$sd[match(d_sub$raw.file, MS1_decal_smr$raw.file)], "ppm)")
  d_sub$fc.raw.file = factor(d_sub$fc.raw.file, levels=unique(d_sub$fc.raw.file), ordered=T)
  
  pl = ggplot(d_sub, col=d_sub$col) +
      geom_boxplot(aes_string(x = "fc.raw.file", y = "uncalibrated.mass.error..ppm.", col="col"), varwidth=TRUE, outlier.shape = NA) +
      scale_colour_manual("", values = c("default"="black", "MQ bug"="red", "out-of-search-tol"="red"), guide=showColLegend) +
      ylab(expression(Delta~"mass [ppm]")) +
      xlab("") +
      ylim(ylim_g) +
      scale_x_discrete_reverse(d_sub$fc.raw.file) +
      geom_hline(yintercept = c(-param_EV_PrecursorTolPPM, param_EV_PrecursorTolPPM), 
                 colour="red",
                 linetype = "longdash") +  ## == vline for coord_flip
      coord_flip() +
      addGGtitle("EVD: Uncalibrated mass error", recal_message)
  #print(pl)
  rep_data$add(pl)
  return(1)
}
## some outliers can have ~5000ppm, blowing up the plot margins
## --> remove outliers 
ylim_g = range(boxplot.stats(d_evd$uncalibrated.mass.error..ppm.)$stats[c(1, 5)], c(-param_EV_PrecursorTolPPM, param_EV_PrecursorTolPPM) * 1.05)
byXflex(d_evd, d_evd$fc.raw.file, 20, plotPCUnCal, sort_indices=F, affected_raw_files=affected_raw_files, ylim_g)

## scores
qc_MS1deCal = ddply(d_evd[, c("uncalibrated.mass.error..ppm.", "raw.file")], "raw.file", 
                    function(x) {
                      xd = na.omit(x$uncalibrated.mass.error..ppm.)
                      if (length(xd)==0) {
                        r = HEATMAP_NA_VALUE ## if empty, give the Raw file an 'NA' score
                      } else if (MS1_decal_smr$outOfCal[MS1_decal_smr$raw.file == x$raw.file[1]]) {
                        r = 0 ## if we suspect out-of-calibration, give lowest score
                      } else r = qualCenteredRef(xd, param_EV_PrecursorTolPPM)
                      return (data.frame(med_rat = r))
                    })

colnames(qc_MS1deCal) = c("raw.file", "X026X_catMS_EVD:~MS~Cal-Pre~(" %+% param_EV_PrecursorTolPPM %+% ")")
QCM[["X026X.EVD.MS_Cal-Pre"]] = qc_MS1deCal


##
## post calibration
##
cat("EVD: Precursor Mass Error (post calibration) ...\n")

param_name_EV_PrecursorTolPPMmainSearch = "File$Evidence$MQpar_mainSearchTol_num"
param_def_EV_PrecursorTolPPMmainSearch = NA  ## we do not dare to have a default, since it ranges from 6 - 4.5 ppm across MQ versions
param_EV_PrecursorTolPPMmainSearch = getYAML(yaml_obj, param_name_EV_PrecursorTolPPMmainSearch, param_def_EV_PrecursorTolPPMmainSearch)
if (param_useMQPAR) {
  v = getMQPARValue(txt_files$mqpar, "mainSearchTol") ## will also warn() if file is missing
  if (!is.null(v)) {
    param_EV_PrecursorTolPPMmainSearch = setYAML(yaml_obj, param_name_EV_PrecursorTolPPMmainSearch, as.numeric(v))
  }
}
if (is.na(param_EV_PrecursorTolPPMmainSearch))
{
  warning("PTXQC: Cannot draw borders for calibrated mass error, since neither 'File$Evidence$MQpar_mainSearchTol_num' is set nor a mqpar.xml file is present!", immediate.=T)
}

plotPCCal = function(d_sub, affected_raw_files, ylim_g)
{
  d_sub$col = "default"
  if (length(affected_raw_files) > 0) {
    d_sub$col = c("default", "MQ bug")[(d_sub$raw.file %in% affected_raw_files) + 1]
    d_sub$mass.error..ppm.[d_sub$raw.file %in% affected_raw_files] = 0
    if (all(d_sub$mass.error..ppm.==0)) d_sub$mass.error..ppm.=rnorm(nrow(d_sub),sd=0.0001, mean=mean(ylim_g))
  }
  ## add 'out-of-calibration' Raw files:
  ooc_raw = MS1_decal_smr$raw.file[MS1_decal_smr$outOfCal]
  d_sub$col[d_sub$raw.file %in% ooc_raw] = "out-of-search-tol"
  ## only show legend if special things happen  
  showColLegend = ifelse(length(setdiff(d_sub$col, "default")) > 0, "legend", "none")
  
  ## plot
  pl = ggplot(d_sub, col=d_sub$col) +
    geom_boxplot(aes_string(x = "fc.raw.file", y = "mass.error..ppm.", col="col"), varwidth=TRUE, outlier.shape = NA) +
    scale_colour_manual("", values = c("default"="black", "MQ bug"="red", "out-of-search-tol"="red"), guide=showColLegend) +
    ylab(expression(Delta~"mass [ppm]")) +
    xlab("") +
    ylim(ylim_g) +
    scale_x_discrete_reverse(d_sub$fc.raw.file) +
    coord_flip() +
    addGGtitle("EVD: Calibrated mass error", recal_message_post)
  if (!is.na(param_EV_PrecursorTolPPMmainSearch)) {
    pl = pl + geom_hline(yintercept = c(-param_EV_PrecursorTolPPMmainSearch, param_EV_PrecursorTolPPMmainSearch), colour="red", linetype = "longdash")  ## == vline for coord_flip
  } 
  #print(pl)
  rep_data$add(pl)
  return (1)
}
ylim_g = range(na.rm=T, boxplot.stats(d_evd$mass.error..ppm.)$stats[c(1, 5)], c(-param_EV_PrecursorTolPPMmainSearch, param_EV_PrecursorTolPPMmainSearch) * 1.05)
byXflex(d_evd, d_evd$fc.raw.file, 20, plotPCCal, sort_indices=F, affected_raw_files=affected_raw_files, ylim_g=ylim_g)

## QC measure for post-calibration ppm error
## .. assume 0 centered and StdDev of observed data
obs_par = ddply(d_evd[, c("mass.error..ppm.", "raw.file")], "raw.file", 
                function(x) data.frame(mu = mean(x$mass.error..ppm., na.rm=T), sd = sd(x$mass.error..ppm., na.rm=T)))
qc_MS1Cal = data.frame(raw.file = obs_par$raw.file, 
                       val = sapply(1:nrow(obs_par), function(x) qualGaussDev(obs_par$mu[x], obs_par$sd[x])))
## if we suspect out-of-calibration, give lowest score
qc_MS1Cal$val[qc_MS1Cal$raw.file %in% MS1_decal_smr$raw.file[ MS1_decal_smr$outOfCal ]] = 0 
## MQ mass bugfix will not work for postCalibration, since values are always too low
qc_MS1Cal$val[qc_MS1Cal$raw.file %in% MS1_decal_smr$raw.file[ MS1_decal_smr$hasMassErrorBug ]] = HEATMAP_NA_VALUE
cname = "X027X_catMS_EVD:~MS~Cal-Post"
colnames(qc_MS1Cal)[colnames(qc_MS1Cal) == "val"] = cname
QCM[["X027X.EVD.MS_Cal-Post"]] = qc_MS1Cal




## compute how well calibration worked
cal_medians = as.vector(by(d_evd$mass.error..ppm., d_evd$raw.file, median, na.rm=T))
cal_stats = quantile(cal_medians, probs=c(0,0.5,1))
cat(pastet("medianCalibratedMassError(min,median,max) [ppm]", paste(cal_stats, collapse=",")), file=fh_out$stats_file, append=T, sep="\n") 

##
## elaborate contaminant fraction per Raw.file (this is not possible from PG, since raw files could be merged)
## find top 5 contaminants (globally)
##
cat("EVD: Contaminants per Raw file ...\n")


## if possible, work on protein names (since MQ1.4), else use proteinIDs
if ("protein.names" %in% colnames(d_evd))
{
  evd_pname = "protein.names"        
} else {
  evd_pname = "proteins" 
}
## protein.names are sometimes not unique, e.g. if a contaminant is involved:
## "P02768;CON__P02768-1" and "P02768" will both give the same name (since contaminant name is empty)
## Thus, the distribution of bars will look slightly different (but summed percentages are identical)

## some protein.names are empty (usually the CON__ ones) ... so we substitute with ID
d_evd$pname = d_evd[, evd_pname];
d_evd$pname[d_evd$pname==""] = d_evd$proteins[d_evd$pname==""] ## a NOP if it already is 'proteins', but ok

d_evd.totalInt = sum(as.numeric(d_evd$intensity), na.rm=T)
d_evd.cont.only = d_evd[d_evd$contaminant,]
cont.top = by(d_evd.cont.only, d_evd.cont.only$pname, function(x) sum(as.numeric(x$intensity), na.rm=T) / d_evd.totalInt*100)
cont.top.sort = sort(cont.top, decreasing=T)
#head(cont.top.sort)
cont.top5.names = names(cont.top.sort)[1:5]


plotCont = function(d_evd_sub, top5=cont.top5.names) 
{ 
  #top5 = cont.top5.names
  if (is.null(top5)) stop("Function plotCont() called with invalid argument. Please report this bug.")
  
  intensity = NULL ## to make R CHECK happy...
  d_evd.cont.only_sub = d_evd_sub[d_evd_sub$contaminant,]
  ## rewrite prot names, and subsume 6th and below as 'other'
  d_evd.cont.only_sub[!(d_evd.cont.only_sub$pname %in% top5), "pname"] = 'other'
  ## aggregate identical proteins
  ##  use sum(as.numeric(.)) to prevent overflow
  d_sum = ddply(d_evd.cont.only_sub[, c("intensity", "pname", "fc.raw.file")], c("pname", "fc.raw.file"), 
                function(x) summarise(x, s.intensity=sum(as.numeric(intensity), na.rm=T)))
  ## normalize by total intensity of raw file
  d_norm = ddply(d_evd_sub[, c("intensity", "fc.raw.file")],  "fc.raw.file", 
                 function(x) summarise(x, total.intensity=sum(as.numeric(intensity), na.rm=T)))
  d_sum$total.intensity = d_norm$total.intensity[match(d_sum$fc.raw.file, d_norm$fc.raw.file)]
  d_sum$Log10Diff = getAbundanceClass(log10(d_sum$total.intensity))
  d_sum$s.intensity = d_sum$s.intensity / d_sum$total.intensity * 100
  ## shorten protein-groups (at most two protein names)
  d_sum$pname = sapply(d_sum$pname, function(x) {
    p.split = unlist(strsplit(x, split=";"))
    ## shorten entries as well (at most 15 characters)
    p.split_s = sapply(p.split[1:(min(2, length(p.split)))], function(x) ifelse(nchar(x)>15, paste0(substr(x, start=1, stop=13), ".."), x))
    r = paste(p.split_s, sep="", collapse=";")
    if (length(p.split)>2) r=paste0(r, ";..")
    return(r)
  })
  ## order of pname determines order of bars    
  d_sum1 = d_sum[d_sum$pname!="other",]
  d_sum2 = d_sum[d_sum$pname=="other",]
  d_sum = rbind(d_sum1, d_sum2)
  ## value of factors determines order in the legend
  ## --> make proteins a factor, with 'other' being the first
  d_sum$Protein = factor(d_sum$pname, levels=unique(c("other", d_sum$pname)), ordered=T)
  head(d_sum)
  
  ## plot
  rep_data$add(
  #print(  
    ggplot(d_sum, aes_string(   x = "factor(fc.raw.file)",
                                y = "s.intensity", 
                             fill = "Protein")) +
      geom_bar(aes_string(alpha = "Log10Diff"), 
                           stat = "identity") +
      scale_alpha_discrete(range = c(c(0.3, 1)[(length(unique(d_sum$Log10Diff))==1) + 1], 1.0),
                            name = "Abundance\nclass") +
      xlab("")  +
      theme_bw() +
      ggtitle("EVD: Contaminant per Raw file") +
      ylab("contaminant (% intensity)") +
      scale_fill_manual(values = brewer.pal(6,"Accent")) + 
      scale_colour_manual(values = brewer.pal(6,"Accent")) +
      geom_hline(aes_string(yintercept = "5"), linetype='dashed') +
      #guides(alpha=NULL, fill = guide_legend(nrow = 2, ncol = 3, byrow = TRUE, reverse = T)) +
      #theme(legend.position="top", legend.title=element_blank()) +
      coord_flip() +
      scale_x_discrete_reverse(d_sum$fc.raw.file)
  )
  return (1)  
}

if (is.null(cont.top5.names))
{
  pl_cont = ggText("EVD: Contaminant per Raw file",
                   paste0("No contaminants found in any sample.\n\nIncorporating contaminants during search is highly recommended!"),
                   "red")
  rep_data$add(pl_cont)  
} else {
  byXflex(d_evd[, c("intensity", "pname", "fc.raw.file", "contaminant")], d_evd$fc.raw.file, 40, sort_indices=F, plotCont, top5=cont.top5.names)
}

## QC measure for contamination
qc_contaminants = ddply(d_evd[, c("intensity", "contaminant", "fc.raw.file")], "fc.raw.file", 
                        function(x) {
                          v = ifelse(is.null(cont.top5.names), 
                                     HEATMAP_NA_VALUE, ## use NA in heatmap if there are no contaminants
                                     1-qualLinThresh(sum(as.numeric(x$intensity[x$contaminant]), na.rm=T)/
                                                       sum(as.numeric(x$intensity), na.rm=T)))
                          data.frame("X001X_catPrep_EVD:~Contaminants" = v, check.names = F)})
QCM[["EVD.Contaminants"]] = qc_contaminants

}



##
## Oversampling: determine peaks repeatedly sequenced
##
cat("EVD: MS2 oversampling ...\n")

d_dups = ddply(d_evd, "fc.raw.file", function(x) {
  tt = as.data.frame(table(x$ms.ms.count), stringsAsFactors = F)
  tt$Count = as.numeric(tt$Var1)
  ## remove "0", since this would be MBR-features
  tt = tt[tt$Count!=0,]
  ## summarize everything above 3 counts
  if (any(tt$Count >= 3)) {
    tt$Count[tt$Count >= 3] = "3+"
    tt = ddply(tt, "Count", function(x) data.frame(Freq=sum(x$Freq)))
  }
  ## make counts relative
  fraction = tt$Freq / sum(tt$Freq) * 100
  return (data.frame(n=as.character(tt$Count), fraction = fraction))
})

fcnPlotOversampling = function(d_dups)
{
  ## reorder factor, such that '10+' is last
  d_dups$n = as.character(d_dups$n)
  n_unique = sort(unique(d_dups$n)) ## sort as character vector!
  d_dups$n = factor(d_dups$n, levels=n_unique[order(nchar(n_unique))], ordered=T)
  
  #fp = colorRampPalette( brewer.pal( 6 , "Blues" ) )
  #rev(fp(length(n_unique))
  rep_data$add(
    #print(
    ggplot(d_dups) + 
      geom_bar(stat="identity", position="stack", aes_string(x = "fc.raw.file", y = "fraction", fill="n")) +
      scale_fill_manual("MS/MS\ncounts", values =c("green", "blue", "red")) +
      scale_x_discrete_reverse(d_dups$fc.raw.file) +
      xlab("") +
      ylab("MS/MS counts per 3D-peak [%]") +
      ggtitle(paste0("EVD: Oversampling (MS/MS counts per 3D-peak)")) + 
      theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
      coord_flip()
  )
  return(TRUE)
}
byXflex(d_dups, d_dups$fc.raw.file, 30, fcnPlotOversampling, sort_indices = F)
## QC measure for centered-ness of MS2-calibration
qc_evd_twin = d_dups[d_dups$n==1,]
cname = "X025X_catMS_EVD:~MS^2~Oversampling"
qc_evd_twin[, cname] = qualLinThresh(qc_evd_twin$fraction/100)
QCM[["EVD.Oversampling"]] = qc_evd_twin[, c("fc.raw.file", cname)]

## trim down to the absolute required (we need to identify contaminants in MSMS.txt later on)
if (!exists("DEBUG_PTXQC")) d_evd = d_evd[, c("id", "contaminant")]
  }  


######
######  msms.txt ...
######

enabled_msms = getYAML(yaml_obj, "File$MsMs$enabled", TRUE)
if (enabled_msms)
{
  ### missed cleavages (again)
  ### this is the real missed cleavages estimate ... but slow
  #d_msms_s = mq$readMQ(txt_files$msms, type="msms", filter = "", nrows=10)
  #colnames(d_msms_s)
  #head(d_msms)
  d_msms = mq$readMQ(txt_files$msms, type="msms", filter = "", col_subset=c("Missed\\.cleavages", "^Raw.file$", "^mass.deviations", "^masses$", "^mass.analyzer$", "fragmentation", "reverse", "^evidence.id$"), check_invalid_lines = F)
  
  d_msms = d_msms[order(match(as.character(d_msms$fc.raw.file), mq$raw_file_mapping$to)),]
  ## sort fc.raw.file's factor values as well
  d_msms$fc.raw.file = factor(d_msms$fc.raw.file, levels = mq$raw_file_mapping$to, ordered = TRUE)
  
  ##
  ##  MS2 fragment decalibration
  ##
  cat("MSMS: MS2 fragment decalibration ...\n")
  ## older MQ versions do not have 'mass.analyzer' or 'mass.deviations..ppm.'
  ## , so we use fragmentation instead (this is a little risky, since you could to CID fragmentation and forward to Orbi, but hey...)
  if (!("mass.analyzer" %in% colnames(d_msms))) d_msms$mass.analyzer = d_msms$fragmentation
  
  
  ms2_decal = ddply(d_msms, c("fc.raw.file", "mass.analyzer"), .fun = function(x) {
    idx_nr = which(!x$reverse)
    ## select a representative subset, otherwise the number of datapoints is just too large
    idx_nr_subset = idx_nr[seq(1,length(idx_nr), by=ceiling(length(idx_nr)/1000))]
    df.ms = getFragmentErrors(x[idx_nr_subset,])
    df.ms$type="forward"
    
    if (any(x$reverse))
    {
      idx_nr = which(x$reverse)
      ## select a representative subset, otherwise the number of datapoints is just too large
      idx_nr_subset = idx_nr[seq(1,length(idx_nr), by=ceiling(length(idx_nr)/1000))]
      df.ms_r = getFragmentErrors(x[idx_nr_subset,])
      df.ms_r$type="decoy"
      
      ## only merge if we have hits (reverse hits might be few and $mass.deviations..da. might be empty)
      if (nrow(df.ms_r)) df.ms = rbind(df.ms, df.ms_r)
    }
    
    return (df.ms)
  })
  
  head(ms2_decal)
  class(ms2_decal$msErr)
  ms2_decal$msErr = as.numeric(as.character(ms2_decal$msErr))
  #ms2_range = diff(range(ms2_decal$msErr, na.rm=T))
  #ms2_binwidth = ms2_range/20
  ## precision (plotting is just so much quicker, despite using a fixed binwidth)
  #ms2_decal$msErr = round(ms2_decal$msErr, digits=ceiling(-log10(ms2_binwidth)+1))
  tail(ms2_decal)
  ms2_decal$facet = paste(ms2_decal$fc.raw.file, paste(ms2_decal$mass.analyzer, ms2_decal$unit), sep="\n")
  fcPlotMS2Dec <- function(d_sub)
  {
    pl = 
      ggplot(data = d_sub, aes_string(x = "msErr", fill="type")) + 
      geom_histogram() +
      #geom_histogram(binwidth = ms2_binwidth) +
      xlab("fragment mass delta") +  
      ylab("count") + 
      scale_fill_manual(values = c(forward = "#99d594", decoy = "#ff0000")) +
      ggtitle("MSMS: Fragment mass errors per Raw file") +
      facet_wrap(~facet)
    rep_data$add(pl)
    #print(pl)
    return(1)
  }
  ## separate plots for each mass analyzer, since we want to keep 'fixed' scales for all raw.files (comparability)
  ddply(ms2_decal, "mass.analyzer", function(ms2_decal) {
    byXflex(ms2_decal, ms2_decal$fc.raw.file, 9, fcPlotMS2Dec, sort_indices=F); 
    return(1) })
  
  ##
  ## QC measure for centered-ness of MS2-calibration
  ##
  head(ms2_decal)
  for (analyzer in unique(ms2_decal$mass.analyzer)) {
    qc_name = paste0("X028X_catMS_", "MSMS:~MS^2~Cal~(", analyzer, ")")
    qc_MS2_decal = ddply(ms2_decal[ms2_decal$mass.analyzer==analyzer, ], "fc.raw.file", 
                         function(x)
                         {
                           xx = na.omit(x$msErr);
                           data.frame(X1 = qualCentered(xx), check.names=F)
                         })
    ## augment fragmentation methods with -Inf for missing raw files (otherwise they would become 'red'=fail)
    if (length( setdiff(mq$raw_file_mapping$to, qc_MS2_decal$fc.raw.file) )) {
      frag_missing = data.frame(fc.raw.file = setdiff(mq$raw_file_mapping$to, qc_MS2_decal$fc.raw.file), X1=-Inf)
      qc_MS2_decal = rbind(qc_MS2_decal, frag_missing)
    }
    colnames(qc_MS2_decal)[colnames(qc_MS2_decal)=="X1"] = qc_name
    QCM[[qc_name]] = qc_MS2_decal[, c("fc.raw.file", qc_name)]
  }
  if (!exists("DEBUG_PTXQC")) rm("ms2_decal")
  
  ##
  ## missed cleavages per Raw file
  ##
  cat("MSMS: missed cleavages per Raw file ...\n")
  
  max_mc = max(-Inf, d_msms$missed.cleavages, na.rm=T) ## will be -Inf iff enzyme was not specified and columns is 100% NA
  if (!is.infinite(max_mc))
  { ## MC's require an enzyme to be set
    smr_msmsMC = summary(d_msms$missed.cleavages)
    ## remove contaminants
    msg_cont_removed = "(includes contaminants -- no evidence.txt read)"
    if (exists("d_evd")) {
      msg_cont_removed = "(excludes contaminants)"
      d_msms$contaminant = d_evd$contaminant[match(d_msms$evidence.id, d_evd$id)]
      summary(d_msms$contaminant)
    }
    
    st_bin = ddply(d_msms[!d_msms$contaminant, c("missed.cleavages", "fc.raw.file")], "fc.raw.file", .fun = function(x) {
      t = table(x$missed.cleavages)/nrow(x)
      r = rep(0, max_mc + 1)
      names(r) = as.character(0:max_mc)
      r[names(t)] = t
      return (r)
    })
    fcMCRTSubset <- function(d_sub, smr_msmsMC)
    {
      st_bin.m = melt(d_sub, id.vars = c("fc.raw.file"))
      pl = 
        ggplot(data = st_bin.m, aes_string(x = "factor(fc.raw.file)", y = "value", fill = "variable")) + 
        geom_bar(stat="identity") +
        xlab("Raw file") +  
        ylab("missed cleavages [%]") + 
        theme(legend.title=element_blank()) +
        scale_fill_manual(values = rep(c("#99d594", "#ffffbf", "#fc8d59", "#ff0000"), 10)) +
        geom_abline(alpha = 0.5, intercept = 0.75, slope = 0, colour = "black", linetype = "dashed", size = 1.5) +
        coord_flip() +
        scale_x_discrete_reverse(st_bin.m$fc.raw.file) +
        addGGtitle("MSMS: Missed cleavages per Raw file", msg_cont_removed)
      #print(pl)
      rep_data$add(pl)
      return(1)
    }    
    byXflex(st_bin, st_bin$fc.raw.file, 25, fcMCRTSubset, smr_msmsMC=smr_msmsMC, sort_indices=F)
    
    mcZero = st_bin[, "0"] * 100
    mcZero_stat = 100 - rev(quantile(mcZero, probs=c(0,0.5,1)))
    cat(pastet("missedCleavages>0 (min,median,max) [%]", paste0(mcZero_stat, collapse=",")), file=fh_out$stats_file, append=T, sep="\n")
    
    ## QC measure for missed-cleavages variation
    qc_mc = data.frame(fc.raw.file = st_bin$fc.raw.file, XXX = st_bin[, "0"], check.names = F)
    cname = "X004X_catPrep_MSMS:~MC"
    colnames(qc_mc)[grep("XXX", colnames(qc_mc))] = cname
    QCM[["MSMS.MC"]] = qc_mc
    qc_mc$"X007X_catPrep_MSMS:~MC~Var" = qualMedianDist(qc_mc[, cname])
    QCM[["MSMS.MC_Var"]] = qc_mc
    
    
  } ## end MC check
  
  
  if (!exists("DEBUG_PTXQC")) rm("d_msms")
}

######
######  msmsScans.txt ...
######

enabled_msmsscans = getYAML(yaml_obj, "File$MsMsScans$enabled", TRUE)
if (enabled_msmsscans)
{
  #d_msmsScan_h = mq$readMQ(txt_files$msmsScan, type="msms", filter = "", nrows=2)
  #colnames(d_msmsScan_h)
  #head(d_msmsScan_h)
  d_msmsScan = mq$readMQ(txt_files$msmsScan, type = "msms", filter = "", 
                         col_subset = c("^ion.injection.time", 
                                        "^retention.time$", 
                                        "^Identified", 
                                        "^Scan.event.number", 
                                        "^Raw.file"),
                         check_invalid_lines = F)
  ##
  ## MQ version 1.0.13 has very rudimentary MSMSscans.txt, with no header, so we need to skip the metrics of this file
  ##
  if (ncol(d_msmsScan) > 3)
  {
    #colnames(d_msmsScan)
    #head(d_msmsScan)
    #unique(d_msmsScan$Identified)
    
    d_msmsScan = d_msmsScan[order(match(d_msmsScan$fc.raw.file, mq$raw_file_mapping$to)),]
    ## sort fc.raw.file's factor values as well
    d_msmsScan$fc.raw.file = factor(d_msmsScan$fc.raw.file, levels = mq$raw_file_mapping$to, ordered = TRUE)
    
    # round RT to 2 min intervals
    d_msmsScan$rRT = round(d_msmsScan$retention.time/2)*2
    
    ##
    ## TopN over RT
    ##
    cat("MSMS-Scans: TopN over RT ...\n")
    
    ## scan event number
    scan.event.number = NULL ## make R check happy
    
    ## maximum scan event over time
    DFmse = ddply(d_msmsScan, c("fc.raw.file"), function(x) {
      ## sort by RT
      if (is.unsorted(x$retention.time))
      { ## should not happen, but just to make sure
        x = x[, order(x$retention.time)]
      }
      ## only take the highest scan event (SE) in a series
      maxN = getMaxima(x$scan.event.number, thresh_rel = 0.0)
      df.max = x[maxN,]
      ## use median of that within one RT bin
      meanN = ddply(df.max, c("rRT"), summarise, medSE = median(scan.event.number))
      return (meanN)    
    })
    
    head(DFmse)
    plotMaxSEinRT = function(data)
    {
      nrOfRaws = length(unique(data$fc.raw.file))
      pl = ggplot(data, aes_string(x = "rRT", y = "medSE", col = "fc.raw.file")) +
        geom_line() +
        scale_color_manual(values = brewer.pal(nrOfRaws, "Set1")) +
        xlab("retention time [min]") +
        ylab("highest N [median per RT bin]") +
        #stat_smooth(method = "loess", formula = y ~ x, se = FALSE, span = 0.1) +
        guides(color=guide_legend(title="")) +
        ggtitle("MSMSscans: TopN over RT")
      #print(pl)
      rep_data$add(pl)
      return (1)
    }
    byXflex(DFmse, DFmse$fc.raw.file, 8, plotMaxSEinRT, sort_indices=F)
    
    ## QC measure for smoothness of TopN over RT
    qc_TopNRT = ddply(DFmse, "fc.raw.file", function(x) data.frame("X012X_catLC_MS^2*Scans:~TopN~over~RT" = qualUniform(x$medSE), check.names=F))
    QCM[["MSMSscans.TopN_over_RT"]] = qc_TopNRT
    
    ##
    ## Injection time over RT
    ##
    cat("MSMS-Scans: Injection time over RT ...\n")
    
    param_name_MSMSScans_ionInjThresh = "File$MsMsScans$IonInjectionThresh_num"
    param_def_MSMSScans_ionInjThresh = 10 ## default ion injection threshold in milliseconds
    param_MSMSScans_ionInjThresh = getYAML(yaml_obj, param_name_MSMSScans_ionInjThresh, param_def_MSMSScans_ionInjThresh)
    if (!is.numeric(param_MSMSScans_ionInjThresh))
    { ## reset if value is weird
      cat("YAML value for '" %+% param_name_MSMSScans_ionInjThresh %+% "' is invalid ('" %+% param_MSMSScans_ionInjThresh %+% "'). Using default of " %+% param_def_MSMSScans_ionInjThresh %+% ".")
      param_MSMSScans_ionInjThresh = param_def_MSMSScans_ionInjThresh
    }
    
    ## average injection time over RT
    DFmIIT = ddply(d_msmsScan, c("fc.raw.file"), function(x) {
      meanN = ddply(x, c("rRT"), function(x) data.frame(medIIT = median(x$ion.injection.time)))
      return (meanN) 
    })
    head(DFmIIT)
    ## average injection time overall
    DFmIITglob = ddply(d_msmsScan, c("fc.raw.file"), function(x) {
      return (data.frame(globalIITmedian = mean(x$ion.injection.time), x = min(x$ion.injection.time)))
    })
    head(DFmIITglob)
    
    
    plotIITinRT = function(data)
    {
      data$fc.raw.file = data$fc.raw.file[,drop=T]
      nrOfRaws = length(unique(data$fc.raw.file))
      DFmIITglob_sub = DFmIITglob[DFmIITglob$fc.raw.file %in% data$fc.raw.file,]
      DFmIITglob_sub$x = min(DFmIITglob_sub$x) ## same X for every raw file
      ## augment legend with average II-time[ms]
      data$fc.raw.file = paste0(data$fc.raw.file, " (~", 
                                round(DFmIITglob_sub$globalIITmedian[match(data$fc.raw.file, DFmIITglob_sub$fc.raw.file)]),
                                " ms)")
      ## manually convert to factor to keep old ordering (otherwise ggplot will sort it, since its a string)
      data$fc.raw.file = factor(data$fc.raw.file, levels = unique(data$fc.raw.file), ordered=T)
      DFmIITglob_sub$fc.raw.file = paste0(DFmIITglob_sub$fc.raw.file, " (~", 
                                          round(DFmIITglob_sub$globalIITmedian[match(DFmIITglob_sub$fc.raw.file, DFmIITglob_sub$fc.raw.file)]),
                                          " ms)")
      pl = ggplot(data) +
        geom_line(aes_string(x = "rRT", y = "medIIT", col = "fc.raw.file")) +
        scale_color_manual(values = brewer.pal(nrOfRaws, "Set1")) +
        xlab("retention time [min]") +
        ylab("ion injection time [ms]") +
        geom_hline(yintercept = param_MSMSScans_ionInjThresh, linetype = 'dashed') +
        guides(color=guide_legend(title="Raw file with\naverage inj. time")) +
        ggtitle("MSMSscans: Ion Injection Time over RT") +
        pointsPutX(x_range=range(data$rRT), x_section=c(0.03,0.08), y=DFmIITglob_sub$globalIITmedian, col=DFmIITglob_sub$fc.raw.file[,drop=T])
      
      #print(pl)
      rep_data$add(pl)
      return (1)
    }
    byXflex(DFmIIT, DFmIIT$fc.raw.file, 8, plotIITinRT, sort_indices=F)
    
    
    ## QC measure for injection times below expected threshold
    DFmIIT_belowThresh = ddply(d_msmsScan, c("fc.raw.file"), function(x) {
      return (data.frame(belowThresh_IIT = sum(x$ion.injection.time < param_MSMSScans_ionInjThresh, na.rm=T) / nrow(x)))
    })
    head(DFmIIT_belowThresh)
    qc_IIT = ddply(DFmIIT_belowThresh, "fc.raw.file", function(x) data.frame("X024X_catMS_MS^2*Scans:~Ion~Inj~Time" = qualLinThresh(x$belowThresh_IIT, t = 1),
                                                                             check.names = F))
    QCM[["MSMSscans.Ion_Inj_Time"]] = qc_IIT
    
    
    ##
    ## TopN counts
    ##
    cat("MSMS-Scans: scan event counts ...\n")
    
    DFc = ddply(d_msmsScan, c("scan.event.number", "fc.raw.file"), summarise, n = length(scan.event.number))
    dfc.ratio = ddply(DFc, "fc.raw.file", function(x, maxn)
    {
      ## sort x by scan event
      event_count = x$n
      ## verify its monotonically increasing
      if (is.unsorted(rev(event_count))) {
        #print(x)
        stop("Scan event distribution is not monotonically increasing!")
      } 
      ## verify that there are no gaps
      if (max(x$scan.event.number) != nrow(x)) {
        #print(x)
        stop("Scan event distribution has unexpected holes...!")
      }
      
      event_pre = c(event_count[-1], 0)
      event_diff = event_count - event_pre
      
      ## build new DF of fixed length
      sn = x$scan.event.number
      if (max(sn) < maxn) 
      {
        event_diff = c(event_diff, rep(0, maxn-max(sn)))
        sn = c(sn, (max(sn)+1):maxn)
      }
      DF.new = data.frame(scan.event.number = sn, n = event_diff)
      return (DF.new)
    }, maxn = max(DFc$scan.event.number))
    head(dfc.ratio)
    
    plotScanEventDiff = function(dfc.ratio)
    {
      rep_data$add(
        ggplot(dfc.ratio, aes_string(x = "scan.event.number", y = "n")) +
          geom_bar(stat="identity") +
          xlab("highest scan event") +
          ylab("count") +
          facet_wrap(~ fc.raw.file, scales = "free_y") +
          ggtitle(paste0("MSMSscans: TopN"))
      )
      return (1)
    }
    byXflex(dfc.ratio, dfc.ratio$fc.raw.file, 9, plotScanEventDiff, sort_indices=F)
    
    ## QC measure for always reaching the maximum TopN
    maxTopN = max(dfc.ratio$scan.event.number)
    qc_TopN = ddply(dfc.ratio, "fc.raw.file", function(x) data.frame("X035X_catMS_MS^2*Scans:~TopN~high" = qualHighest(x$n, maxTopN),
                                                                     check.names = F))
    QCM[["MSMSscans.TopN"]] = qc_TopN
    
    
    ##
    ## Scan event: % identified
    ##
    cat("MSMS-Scans: TopN % identified ...\n")
    
    DF = ddply(d_msmsScan, c("scan.event.number", "identified", "fc.raw.file"), summarise, n = length(scan.event.number))
    
    # try KS on underlying data instead of using qualUniform()
    #   DF2= ddply(d_msmsScan, "fc.raw.file", function(rf){
    #     cat(class(rf))
    #     cat(rf$fc.raw.file[1])
    #     idx_p = rf$identified=="+"
    #     cat(length(idx_p) %+% "\n")
    #     kk = ks.test(rf$scan.event.number[idx_p], rf$scan.event.number[-idx_p])
    #     cat(kk$p.value)
    #     kk$statistic  # = 'D' ,,  p.value is much smaller (~0)
    #   })
    #   --> fail, 'D' and p-values are too low
    df.ratio = ddply(DF, c("scan.event.number", "fc.raw.file"), function(x)
    {
      xp = xm = 0
      if ("+" %in% x$identified) xp = x$n[x$identified=="+"]
      if ("-" %in% x$identified) xm = x$n[x$identified=="-"]
      ratio = xp * 100 / sum(xp, xm)
      return (data.frame(ratio = ratio, count = sum(x$n)))
    })
    head(df.ratio)
    
    plotScanEvent = function(df.ratio)
    {
      
      p = ggplot(df.ratio, aes_string(x = "scan.event.number", y = "ratio", alpha = "count")) +
        geom_bar(stat="identity") +
        xlab("scan event") +
        ylab("percent identified") +
        facet_wrap(~ fc.raw.file) +
        ggtitle(paste0("MSMSscans: TopN % identified over N"))
      return (p)
    }
    pl = byXflex(df.ratio, df.ratio$fc.raw.file, 9, plotScanEvent, sort_indices=F)
    for (p in pl) rep_data$add(p)
    
    ## QC measure for constantly identifiying peptides, irrespective of scan event number
    ## -- we weight scan events by their number of occurence
    qc_TopN_ID = ddply(df.ratio, "fc.raw.file", function(x) data.frame("X038X_catMS_MS^2*Scans:~TopN~ID~over~N" = qualUniform(x$ratio, x$count),
                                                                       check.names = F))
    QCM[["MSMSscans.TopN_ID_over_N"]] = qc_TopN_ID
  } ## end MSMSscan from MQ > 1.0.13
}

hm = getQCHeatMap(QCM, raw_file_mapping = mq$raw_file_mapping)
#print(hm[["plot"]])
write.table(hm[["table"]], file = fh_out$heatmap_values_file, quote= T, sep = "\t", row.names=F)
rep_data$add(hm[["plot"]], "heatmap")

## get MQ short name mapping plot (might be NULL if no mapping was required)
rep_data$add(mq$plotNameMapping(), "name_mapping")

##
## plot it!!!
##


out_formats_supported = c("html", "plainPDF")

param_name_PTXQC_OutputFormats = "PTXQC$OutputFormats"
param_def_PTXQC_OutputFormats = out_formats_supported[2]
param_OutputFormats = getYAML(yaml_obj, param_name_PTXQC_OutputFormats, param_def_PTXQC_OutputFormats)

param_name_PTXQC_PageNumbers = "PTXQC$PlainPDF$AddPageNumbers"
param_def_PTXQC_PageNumbers = "on"
param_PageNumbers = getYAML(yaml_obj, param_name_PTXQC_PageNumbers, param_def_PTXQC_PageNumbers)

cat("Creating Report file ...")

## give the user a chance to close open reports which are currently blocked for writing
if (!wait_for_writable(fh_out$report_file))
{
  stop("Target file not writable")
}



#
#param_OutputFormats = "html pdf"
#
out_formats = unlist(strsplit(param_OutputFormats, "[ ,]+"))
out_formats
out_format_requested = out_formats_supported[match(out_formats, out_formats_supported)]
if (any(is.na(out_format_requested)))
{
  stop("Output format(s) not supported: '", paste(out_formats[is.na(out_format_requested)], collapse="', '"), "'")
}

if ("html" %in% out_format_requested)
{
  #template = "C:/projects/QC/package/PTXQC/inst/reportTemplate/PTXQC_report_template.Rmd"
  #knit2html(template, output = paste0(fh_out$report_file, ".html"))
  template = system.file("./reportTemplate/PTXQC_report_template.Rmd", package="PTXQC")
  template
  ## Rmarkdown: convert to Markdown, and then to HTML or PDF...
  render(template, output_file = paste0(fh_out$report_file, ".html"))
  ##render(template, output_file = paste0(fh_out$report_file, ".pdf"))
}

  
if ("plainPDF" %in% out_format_requested)
{
  if (param_PageNumbers == "on")
  {
    printWithPage = function(gg_obj, page_nr, filename = fh_out$report_file)
    {
      filename = basename(filename)
      printWithFooter(gg_obj, bottom_left = filename, bottom_right = page_nr)
    }
  } else {
    ## no page number and filename at bottom of each page
    printWithPage = function(gg_obj, page_nr, filename = fh_out$report_file)
    {
      print(gg_obj)
    }
  }
  pdf(paste0(fh_out$report_file, ".pdf"))
  printWithPage(rep_data$get("params"), "p. 1")       # parameters
  printWithPage(rep_data$get("name_mapping"), "p. 2") # short file mapping
  printWithPage(rep_data$get("heatmap"), "p. 3")      # summary heatmap
  GPL_lst = rep_data$get("metric")
  pc = 4; ## subsequent pages start at #4
  for (idx in sort(names(GPL_lst)))
  {
    printWithPage(GPL_lst[[idx]], paste("p.", pc))
    pc = pc + 1
  }
  dev.off();
  cat(" done\n")
}

## save plot object (for easier access, in case someone wants high-res plots)
## (...disabled for now until concrete use case pops up)
#cat("Dumping plot objects as Rdata file ...")
#save(file = fh_out$R_plots_file, list = "GPL")
#cat(" done\n")

### write YAML config
writeYAML(fh_out$yaml_file, yaml_obj)

## write sorting of filenames
mq$writeMappingFile(fh_out$filename_sorting)

cat(paste("Report file created at\n\n    ", fh_out$report_file, ".*\n\n", sep=""))
cat(paste0("\n\nTime elapsed: ", round(as.double(Sys.time() - time_start, units="mins"), 1), " min\n\n"))

## return path to PDF report and YAML config, etc
return (fh_out)
}
