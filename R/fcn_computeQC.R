#' Create a quality control report (in PDF format).
#'
#' This is the main function of the package and the only thing you need to call directly if you are 
#' just interested in getting a QC report.
#' 
#' You need to provide the folder name of the 'txt' output, as generated by MaxQuant and 
#' optionally a YAML configuration object, which allows to (de)activate certain plots and holds other parameters.
#' The yaml_obj is complex and best obtained by running this function once using the default (empty list).
#' A full YAML configuration object will be written in the 'txt' folder you provide and can be loaded using
#' \code{\link[yaml]{yaml.load}}. 
#' 
#' The PDF and the config file will be stored in the given txt folder.
#' 
#' @note You need write access to the txt folder!
#' 
#' For updates, bug fixes and feedback please visit \url{http://github.com/cbielow/R-PTXQC}.
#'
#' @param txt_folder Path to txt output folder of MaxQuant (e.g. "c:/data/Hek293/txt")
#' @param yaml_obj   A nested list object with configuration parameters for the report.
#'                   Useful to switch off certain plots or skip entire sections.
#' @return List with three strings: 
#'          \itemize{
#'            \item pdf_filename     Path to PDF report
#'            \item yaml_filename    Path to a YAML configuration file used during report generation. 
#'                                   Parameters missing in yaml_obj (input param) were restored to default.
#'            \item heatmap_filename Path to Heatmap table
#'          }
#'          
#' @import ggplot2
#' @import directlabels
#' @importFrom plyr ddply dlply summarise
#' @importFrom grid unit
#' @importFrom reshape2 melt
#' @importFrom RColorBrewer brewer.pal
#' @importFrom splines ns
#'  
#' @export
#'           
createReport <- function(txt_folder, yaml_obj = list())
{
  
### script starts...

if (!any(file.info(txt_folder)$isdir, na.rm=T))
{
  stop(paste0("Argument txt_folder with value '", txt_folder, "' is not a valid directory\n"));
}

YAML_CONFIG = list()
if (class(yaml_obj) != "list")
{
  stop(paste0("Argument 'yaml_obj' is not of type list\n"));
}

## list of plots
GPL = ObjHandler$new()

## list of data.frames containing one QC metric per list for each Raw file
## used for heat map later on
QCM = list()


txt_files = list()
txt_files$param = "parameters.txt"
txt_files$summary = "summary.txt"
txt_files$groups = "proteinGroups.txt"
txt_files$evd = "evidence.txt"
txt_files$msms = "msms.txt"
txt_files$msmsScan = "msmsScans.txt"
txt_files = lapply(txt_files, function(x) paste(txt_folder, x, sep="\\"))


# ideas:
## automatic flagging of suspicious results
  
## increase package number if required. Added to output filename
if (!require("PTXQC", quietly=T)) pv = "_unknown" else pv = packageVersion("PTXQC")
report_version = paste0("v", pv)  


time_start = Sys.time()

stats_file = paste(txt_folder, "\\report_", report_version, "_stats.txt", sep="")
unlink(stats_file)
cat("Statistics summary:", file=stats_file, append=F, sep="\n")

report_file = paste(txt_folder, "\\report_", report_version, ".pdf", sep="")
yaml_file = paste(txt_folder, "\\report_", report_version, ".yaml", sep="")
heatmap_values_file = paste(txt_folder, "\\report_", report_version, "_heatmap.txt", sep="")
R_plots_file = paste(txt_folder, "\\report_", report_version, "_plots.R", sep="")

## prepare for readMQ()
mq = MQDataReader$new()

######
######  parameters.txt ...
######

enabled_parameters = getYAML(yaml_obj, "File$Parameters$enabled", TRUE)
if (enabled_parameters)
{
  d_parAll = mq$readMQ(txt_files$param, type="par")
  
  line_break = "\n"; ## use space to make it work with table
  ## remove AIF stuff
  d_parAll = d_parAll[!grepl("^AIF ", d_parAll$parameter),]
  d_parAll$value = gsub(";", line_break, d_parAll$value)
  ## seperate FASTA files (usually they destroy the layout)
  idx_fastafile = grepl("fasta file", d_parAll$parameter, ignore.case = T)
  d_par_file = d_parAll[idx_fastafile, ]
  fasta_files = sapply(unlist(strsplit(d_par_file$value, "\n")), function(x) rev(strsplit(x,"\\", fixed=T)[[1]])[1])
  d_par = d_parAll[!idx_fastafile, ]
  ## remove duplicates
  d_par = d_par[!duplicated(d_par$parameter),]
  rownames(d_par) = d_par$parameter
  
  ## trim long param names (the user should know what they mean)
  d_par$parameter = sapply(d_par$parameter, function (s) {
    allowed_len = nchar("Min. score for unmodified .."); 
    if (nchar(s) > allowed_len) {
      s = paste(substring(s, 1, allowed_len), "..", collapse = "", sep="")
    }
    return (s)
  })
  ## break long values into multiple lines (to preserve table width)
  d_par$value = sapply(d_par$value, function (s) 
  {
    allowed_len = nchar("Use least modified peptide"); ## this is a typical entry -- everything which is longer gets split
    r = paste(sapply(unlist(strsplit(s, line_break, fixed=T)), function(s1) {
      if (nchar(s1) > allowed_len) {
        s_beg = seq(1, nchar(s1) - 1, allowed_len)
        s1 = paste(unlist(substring(s1, s_beg, s_beg + allowed_len)), collapse = line_break)
      }
      return(s1)
    }), collapse = line_break)
    return (r)
  })
  
  ## two column layout
  mid = floor(nrow(d_par)/2)
  d_par$page = 1
  d_par$page[1:mid] = 0
  
  d_par$ypos = -rep(1:mid, 2)
  head(d_par)
  d_par.long = melt(d_par, id.vars = c("ypos", "page"), measure.vars=c("parameter", "value"))
  head(d_par.long)
  d_par.long$variable = as.character(d_par.long$variable)
  d_par.long$variable[d_par.long$variable=="parameter"] = 10
  d_par.long$variable[d_par.long$variable=="value"] = 5
  par_pl = ggplot(d_par.long, aes_string(x = "variable", y = "ypos"))  +
    coord_cartesian(xlim=c(2, 0)) + 
    geom_text(aes_string(label = "value", colour = "variable"), family="mono", hjust=1, size=2) +
    facet_wrap(~ page, ncol=2) +
    scale_colour_manual(values=c("#000000", "#5F0000")) +
    theme_bw() +
    theme(plot.margin = unit(c(1,1,1,1), "cm"), line = element_blank(), axis.title = element_blank(), panel.border = element_blank(),
          axis.text = element_blank(), strip.text = element_blank(), legend.position="none") +
    ggtitle("PAR: parameters") +
    geom_text(data = data.frame(variable=0, ypos=-mid-2, page=0), label = paste(fasta_files, collapse=line_break), size=2, hjust=0)
  GPL$add(par_pl, ".pl_params")
  ##todo: read in mqpar.xml to get group information and ppm tolerances for all groups (parameters.txt just gives Group1)
}

######
######  summary.txt ...
######

enabled_summary = getYAML(yaml_obj, "File$Summary$enabled", TRUE)
if (enabled_summary)
{
  d_smy = mq$readMQ(txt_files$summary, type="sm")
  #colnames(d_smy)
  #colnames(d_smy[[1]])
  
  id_rate_bad = getYAML(yaml_obj, "File$Summary$IDRate$Thresh_bad_num", 20)
  id_rate_great = getYAML(yaml_obj, "File$Summary$IDRate$Thresh_great_num", 35)
  
  ### MS/MS identified [%]
  dms = d_smy[[1]][,"ms.ms.identified...."]
  lab_IDd = c("bad (<" %+% id_rate_bad %+% "%)", "ok (" %+% id_rate_bad %+% "-" %+% id_rate_great %+% "%)", "great (>" %+% id_rate_great %+% "%)")
  d_smy[[1]]$color = factor(cut(dms, breaks=c(-1, id_rate_bad, id_rate_great, 100), labels=lab_IDd))
  #unique(d_smy[[1]]$color)
  cols_IDd = c("red", "blue", "green")
  cols_IDs_active = cols_IDd[lab_IDd %in% unique(d_smy[[1]]$color)]
  #cols_IDs_active
  
  d_smy[[1]]$x = 1:nrow(d_smy[[1]])
  GPL$add( 
    ggplot(d_smy[[1]], aes_string(x = "x", y = "ms.ms.identified....")) +
      geom_point(aes_string(colour = "color")) +
      xlab("raw file (ordered as in SM.txt)") + ylab("MS/MS identified [%]") +
      scale_colour_manual(values=cols_IDs_active) + 
      ggtitle("SM: MS/MS identified per RAW file") + 
      ylim(0, max(dms)*1.1) + 
      guides(color=guide_legend(title="ID class"))
    )
  ## QC measure for contamination
  qc_sm_id = d_smy[[1]][, c("raw.file", "ms.ms.identified....")]
  cname = "X030X.SM.MS2_ID_rate (>" %+% id_rate_great %+% ")"
  qc_sm_id[, cname] = qualLinThresh(qc_sm_id$ms.ms.identified.... , id_rate_great)
  QCM[["SM.MS2_ID_rate"]] = qc_sm_id[,c("raw.file", cname)]
  
  
  ## table of files with 'bad' MS/MS id rate
  bad_id_count = sum(d_smy[[1]]$color==lab_IDd[1])
  if (bad_id_count>0)
  {
    sm_badID = d_smy[[1]][d_smy[[1]]$color==lab_IDd[1],c("raw.file","ms.ms.identified....")]
    if (nrow(sm_badID) > 40)
    {
      sm_badID[40, "raw.file"] = paste(nrow(sm_badID) - 39, "more ...");
      sm_badID[40, "ms.ms.identified...."] = ""
      sm_badID = sm_badID[1:40, ]
    }
    sm_badID$ypos = -(1:nrow(sm_badID))
    head(sm_badID)
    sm_badID.long = melt(sm_badID, id.vars = c("ypos"), measure.vars=c("raw.file","ms.ms.identified...."))
    head(sm_badID.long)
    sm_badID.long$variable = as.character(sm_badID.long$variable)
    sm_badID.long$col = "#000000";
    sm_badID.long$col[sm_badID.long$variable=="ms.ms.identified...."] = "#5F0000"
    sm_badID.long$variable[sm_badID.long$variable=="raw.file"] = "6"
    sm_badID.long$variable[sm_badID.long$variable=="ms.ms.identified...."] = "8"
    sm_badID.long$variable = as.numeric(sm_badID.long$variable)
    sm_badID.long$size = 2
    sm_badID.long2 = rbind(data.frame(ypos=0, variable=c(6, 8), value=c("raw file", "% identified"), col="#000000", size=3), sm_badID.long)
    smbad_pl = ggplot(sm_badID.long2, aes_string(x = "variable", y = "ypos"))  +
      xlim(0, 11) + 
      geom_text(aes_string(label = "value"), color = sm_badID.long2$col, hjust=1, size=sm_badID.long2$size) +
      theme_bw() +
      theme(plot.margin = unit(c(1,1,1,1), "cm"), line = element_blank(), axis.title = element_blank(), panel.border = element_blank(),
            axis.text = element_blank(), strip.text = element_blank(), legend.position="none") +
      ggtitle(paste0("SM: Files with '", lab_IDd[1], "' ID rate (", round(bad_id_count*100/nrow(d_smy[[1]])),"% of samples)"))
      
    GPL$add(smbad_pl)
  }
}  


######
######  proteinGroups.txt ...
######

enabled_proteingroups = getYAML(yaml_obj, "File$ProteinGroups$enabled", TRUE)
enabled_pg_ratioLabIncThresh = getYAML(yaml_obj, "File$ProteinGroups$RatioPlot$LabelIncThresh_num", 8)
if (enabled_proteingroups)
{
    
  d_pg = mq$readMQ(txt_files$groups, type="pg", col_subset=NA, filter="R")
  
  ## Contaminants stats
  idx_int = grepv("^intensity\\.", colnames(d_pg))
  if (length(idx_int) == 0)
  { ##apparently no conditions were used, so there is just 'intensity'
    idx_int = "intensity"
  }
  con_stats = t(sapply(idx_int, function(x) sum(as.numeric(d_pg[d_pg$contaminant, x]))/sum(as.numeric(d_pg[, x]))*100 ))
  con_stats[is.na(con_stats)] = 0
  colnames(con_stats) = simplifyNames(delLCP(idx_int))
  
  #barplot(con_stats, ylim=c(0,max(20, max(con_stats)*1.1)), main="PG: Contaminant per condition", xlab="", ylab="% intensity of contaminants", las=3,)
  #abline(a=5, b=0, col="red", lwd=4)
  plotContsPG = function(datav) {
    datav$section = as.integer(seq(0, nrow(datav)/40, length.out=nrow(datav)))
    pl = 
      ggplot(data=datav, aes_string(x = "x", y = "y")) +
        geom_bar(stat="identity") +
        theme(axis.text.x = element_text(angle = 90, vjust = 0.5)) +
        xlab("")  +
        ggtitle("PG: Contaminant per condition") +
        ylab("contaminant (% intensity)") +
        geom_hline(aes_string(yintercept = "5"), linetype = 'dashed') +
        facet_wrap(~ section, ncol = 1, scales="free_x")
    return (pl)
  }
  df.con_stats = data.frame(x=colnames(con_stats), y=as.vector(con_stats[1,]))
  # plot list (for later plotting)
  pg_plots_cont = byXflex(df.con_stats, 1:nrow(df.con_stats), 120, plotContsPG, sort_indices=F)
  for (p in pg_plots_cont) GPL$add(p);
  
  ### warn of special contaminants!
  ## these need to be in FASTA headers (description is not enough)!
  ## syntax:  list( contaminant1 = c(name, threshold), contaminant2 = c(...), ...)
  contaminant_alarm = list("cont_MYCO" = c(name="MYCOPLASMA", threshold=1)) # name (FASTA), threshold for % of unique peptides
  #contaminant_alarm = list("cont_MYCO" = c(name="UniRef100", threshold=1)) # name (FASTA), threshold for % of unique peptides
  #contaminant_alarm = list("cont_MYCO" = c("MYCOPLASMA", 1), "cont_corrbt" = c("corrbt7", 1)) 
  # yaml_contaminants = contaminant_alarm
  yaml_contaminants = getYAML(yaml_obj, "File$ProteinGroups$SpecialContaminants", contaminant_alarm)
  for (ca_entry in yaml_contaminants)
  {
    #ca_entry = yaml_contaminants[[1]]
    ca = ca_entry[1]
  
    # ca = yaml_contaminants[1]
    # idx = 1:30
    idx = grep(ca, d_pg$fasta.header, ignore.case = T)
  
    ## we might or might not have found something... we plot it anyways, so the user can be sure that we searched for it
  
    ## total number of unique peptides
    unique_total = sum(d_pg$unique.peptides[idx])
    idx_uniquePep = grepv("^unique.peptides", colnames(d_pg))
    idx_intensity = grepv("^intensity", colnames(d_pg))
    
    ca_protgroups = d_pg$protein.ids[idx]
    ca_samples_pep = colSums(d_pg[idx, idx_uniquePep, drop=F])
    
    ca_samples_intProportion = colSums(d_pg[idx, idx_intensity, drop=F]) / colSums(d_pg[, idx_intensity, drop=F], na.rm = T) * 100
    names(ca_samples_intProportion) = paste0("int", delLCP(names(ca_samples_intProportion)))
  
    ca_samples_pepProportion = colSums(d_pg[idx, idx_uniquePep, drop=F]) / colSums(d_pg[, idx_uniquePep, drop=F], na.rm = T) * 100
    above.thres = (ca_samples_pepProportion > as.numeric(ca_entry[2]))
    names(ca_samples_pepProportion) = paste0("pep", delLCP(names(ca_samples_pepProportion)))
    
    names(above.thres) = delLCP(names(above.thres))
    above.thres
    
    ## build data for plotting
    bar.data = data.frame(name = c(names(ca_samples_pepProportion), names(ca_samples_intProportion)),
                          value = c(ca_samples_pepProportion, ca_samples_intProportion))
    bar.data$name = shortenStrings(simplifyNames(as.character(factor(bar.data$name, levels=bar.data$name))))
    bar.data$group = c(rep("pepCount", length(ca_samples_pepProportion)), rep("int", length(ca_samples_intProportion)))
    #pdf("test.pdf")
    main_sub_found = ""
    main_col = "red"
    if (sum(above.thres) == 0) {
      #install.packages("gridExtra")
      #library(gridExtra)
      #grid.newpage()
      #gt = grid.text((paste("Not found")),
      #          x = unit(.5, "npc"), y = unit(.5, "npc"), just = c("center", "bottom"), 
      #          gp = gpar(fontface = "bold", fontsize = 18, col = "red"))
      main_sub_found = "\n\nNot found"
      main_col="black"
    }
  
    if (sum(bar.data$value)==0)
    { ## identifier was not found in any sample
      plot(0:100, 0:100, type="n", axes=F, xlab="", ylab="")
      mtext(line=-2, paste0("Contaminant '", ca, "' was not found in any sample.\n\nDid you use the correct database?"))  
    } else {
      plotContUser = function(datav, extra_limit) {
        #cat(paste0("CA entry is ", extra_limit, "\n"))
        datav$section = as.integer(seq(0, nrow(datav)/40, length.out = nrow(datav)))
        pr = ggplot(datav, aes_string(x = "factor(name)", y = "value")) +
            geom_bar(stat="identity", aes_string(fill = "group"), position = "dodge") +
            theme(axis.text.x = element_text(angle = 90, vjust = 0.5)) +
            xlab("")  +
            theme(plot.title = element_text(colour = main_col)) +
            ylab("abundance (%)") +
            ylim(c(0, max(extra_limit, max(bar.data$value, extra_limit)*1.1))) +
            geom_hline(yintercept = extra_limit, linetype = 'dashed') +
            facet_wrap(~ section, ncol = 1, scales = "free_x")
        pr = addGGtitle(pr, paste0("PG: Contaminant '", ca, "'"), main_sub_found)
        GPL$add(pr)
        return(1)
      }
      byXflex(data = bar.data, indices = 1:nrow(bar.data), subset_size = 120, FUN = plotContUser, sort_indices=F, extra_limit = as.numeric(ca_entry[2]))
    }
  
    #dev.off()
    
    report_short = pastet("Contaminant:", ca, paste0(sum(above.thres),"/",length(ca_samples_pep)," sample-classes"), paste0(unique_total," unique peptides total"))
    report_samples  = pastet("Contaminant-details (name, sample, peptides%): " , ca, names(ca_samples_pepProportion), ca_samples_pepProportion, collapse="\n")
    report_samples2 = pastet("Contaminant-details (name, sample, intensity%): ", ca, names(ca_samples_intProportion), ca_samples_intProportion, collapse="\n")
    cat(pasten(report_short, report_samples, report_samples2), file=stats_file, append=T, sep="\n")
    
  } ## contaminant loop
  
  
  ##
  ## stats file
  ##
  con_stats_smry = quantile(con_stats[,1], probs=c(0,0.5,1))
  cat(pastet("contamination(min,median,max) [%]", paste(con_stats_smry, collapse=",")), file=stats_file, append=T, sep="\n")  
  
  
  clusterCols = list()
  ##
  ## intensity boxplots
  ##
  param_name_PG_intThresh = "File$ProteinGroups$IntensityThreshLog2_num"
  param_def_PG_intThresh = 25 ## default median intensity in log2 scale
  param_PG_intThresh = getYAML(yaml_obj, param_name_PG_intThresh, param_def_PG_intThresh)
  if (!is.numeric(param_PG_intThresh) || !(param_PG_intThresh %in% 1:100))
  { ## reset if value is weird
    print("YAML value for '" %+% param_name_PG_intThresh %+% "' is invalid ('" %+% param_PG_intThresh %+% "'). Using default of " %+% param_def_PG_intThresh %+% ".")
    param_PG_intThresh = param_def_PG_intThresh
  }
  
  
  colsSIL = grepv("^intensity.[HLM].", colnames(d_pg))
  colsLF = grepv("^intensity.[^HLM].", colnames(d_pg))
  colsOneCond = "intensity"
  if (length(colsSIL)) colsW = colsSIL else if (length(colsLF)) colsW = colsLF else colsW = colsOneCond
  clusterCols$raw.intensity = colsW ## cluster using intensity
  #cat("colsW:\n")
  #cat(paste0(colsW, collapse=","))
  ## some stats (for plot title)
  medians_no0 = sort(apply(log2(d_pg[, colsW, drop=F]), 2, function(x) quantile(x[x>0], probs=0.5, na.rm=T))) # + c(0,0,0,0,0,0))
  int_dev_no0 = RSD(medians_no0)
  ## do not remove zeros (but add +1 since RSD is 'NA' when 'inf' is included in log-data)
  medians = sort(apply(log2(d_pg[, colsW, drop=F]+1), 2, quantile, na.rm=T, probs=0.5)) # + c(0,0,0,0,0,0))
  int_dev = RSD(medians)
  int_dev.s = pastet("INT RSD [%]", round(int_dev, 3))
  lpl = boxplotCompare(data = melt(d_pg[, colsW, drop=F], id.vars=c()), log2 = T, 
                 mainlab="PG: intensity distribution",
                 ylab = "log2 intensity",
                 sublab=paste0("RSD ", round(int_dev_no0, 1),"% (should be < 5%)\nRSD ", round(int_dev, 1),"% (with 0's remaining) [high RSD indicates few peptides])"),
                 abline = param_PG_intThresh)
  for (pl in lpl) GPL$add(pl);
            
  cat(int_dev.s, file=stats_file, append=T, sep="\n")
  
  ##
  ## LFQ boxplots
  ##
  colsSIL = grepv("^lfq.intensity.[HLM].", colnames(d_pg))
  colsLF = grepv("^lfq.intensity.[^HLM].", colnames(d_pg))
  if (length(c(colsSIL, colsLF)) > 0)
  {
    if (length(colsSIL)) colsW = colsSIL else colsW = colsLF
    clusterCols$lfq.intensity = colsW ## cluster using LFQ
    ## some stats (for plot title)
    medians_no0 = sort(apply(log2(d_pg[, colsW, drop=F]), 2, function(x) quantile(x[x>0], probs=0.5, na.rm=T))) # + c(0,0,0,0,0,0))
    lfq_dev_no0 = RSD(medians_no0)
    ## do not remove zeros (but add +1 since RSD is 'NA' when 'inf' is included in log-data)
    medians = sort(apply(log2(d_pg[, colsW, drop=F]+1), 2, quantile, probs=0.5, na.rm=T)) # + c(0,0,0,0,0,0))
    lfq_dev = RSD(medians)
    lfq_dev.s = pastet("LFQ RSD [%]", round(lfq_dev, 3))
    lpl = boxplotCompare(data = melt(d_pg[, colsW, drop=F], id.vars=c()), log2 = T, 
                         mainlab="PG: LFQ intensity distribution", 
                         ylab = "log2 LFQ intensity",
                         sublab= paste0("RSD ", round(lfq_dev_no0, 1),"% (should be < 5%)\nRSD ", round(lfq_dev, 1),"% (with 0's remaining) [high RSD indicates few peptides])"),
                         abline = param_PG_intThresh)
    for (pl in lpl) GPL$add(pl);
    cat(lfq_dev.s, file=stats_file, append=T, sep="\n")
  }
  
  ##
  ## iTRAQ/TMT, reporter ion intensity boxplot
  ##
  colsITRAQ = grepv("^reporter.intensity.[0-9].", colnames(d_pg))
  if (length(colsITRAQ) > 0)
  {
    colsW = colsITRAQ
    clusterCols$reporter.intensity = colsW ## cluster using reporters
    ## some stats (for plot title)
    medians_no0 = sort(apply(log2(d_pg[, colsW, drop=F]), 2, function(x) quantile(x[x>0], probs=0.5, na.rm=T))) # + c(0,0,0,0,0,0))
    reprt_dev_no0 = RSD(medians_no0)
    ## do not remove zeros (but add +1 since RSD is 'NA' when 'inf' is included in log-data)
    medians = sort(apply(log2(d_pg[, colsW, drop=F]+1), 2, quantile, probs=0.5, na.rm=T)) # + c(0,0,0,0,0,0))
    reprt_dev = RSD(medians)
    reprt_dev.s = pastet("Reporter RSD [%]", round(reprt_dev, 3))
    lpl = boxplotCompare(melt(d_pg[, colsW, drop=F], id.vars=c()), log2 = T, ylab="log2 intensity", 
                   mainlab="PG: reporter intensity distribution", 
                   sublab= paste0("RSD ", round(reprt_dev_no0, 1),"% (should be < 5%)\nRSD ", round(reprt_dev, 1),"% (with 0's remaining) [high RSD indicates low reporter intensity])"),
                   abline = param_PG_intThresh)
    for (pl in lpl) GPL$add(pl);
    cat(reprt_dev.s, file=stats_file, append = T, sep="\n")
  }
  
  
  ##
  ## PCA
  ##
  ## some clustering (its based on intensity / lfq.intensity columns..)
  ## todo: maybe add ratios -- requires loading from txt though..
  for (cond in names(clusterCols))
  {
    #cond = names(clusterCols)[3]
    #print(clusterCols[cond])
    if (length(clusterCols[[cond]]) <= 1) 
    { ## only one condition.. PCA does not make sense (and will not work)
      next;
    }
    ## remove contaminants
    data = t(d_pg[!d_pg$contaminant, unlist(clusterCols[cond]), drop=F])
    ## remove constant/zero columns (== dimensions == proteins)
    data = data[, colSums(data, na.rm=T) > 0, drop=F]
    rownames(data) = simplifyNames(strings = rownames(data), infix_iterations = 2)
    lpl = getPCA(data = data, gg_layer = ggtitle(paste("PG: PCA\n", sub(".", " ", cond, fixed=T))))[["plots"]]
    for (pl in lpl) GPL$add(pl);
  }
  
  
  ##################################
  ## ratio plots
  ##################################
  ## get ratio column
  ratio_cols = grepv("^ratio\\.h\\.l", colnames(d_pg))
  ## remove everything else
  ratio_cols = grepv("^ratio.h.l.normalized", ratio_cols, invert=T)
  ratio_cols = grepv("^ratio.h.l.count", ratio_cols, invert=T)
  ratio_cols = grepv("^ratio.h.l.variability", ratio_cols, invert=T)
  ratio_cols
  
  if (length(ratio_cols) > 0)
  {
    colnames(d_pg)
    
    ## remove reverse and contaminants (might skew the picture)
    idx_row = !d_pg$contaminant & !d_pg$reverse
    d_sub = log2(d_pg[idx_row, ratio_cols, drop=F])
    ## rename "ratio.l.h" to "ratio.l.h.l.h"
    colnames(d_sub)[1] = "l.h"
    ## simplify the rest
    if (ncol(d_sub) > 1) 
    {
      colnames(d_sub)[-1] = simplifyNames(strings = delLCP(colnames(d_sub)[-1]))
    }
    #summary(d_sub)
    # 
    # plot(density(d_sub[,1], bw = "SJ", adjust=1, na.rm=T, n=128))
    # plot(d_sub[,1])
    # h = density(d_sub[,1], bw = "SJ", adjust=1, na.rm=T, n=128)
    
    
    ## get ranges to fix breaks for density intervals
    # breaks = seq(min(d_sub, na.rm=T), max(d_sub, na.rm=T), length.out=(max(dd, na.rm=T)-min(dd, na.rm=T))/0.5)
    # mid = hist(d_sub[, 1], breaks = breaks)$mids
    ratio.densities = do.call(rbind, (lapply(1:ncol(d_sub), function(x) {
      h = density(d_sub[ ,x], bw = "SJ", adjust=2, na.rm=T)
      name = colnames(d_sub)[x]
      count = sum(getMaxima(h$y))
      if (count > 1) name = paste(name, "*")
      df = data.frame(x = h$x, y = h$y, col = name, multimodal = (count>1))
      return (df)
    })))
    ratio.densities$alpha = c(0.8, 1)[ratio.densities$multimodal+1]
    ratio.densities$ltype = c("dotted", "solid")[ratio.densities$multimodal+1]
    #head((ratio.densities))
    
    
    legend_title = "group"
    ## compute label incorporation?
    ratio.mode = ddply(ratio.densities, "col", .fun = function(x) {
      mode = x$x[which.max(x$y)]
      return (data.frame(mode = mode))
    })
    
    ## on more than ratio 1:8 or 8:1 ratio, report label incorporation
    # enabled_pg_ratioLabIncThresh == 8 by default
    if (max(abs(ratio.mode$mode)) > abs(log2(enabled_pg_ratioLabIncThresh))) {
      cat(paste0("Maximum ratio (log2) was ", max(abs(ratio.mode$mode)), ", reaching the threshold of ", abs(log2(enabled_pg_ratioLabIncThresh)), " for label-incorporation computation.\nComputing ratios ...\n"))
      ## back to normal scale
      ratio.norm = 2^ratio.mode$mode
      ## compute incorporation
      ratio.inc =  ratio.norm / (ratio.norm+1) * 100
      ## round
      ratio.mode$li = round(ratio.inc)
      ## new label
      ratio.mode$col_new = ratio.mode$col %+% " (" %+% ratio.mode$li %+% "%)"
      ## replace column names in data.frame
      ratio.densities$col = ratio.mode$col_new[match(ratio.densities$col, ratio.mode$col)]
      ## notify user via legend title
      legend_title = "group\n(with label inc)"
    } else
    {
      cat(paste0("Maximum ratio (log2) was ", max(abs(ratio.mode$mode)), ", NOT reaching the threshold of ", abs(log2(enabled_pg_ratioLabIncThresh)), " for label-incorporation computation.\nSkipping ratios ...\n"))
    }
    
    title_ratio = "PG: ratio density\n(w/o contaminants)"
    title_col = "black"
    if (any(ratio.densities$multimodal))
    {
      title_ratio = paste0(title_ratio, "\nWarning: multimodal densities detected")
      title_col = "red"
    }
    
    plotRatios = function(df_ratios, d_min, d_max, title_col)
    {
      br = c(2, 5, 10, 20);
      GPL$add(
        ggplot(data = df_ratios, aes_string(x = "x", y = "y", colour = "col")) + 
          facet_grid(col ~ ., scales = "free_y") +
          geom_line(aes_string(linetype="ltype", alpha = "alpha"), size = 1.2) +
          geom_area(aes_string(fill = "col"), alpha=0.5) +
          xlab("ratio")  +
          ylab("density")  +
          #facet_grid(col ~ ) +
          scale_fill_manual(values = rep(brewer.pal(6,"Accent"), times=400), guide_legend(legend_title)) + 
          scale_colour_manual(values = rep(brewer.pal(6,"Accent"), times=400), guide_legend(legend_title)) +
          scale_linetype_manual(values = c("dotted"="dotted", "solid"="solid"), 
                                labels=c("dotted"="unimodal", "solid"="multimodal"),
                                guide_legend("mode")
          ) +
          scale_x_continuous(limits = c(d_min, d_max), trans = "identity", breaks = c(-br, 0, br), labels=c(paste0("1/",2^(br)), 1, 2^br)) +
          guides(alpha=FALSE, colour=FALSE) +
          theme(plot.title = element_text(colour = title_col)) +
          theme_bw() +
          geom_vline(alpha = 0.5, xintercept = 0, colour = "green", linetype = "dashed", size = 1.5) +
          ggtitle(title_ratio)
      )
      return (1)
    }
    
    byXflex(ratio.densities, ratio.densities$col, 5, plotRatios, sort_indices = F, d_min = min(d_sub, na.rm=T), d_max = max(d_sub, na.rm=T), title_col)
    
  }
    
}

######
######  evidence.txt ...
######

enabled_evidence = getYAML(yaml_obj, "File$Evidence$enabled", TRUE)
if (enabled_evidence)
{
  #d_evd_s = mq$readMQ(txt_files$evd, type="ev", filter = "", nrows=10000)
  #d_evd_s = mq$readMQ(txt_files$evd, type="ev", filter = "")
  #head(d_evd_s)
  #colnames(d_evd_s)
  #table(d_evd_s$reverse)
  #[grep("ount", colnames(d_evd))]
  
  ## protein.names is only available from MQ 1.4 onwards
  d_evd = mq$readMQ(txt_files$evd, type="ev", filter="R", col_subset=c("proteins", "Retention.Length", "retention.time.calibration", 
                                                                       "Match.Time.Difference", "^Sequence$", "^intensity$", "Mass\\.Error", 
                                                                       "^uncalibrated...calibrated." , "Raw.file", "^Protein.Group.IDs$", 
                                                                       "Contaminant", "Retention.time$", "^m.z$", "^Contaminant", "[RK]\\.Count", 
                                                                       "^Charge$", "modified.sequence", "^Mass$", "^protein.names$"))
  ##
  ## write peptides to stats file (remnant from proteinGroups)
  ##
  for (ca_entry in contaminant_alarm)
  {
    ca = ca_entry[1]
    ## this relies on ProteinGroups and Evidence!!!!
    if (enabled_proteingroups)
    {
      idx_pg = grep(ca, d_pg$fasta.header, ignore.case = T)
      if (length(idx_pg))
      { ## found something
        idx_pep = which(d_evd$protein.group.ids %in% d_pg$id[idx_pg])
        cat(pastet("contamination-proteins:", ca, paste((d_pg$majority.protein.ids[idx_pg]), collapse=",")), file=stats_file, append=T, sep="\n") 
        cat(pastet("contamination-peptides:", ca, paste(unique(d_evd$sequence[idx_pep]), collapse=",")), file=stats_file, append=T, sep="\n") 
      }
    }
  }
  
  ##
  ## sort by rawfile as shown in the summary.txt (or whatever the first txt file was)
  ##
  d_evd = d_evd[order(match(as.character(d_evd$fc.raw.file), mq$raw_file_mapping$to)),]
  ## sort fc.raw.file's factor values as well
  d_evd$fc.raw.file = factor(d_evd$fc.raw.file, levels = mq$raw_file_mapping$to, ordered = TRUE)
  
  #d_evd = mq$readMQ(txt_files$evd, type="ev", filter="R", col_subset=c("labeling.state", "Match.Time.Difference", "fasta.headers", "^intensity$", "Raw.file", "^Protein.Group.IDs$"))
  #summary(head(d_evd))
  #head(d_evd)
  #colnames(d_evd)
{
  ## ms.ms.count is always 0 when mtd has a number; 'type' is always "MULTI-MATCH" and ms.ms.ids is empty!
  #dsub = d_evd[,c("ms.ms.count", "match.time.difference")]
  #head(dsub[is.na(dsub[,2]),])
  #sum(0==(dsub[,1]) & is.na(dsub[,2]))
  ##
  ## MQ1.4 MTD is either: NA or a number
  ##
  
  ## intensity of peptides
  param_name_EV_intThresh = "File$Evidence$IntensityThreshLog2_num"
  param_def_EV_intThresh = 23 ## default median intensity in log2 scale
  param_EV_intThresh = getYAML(yaml_obj, param_name_EV_intThresh, param_def_EV_intThresh)
  if (!is.numeric(param_EV_intThresh) || !(param_EV_intThresh %in% 1:100))
  { ## reset if value is weird
    print("YAML value for '" %+% param_name_EV_intThresh %+% "' is invalid ('" %+% param_EV_protThresh %+% "'). Using default of " %+% param_def_EV_intThresh %+% ".")
    param_EV_intThresh = param_def_EV_intThresh
  }
  
  colnames(d_evd)
  medians_pep = ddply(d_evd[ ,c("fc.raw.file", "intensity")], "fc.raw.file",
                      function(x) data.frame(med = log2(quantile(x$intensity, probs=0.5, na.rm=T))))
  
  int_dev_pep = RSD((medians_pep$med))
  int_dev.s = pastet("INT RSD [%]", round(int_dev_pep, 3))
  lpl = boxplotCompare(data = d_evd[, c("fc.raw.file", "intensity")], log2 = T, 
                       mainlab="EVD: peptide intensity distribution",
                       ylab = "log2 intensity",
                       sublab=paste0("RSD ", round(int_dev_pep, 1),"% (should be < 5%)\n"),
                       abline = param_EV_intThresh)
  for (pl in lpl) GPL$add(pl);
  ## QC measure for peptide intensity
  qc_pepint = medians_pep
  cname = "X003X.EVD.Peptide_Intensity (>" %+% param_def_EV_intThresh %+% ")"
  qc_pepint[,cname] = qualLinThresh(qc_pepint$med, param_def_EV_intThresh)
  QCM[["EVD.PepIntensity"]] = qc_pepint[, c("fc.raw.file", cname)]
  
  
  # use only if it contains information (all NA if disabled)
  has_mtd = !is.na(d_evd$match.time.difference)
  head(has_mtd)
  # if ALL na's, just fill it with "true"
  #length(na.omit(d_evd$match.time.difference))==0
  #if (length(na.omit(d_evd$match.time.difference))==0) has_mtd = rep(T,length(mtd))
  
  ## only count protein groups from non-inferred evidence
  # get only the column without MTDs
  d_evd$hasMTD = has_mtd
  
  protGroupCount_pre = ddply(d_evd[, c("hasMTD", "fc.raw.file", "protein.group.ids")], "fc.raw.file", .fun = function(x){
    ## proteins
    # remove duplicates (since strsplit below is expensive)
    x$group_mtdinfo = paste(x$protein.group.ids, x$hasMTD, sep="_")
    xpro = x[!duplicated(x$group_mtdinfo),]
    p_groups = lapply(as.character(xpro$protein.group.ids), function(x) {
      return (strsplit(x, split=";", fixed=T))
    })
    # get number of unique groups
    pg_count_noMBR = length(unique(unlist(p_groups[!xpro$hasMTD])))
    pg_count_extraMBR = length(unique(unlist(p_groups))) - pg_count_noMBR
    
    ## peptides
    ## (we count double sequences... mhh...)
    pep_count_noMBR = sum(!x$hasMTD)
    pep_count_MBRgain = nrow(x) - pep_count_noMBR
    
    return (c(proteinCount_noMBR = pg_count_noMBR, 
              proteinCount_MBRgain = pg_count_extraMBR,
              pep_count_noMBR = pep_count_noMBR,
              pep_count_MBRgain = pep_count_MBRgain))
  })
  protGroupCount_pre
  ## manually melt
  pgc =       data.frame(fc.raw.file = protGroupCount_pre$fc.raw.file, protCount = protGroupCount_pre$proteinCount_noMBR, match = "no")
  pgc = rbind(pgc,
              data.frame(fc.raw.file = protGroupCount_pre$fc.raw.file, protCount = protGroupCount_pre$proteinCount_MBRgain, match = "yes"))
  pgc
  ## re-order (ddply somehow reorders, even if we use ordered factors...)
  pgc$fc.raw.file = factor(pgc$fc.raw.file, levels = mq$raw_file_mapping$to, ordered = TRUE)
  #levels(pgc$fc.raw.file)
  
  # combine Prot & Pep stats
  ## Warn: this is still different from summary.txt...
  #colnames(ppg) = c("# protein groups", "# peptides", "# peptides\n(incl. matched)", "file")
  #mdat = melt(ppg, id.vars="file")
  
  head(pgc)
  pgc$block = factor(assignBlocks(pgc$fc.raw.file, 30))
  max_prot = max(protGroupCount_pre$proteinCount_noMBR + protGroupCount_pre$proteinCount_MBRgain)
  
  param_name_EV_protThresh = "File$Evidence$ProteinCountThresh_num"
  param_def_EV_protThresh = 3500
  param_EV_protThresh = getYAML(yaml_obj, param_name_EV_protThresh, param_def_EV_protThresh)
  if (!is.numeric(param_EV_protThresh) || !(param_EV_protThresh %in% 1:1e5))
  { ## reset if value is weird
    print("YAML value for '" %+% param_name_EV_protThresh %+% "' is invalid ('" %+% param_EV_protThresh %+% "'). Using default of " %+% param_def_EV_protThresh %+% ".")
    param_EV_protThresh = param_def_EV_protThresh
  }
    
  #require(RColorBrewer)
  ddply(pgc, "block", .fun = function(x) {
    #x$s.raw.file = simplifyNames((as.character(x$raw.file)))
    GPL$add(ggplot(x, aes_string(x = "fc.raw.file", y = "protCount", fill = "match")) +
            geom_bar(stat = "identity", position = "stack") +
            xlab("") +
            ylab("count") +
            scale_x_discrete_reverse(x$fc.raw.file) +
            ylim(0, max(param_EV_protThresh, max_prot)*1.1) +
            scale_fill_manual(values = rep(brewer.pal(6,"Accent"), times=400)) +
            ggtitle("EV: Protein ID count") + 
            geom_abline(alpha = 0.5, intercept = param_EV_protThresh, slope = 0, colour = "green", linetype = "dashed", size = 1.5) +
            coord_flip()
          )
    return (1)
  })
  ## QC measure for protein ID performance
  qc_protc = pgc[pgc$match=="no", c("fc.raw.file", "protCount")]
  cname = "X045X.EVD.Protein_Count (>" %+% param_EV_protThresh %+% ")"
  qc_protc[,cname] = qualLinThresh(qc_protc$protCount, param_EV_protThresh)
  QCM[["EVD.ProtCount"]] = qc_protc[, c("fc.raw.file", cname)]
  
  
  ##
  ## EVD: peptide count
  ##
  pepc =       data.frame(fc.raw.file = protGroupCount_pre$fc.raw.file, pepCount = protGroupCount_pre$pep_count_noMBR, match = "no")
  pepc = rbind(pepc,
               data.frame(fc.raw.file = protGroupCount_pre$fc.raw.file, pepCount = protGroupCount_pre$pep_count_MBRgain, match = "yes"))
  pepc
  ## re-order (ddply somehow reorders, even if we use ordered factors...)
  pepc$fc.raw.file = factor(pepc$fc.raw.file, levels = mq$raw_file_mapping$to, ordered = TRUE)
  
  head(pepc)
  pepc$block = factor(assignBlocks(pepc$fc.raw.file, 30))
  max_pep = max(protGroupCount_pre$pep_count_noMBR + protGroupCount_pre$pep_count_MBRgain)
  
  param_name_EV_pepThresh = "File$Evidence$PeptideCountThresh_num"
  param_def_EV_pepThresh = 15000
  param_EV_pepThresh = getYAML(yaml_obj, param_name_EV_pepThresh, param_def_EV_pepThresh)
  if (!is.numeric(param_EV_pepThresh) || !(param_EV_pepThresh %in% 1:1e6))
  { ## reset if value is weird
    print("YAML value for '" %+% param_name_EV_pepThresh %+% "' is invalid ('" %+% param_EV_pepThresh %+% "'). Using default of " %+% param_def_EV_pepThresh %+% ".")
    param_EV_pepThresh = param_def_EV_pepThresh
  }

  #require(RColorBrewer)
  ddply(pepc, "block", .fun = function(x) {
    #x$s.raw.file = simplifyNames((as.character(x$raw.file)))
    p = ggplot(x, aes_string(x = "factor(fc.raw.file)", y = "pepCount", fill = "match")) +
            geom_bar(stat = "identity", position = "stack") +
            xlab("") +
            ylab("count") +
            scale_x_discrete_reverse(x$fc.raw.file) +
            ylim(0, max(param_EV_pepThresh, max_pep)*1.1) +
            geom_abline(alpha = 0.5, intercept = param_EV_pepThresh, slope = 0, colour = "green", linetype = "dashed", size = 1.5) +
            scale_fill_manual(values = rep(brewer.pal(6,"Accent"), times=400)) +
            ggtitle("EV: Peptide ID count") + 
            coord_flip()
    GPL$add(p)
    return (1)
  })
  
  ## QC measure for peptide ID performance
  qc_pepc = pepc[pepc$match=="no", c("fc.raw.file", "pepCount")]
  cname = "X040X.EVD.Peptide_Count (>" %+% param_EV_pepThresh %+% ")"
  qc_pepc[,cname] = qualLinThresh(qc_pepc$pepCount, param_EV_pepThresh)
  QCM[["EVD.PepCount"]] = qc_pepc[, c("fc.raw.file", cname)]
  
  ##
  ## retention time calibration (to see if window was sufficiently large)
  if (any(d_evd$retention.time.calibration, na.rm=T)) 
  {
    MBR_warning = ""
    if (quantile(abs(d_evd$retention.time.calibration), probs = 0.99) < 1e-4)
    { ## Probably MBR was switched off
      ## Alternatively, we could use 'd_evd$match.time.difference', but its not guaranteed that the user has activated it
      MBR_warning = "Warning: MBR was off - data are (very small) MQ artifacts"  
    }
    
    param_name_mbr = "File$Evidence$MatchBetweenRuns_wA"
    param_evd_mbr = getYAML(yaml_obj, param_name_mbr, "auto")
    if (param_evd_mbr == FALSE || (nchar(MBR_warning)>0 && param_evd_mbr=="auto"))
    {
      MBR_warning_auto = ""
      if (nchar(MBR_warning)>0) MBR_warning_auto = "Match-between-runs has no data to show."
      #plot(0:100, 0:100, type="n", axes=F, xlab="",ylab="")
      #mtext(line=-2, paste0("'Match-between-runs' plot is disabled.\n\nYAML variable '", param_name_mbr, "' is set to '",  param_evd_mbr,"'.\n", MBR_warning_auto))  
    } else
    {
      ## global histogram of delta times
      hist(d_evd$retention.time.calibration, 100, 
           main=paste0("EV: Summary of time difference between\nmatched features across files\n", MBR_warning), 
           xlab="time [min]",
           ylab="count")
      
      ## thin out data, since it takes ages to draw the plot in PDF (100k datapoints are common)
      evd_RT_thin = d_evd[,c("retention.time", "retention.time.calibration", "fc.raw.file")]
      ##  .. everything this close together is deleted
      RT_delta = (max(evd_RT_thin$retention.time) - min(evd_RT_thin$retention.time))/1000
      evd_RT_t = ddply(evd_RT_thin, "fc.raw.file", function(x) {
        nstart = nrow(x)
        #x = evd_RT_thin[1:1000,]
        ## first remove duplicates (they cannot possibly pass the filter)
        x = x[!duplicated(x$retention.time), ]
        ##
        x = x[order(x$retention.time), ]
        local_deltas = c(0, (x$retention.time[-1] - x$retention.time[-nrow(x)]))
        ld_cs = cumsum(local_deltas)
        x = x[!duplicated(round(ld_cs / RT_delta)),]
        #print("Saved " %+% round(100 - nrow(x)/nstart*100) %+% "% for " %+% x$fc.raw.file[1])
        return(x)
      })
      ##head(evd_RT_t)
      
      #require(splines) ## for ns()
      splitRTAlignByRawFile = function(RTdata) {
        pl = ggplot(data=RTdata, aes_string(x = "retention.time", y = "retention.time.calibration")) 
        # needs to be done here and not at the end (due to facet_wrap)
        pl = addGGtitle(pl, "EVD: Retention Time Mapping", MBR_warning)
        pl = pl +
          geom_point(alpha=0.5) +
          stat_smooth(method = "lm", formula = y ~ ns(x,30), se = TRUE, size=1, colour = "red") +
          facet_wrap( ~ fc.raw.file) +
          ylab("RT correction [min]") +
          xlab("retention time [min]")
        GPL$add(pl)
        return(1)
      }
      
      byX(evd_RT_t, as.numeric(as.factor(evd_RT_t$fc.raw.file)), 8, splitRTAlignByRawFile, sort_indices = F)
      
      ## QC measure for alignment quality
      ## compute deviation of medians
      qc_RT = ddply(d_evd[, c("match.time.difference", "fc.raw.file")], "fc.raw.file", 
                    function(x) data.frame(X024X.EVD.RT_Align = qualGauss2Mix(x$match.time.difference)))
      QCM[["X024X.EVD.RT_Align"]] = qc_RT
      
    }
  }
  
  ##
  ## additional evidence by matching MS1 by AMT across files
  if (any(d_evd$match.time.difference, na.rm=T)) {
    ## scatter plot: for each raw file give median time diff and # peptides used for matching
    r = (by(d_evd$match.time.difference, d_evd$raw.file, function(x) {
      match_count_abs = sum(!is.na(x));
      match_count_pc  = round(100*sum(!is.na(x))/length(x))
      c(match_count_abs, match_count_pc)
    }))
    tmp_lab = names(r)
    r = unlist(r)
    mtr.df = data.frame(abs = r[seq(1,length(r),by=2)], pc = r[seq(2,length(r),by=2)])
    mtr.df$lab = tmp_lab
    ## shorten labels (if required)
    if (max(nchar(mtr.df$lab)) > 10) {
      mtr.df$lab = as.character(d_evd$fc.raw.file[match(mtr.df$lab, d_evd$raw.file)])
    }
    
    
    p_amt = ggplot(data=mtr.df, aes_string(x = "abs", y = "pc", col = "lab")) + 
      geom_point(size=2) + 
      #geom_text(size=2, vjust=1, aes_string(alpha=0.5)) + 
      ggtitle(paste0("EVD: Peptides inferred by AMT-matching\n", round(100*sum(!is.na(d_evd$match.time.difference))/nrow(d_evd)) ,"% average" )) +
      xlab("inferred by MS1 [count]") +
      ylab("inferred by MS1 [%]") +
      xlim(0, max(mtr.df$abs, na.rm=T)*1.1) +
      ylim(0, max(mtr.df$pc, na.rm=T)*1.1)
    #install.packages("directlabels")
    #require(directlabels)
    GPL$add(direct.label(p_amt, list(cex=0.5, "smart.grid")))
    #print(p_amt)
    
  } 
  
  ##
  ## charge distribution
  ##
  ## todo: this is using MBR peptides which changes the distribution (usually making bad samples better) -- remove MBR peptides??
  ##       same for other plots down below
  fcChargePlot = function(d_sub)
  {
    GPL$add(
      mosaicPlot(d_sub$fc.raw.file, d_sub$charge) +
             xlab("RAW file") +
             ylab("fraction [%]") +
             guides(fill=guide_legend(title="charge"), color=FALSE) + # avoid black line in legend
             scale_x_reverse() +
             coord_flip() +
             theme(axis.text.y=element_blank(), axis.ticks=element_blank()) +
             ggtitle("EVD: charge distribution")
    )
    return (1);
  }
  byXflex(d_evd[, c("fc.raw.file", "charge")], d_evd$fc.raw.file, 30, fcChargePlot, sort_indices = FALSE)
  
  ## QC measure for charge centeredness
  qc_charge = ddply(d_evd[, c("charge",  "raw.file")], "raw.file", function(x) data.frame(raw.file = x$raw.file[1], X010X.EVD.charge = (sum(x$charge==2)/nrow(x))))
  qc_charge$X010X.EVD.charge = qualMedianDist(qc_charge$X010X.EVD.charge)
  QCM[["EVD.charge2"]] = qc_charge
  
  
  ## peptides per RT 
  raws_perPlot = 8
  smr_evdRT = summary(d_evd$retention.time)
  max_y = max(by(d_evd$retention.time, d_evd$fc.raw.file,  function(d) max(hist(d, breaks=seq(from=min(d)-3, to=max(d)+3, by=3), plot=F)$counts)))
  fcRTSubset <- function(d_sub, smr_evdRT)
  {
    qp = ggplot(data = d_sub, aes_string(x = "retention.time", colour = "fc.raw.file")) +
                geom_freqpoly(binwidth = 3) +
                xlim(from = smr_evdRT["Min."] - 1, to = smr_evdRT["Max."] + 2) +
                xlab("RT [min]") + 
                ylim(from = 0, to = max_y) +
                ylab("ID count") +
                ggtitle("EVD: IDs over RT") +
                theme(legend.title=element_blank()) +
                scale_fill_manual(values = rep(c("#a6cee3", "#1f78b4", "#b2df8a", "#33a02c", 
                                                 "#fb9a99", "#e31a1c", "#fdbf6f", "#ff7f00",
                                                 "#cab2d6", "#6a3d9a", "#ffff99"), 10))
    GPL$add(qp)
    return (1)
  }
  byXflex(d_evd, d_evd$raw.file, raws_perPlot, fcRTSubset, smr_evdRT=smr_evdRT, sort_indices = FALSE)
  
  ## QC measure for uniform-ness
  QCM[["ID_rate_over_RT"]] = ddply(d_evd[, c("retention.time",  "raw.file")], "raw.file", 
                                 function(x) data.frame(raw.file = x$raw.file[1], X015X.EVD.ID_rate_over_RT = qualUniform(x$retention.time)))
  
  
} 
  ## histograms of mass error
  
  ## MQ seems to mess up mass recal on some (iTRAQ) samples, by reporting ppm errors which include modifications
  ## , thus one sees >1e5 ppm, e.g. 144.10 Da
  ##  this affects both 'uncalibrated.mass.error..ppm.'   and
  ##                    'mass.error..ppm.'
  ## HOWEVER, 'uncalibrated...calibrated.m.z..ppm.' seems unaffected, but is not available in all MQ versions :(
  ##    also, 'mass' and 'm/z' columns seem unaffected.
  ##  But weirdly, one cannot reconstruct mass_error[ppm] from 'm/z' and mass columns (m/z is just too close to the theoretical value)
  ##  , this might be due to lacking precision of the stored numbers though
  ## The MQ list reports one case with high ppm error (8000), where the KR.count was at fault. We cannot
  ## reconstruct this.
  recal_message = ""
  ## check each raw file individually (usually its just a few who are affected)
  de_cal = ddply(d_evd, "raw.file", .fun = function(x) (quantile(abs(x$uncalibrated.mass.error..ppm.), probs = 0.5, na.rm=T)) > 1e3)
  if (any(de_cal[,2]))
  {
    ## for stats, show how many % of spectra suffer from this
    de_cal_pc = ddply(d_evd, "raw.file", .fun = function(x) (sum((abs(x$uncalibrated.mass.error..ppm.)) > 1e3, na.rm=T) / nrow(x) * 100))
    de_cal_pc_pl = de_cal_pc[de_cal_pc[,2]>0, ]
    byXflex(de_cal_pc_pl, 1:nrow(de_cal_pc_pl), 25, function(x) {
      dc = x[, 2]
      names(dc) = x[, 1]
      barplot(dc, horiz=T, las=2, main = "RAW files affected by wrong calibration numbers", xlab="% of ID's affected", cex.names = 0.5)
    }, sort_indices=F)
    affected_raw_files = de_cal_pc_pl[, 1]
    
    ## re-compute 'uncalibrated.mass.error..ppm.'
    
    if (!("uncalibrated...calibrated.m.z..ppm." %in% colnames(d_evd)))
    {
      stop("column missing: 'uncalibrated...calibrated.m.z..ppm.'")
    }
    if (!("mass" %in% colnames(d_evd)))
    {
      stop("column missing: 'mass'")
    }
    
    { ## this MQ version has it...
      
#       counts =  d_evd$k.count + d_evd$r.count
#       idx_decal = (abs(d_evd$uncalibrated.mass.error..ppm.) > 30)
#       hist(d_evd$mass - d_evd$m.z * d_evd$charge, 1000)
#       unique(d_evd$mass - d_evd$m.z * d_evd$charge)
#       hist(counts[!idx_decal])
      
      recal_message = "m/z recalibration bugfix applied"
      
      d_evd$theomz = d_evd$mass / d_evd$charge + 1.00726
      
      ## re-estimate 'mass.error..ppm.'
      d_evd$mass.error..ppm.2 = (d_evd$theomz - d_evd$m.z) / d_evd$theomz * 1e6
      #hist(d_evd$mass.error..ppm.2, 1000)
      #plot(d_evd$mass.error..ppm.2, d_evd$mass)
      #hist(d_evd$mass.error..ppm. - d_evd$mass.error..ppm.2, 100000, xlim=c(-30,30))
      d_evd$uncalibrated.mass.error..ppm.2 = d_evd$mass.error..ppm.2 + d_evd$uncalibrated...calibrated.m.z..ppm.
      
      # check if fix worked
      de_cal2 = ddply(d_evd, "raw.file", .fun = function(x) (median(abs(x$uncalibrated.mass.error..ppm.2), na.rm=T)) > 1e3)
      if (any(de_cal2[,2]))
      {
        ## fix did not work
        recal_message = "m/z recalibration bugfix applied but failed\n(there are still large numbers)"
      }
      
    }
#      else {
#       recal_message = "m/z recalibration bugfix cannot be applied\n(uncalibrated values not recoverable)\naffected samples are set to 0")
#       d_evd$uncalibrated.mass.error..ppm.2[d_evd$raw.file %in% affected_raw_files ] = 0
#     }
    #hist(d_evd$uncalibrated.mass.error..ppm. - d_evd$uncalibrated.mass.error..ppm.2, 100000, xlim=c(-30,30))
    
    idx_overwrite = (d_evd$raw.file %in% affected_raw_files)
    ## overwrite original values
    d_evd$mass.error..ppm.[idx_overwrite] = d_evd$mass.error..ppm.2[idx_overwrite]
    d_evd$uncalibrated.mass.error..ppm.[idx_overwrite] = d_evd$uncalibrated.mass.error..ppm.2[idx_overwrite]

    #max_ume = max(abs(d_evd$uncalibrated.mass.error..ppm.), na.rm=T)
    #max_idx = which (abs(d_evd$uncalibrated.mass.error..ppm.) == max_ume)
    #d_evd[max_idx,]
    #iqr
    
  } else
  {
    affected_raw_files = c()
  }
  
  
  ## some outliers have 5000ppm or so.. messing up the plot
  ## , so either remove outliers before (quantile estimation seems not robust enough) or don't plot them (default)
  plotAlignDiff = function(d_sub, affected_raw_files)
  {
    d_sub$col = c("black", "red")[(d_sub$raw.file %in% affected_raw_files) + 1]
    ylim_g = boxplot.stats(d_sub$uncalibrated.mass.error..ppm.)$stats[c(1, 5)]
    pl = ggplot(d_sub, col=d_sub$col) +
        geom_boxplot(aes_string(x = "fc.raw.file", y = "uncalibrated.mass.error..ppm."), varwidth=TRUE, outlier.shape = NA) +
        coord_flip() +
        ylab("ppm error") +
        xlab("") +
        ylim(ylim_g) +
        scale_colour_manual(values = c("black", "red")) +
        scale_x_discrete_reverse(d_sub$fc.raw.file)
    pl = addGGtitle(pl, "EVD: Uncalibrated mass error", recal_message)
    #print(pl)
    GPL$add(pl)
    return(1)
  }
  byXflex(d_evd, d_evd$fc.raw.file, 20, plotAlignDiff, sort_indices=F, affected_raw_files=affected_raw_files)

  param_name_EV_PrecursorTolPPM = "File$Evidence$PrecursorTolPPM"
  param_def_EV_PrecursorTolPPM = 20
  param_EV_PrecursorTolPPM = getYAML(yaml_obj, param_name_EV_PrecursorTolPPM, param_def_EV_PrecursorTolPPM)
  qc_MS1deCal = ddply(d_evd[, c("uncalibrated.mass.error..ppm.", "fc.raw.file")], "fc.raw.file", 
                      function(x) data.frame(med_rat = qualCenteredRef(x$uncalibrated.mass.error..ppm., param_EV_PrecursorTolPPM)))
  colnames(qc_MS1deCal) = c("fc.raw.file", "X025X.EVD.MS1_DeCalibration (" %+% param_EV_PrecursorTolPPM %+% ")")
  QCM[["EVD.MS1_decalibration"]] = qc_MS1deCal


  
  ##
  ## post calibration
  ##
  plotAlignDiffCal = function(d_sub, affected_raw_files)
  {
    col = c("black", "red")[(unique(d_sub$raw.file) %in% affected_raw_files) + 1]
    ylim_g = boxplot.stats(d_sub$mass.error..ppm.)$stats[c(1, 5)]
    pl = ggplot(d_sub, col=d_sub$col) +
      geom_boxplot(aes_string(x = "fc.raw.file", y = "mass.error..ppm."), varwidth=TRUE, outlier.shape = NA) +
      coord_flip() +
      ylab("ppm error") +
      xlab("") +
      ylim(ylim_g) +
      scale_colour_manual(values = c("black", "red")) +
      scale_x_discrete_reverse(d_sub$fc.raw.file)
    pl = addGGtitle(pl, "EVD: Calibrated mass error", recal_message)
    GPL$add(pl)
    return (1)
  }
  byXflex(d_evd, d_evd$fc.raw.file, 20, plotAlignDiffCal, sort_indices=F, affected_raw_files=affected_raw_files)
  ## QC measure for post-calibration ppm error
  ## .. assume 0 centered and StdDev of observed data
  obs_par = ddply(d_evd[, c("mass.error..ppm.", "fc.raw.file")], "fc.raw.file", function(x) data.frame(mu = mean(x$mass.error..ppm., na.rm=T), sd = sd(x$mass.error..ppm., na.rm=T)))
  qc_MS1Cal = data.frame(fc.raw.file = obs_par$fc.raw.file, 
                         X026X.EVD.MS1_Calibration = sapply(1:nrow(obs_par), function(x) qualGaussDev(obs_par$mu[x], obs_par$sd[x])))
  QCM[["EVD.MS1_calibration"]] = qc_MS1Cal



  ## compute how well calibration worked
  cal_medians = as.vector(by(d_evd$mass.error..ppm., d_evd$raw.file, median, na.rm=T))
  cal_stats = quantile(cal_medians, probs=c(0,0.5,1))
  cat(pastet("medianCalibratedMassError(min,median,max) [ppm]", paste(cal_stats, collapse=",")), file=stats_file, append=T, sep="\n") 


  ## elaborate contaminant fraction per Raw.file (this is not possible from PG, since raw files could be merged)
  ## find top 5 contaminants (globally)
  
  ## if possible, work on protein names (since MQ1.4), else use proteinIDs
  if ("protein.names" %in% colnames(d_evd))
  {
    evd_pname = "protein.names"        
  } else {
    evd_pname = "proteins" 
  }
  ## protein.names are sometimes not unique, e.g. if a contaminant is involved:
  ## "P02768;CON__P02768-1" and "P02768" will both give the same name (since contaminant name is empty)
  ## Thus, the distribution of bars will look slightly different (but summed percentages are identical)

  ## some protein.names are empty (usually the CON__ ones) ... so we substitute with ID
  d_evd$pname = d_evd[, evd_pname];
  d_evd$pname[d_evd$pname==""] = d_evd$proteins[d_evd$pname==""] ## a NOP if it already is 'proteins', but ok

  d_evd.totalInt = sum(as.numeric(d_evd$intensity), na.rm=T)
  d_evd.cont.only = d_evd[d_evd$contaminant,]
  cont.top = by(d_evd.cont.only, d_evd.cont.only$pname, function(x) sum(as.numeric(x$intensity), na.rm=T) / d_evd.totalInt*100)
  cont.top.sort = sort(cont.top, decreasing=T)
  #head(cont.top.sort)
  cont.top5.names = names(cont.top.sort)[1:5]
  

  plotCont = function(d_evd_sub, top5) 
  { 
    #top5 = cont.top5.names
    #d_evd_sub = d_evd[, c("intensity", "pname", "fc.raw.file", "contaminant", "proteins", "protein.names")]
    #head(d_evd_sub)
    
    intensity = NULL ## to make R CHECK happy...
    d_evd.cont.only_sub = d_evd_sub[d_evd_sub$contaminant,]
    ## rewrite prot names, and subsume 6th and below as 'other'
    d_evd.cont.only_sub[!(d_evd.cont.only_sub$pname %in% top5), "pname"] = 'other'
    ## aggregate identical proteins
    ##  use sum(as.numeric(.)) to prevent overflow
    d_sum = ddply(d_evd.cont.only_sub[, c("intensity", "pname", "fc.raw.file")], c("pname", "fc.raw.file"), 
                  function(x) summarise(x, s.intensity=sum(as.numeric(intensity), na.rm=T)))
    ## normalize by total intensity of raw file
    d_norm = ddply(d_evd_sub[, c("intensity", "fc.raw.file")],  "fc.raw.file", 
                   function(x) summarise(x, s.intensity=sum(as.numeric(intensity), na.rm=T)))
    d_sum$s.intensity = d_sum$s.intensity / d_norm$s.intensity[match(d_sum$fc.raw.file, d_norm$fc.raw.file)] * 100
    ## shorten protein-groups (at most two protein names)
    d_sum$pname = sapply(d_sum$pname, function(x) {
      p.split = unlist(strsplit(x, split=";"))
      ## shorten entries as well (at most 20 characters)
      p.split_s = sapply(p.split, function(x) ifelse(nchar(x)>20, paste0(substr(x, start=1, stop=18), ".."), x))
      r = ifelse(length(p.split_s)<=2, paste(p.split_s, sep="", collapse=";"),
                                       paste0(paste(p.split_s[1:2], sep="", collapse=";"),";..."))
      return(r)
    })
    ## order of pname determines order of bars    
    d_sum1 = d_sum[d_sum$pname!="other",]
    d_sum2 = d_sum[d_sum$pname=="other",]
    d_sum = rbind(d_sum1, d_sum2)
    ## value of factors determines order in the legend
    ## --> make proteins a factor, with 'other' being the first
    d_sum$pname = factor(d_sum$pname, levels=unique(c("other", d_sum$pname)))
    as.numeric(d_sum$pname)
    
    ## plot
    GPL$add(ggplot(d_sum) +
      geom_bar(aes_string(x = "factor(fc.raw.file)", y = "s.intensity", fill = "pname"), stat="identity") +
      xlab("")  +
      theme_bw() +
      ggtitle("EVD: Contaminant per RAW file") +
      ylab("contaminant (% intensity)") +
      scale_fill_manual(values = brewer.pal(6,"Accent")) + 
      scale_colour_manual(values = brewer.pal(6,"Accent")) +
      geom_hline(aes_string(yintercept = "5"), linetype='dashed') +
      guides(fill = guide_legend(nrow = 2, ncol = 3, byrow = TRUE, reverse = T)) +
      theme(legend.position="top", legend.title=element_blank()) +
      coord_flip() +
      scale_x_discrete_reverse(d_sum$fc.raw.file)
    )
    return (1)  
  }

  byXflex(d_evd[, c("intensity", "pname", "fc.raw.file", "contaminant")], d_evd$fc.raw.file, 40, sort_indices=F, plotCont, top5=cont.top5.names)
  
  ## QC measure for contamination
  qc_contaminants = ddply(d_evd[, c("intensity", "contaminant", "fc.raw.file")], "fc.raw.file", 
                          function(x) data.frame(X001X.EVD.Contaminants =
                                                   1-qualLinThresh(sum(as.numeric(x$intensity[x$contaminant]), na.rm=T)/
                                                                sum(as.numeric(x$intensity), na.rm=T))))
  QCM[["EVD.Contaminants"]] = qc_contaminants

  
  ### peak width (all raw.files --- too much for large experiments)
  #   GPL$add(ggplot(d_evd, aes_string(x="retention.length", colour="fc.raw.file")) +
  #           geom_density() +
  #           scale_x_log10() + xlab("retention length") + ggtitle("EVD: Peak width histogram")
  #         )
  ## compute density manually
  fcn_peakWidth = function(x) 
  {      
    tmp = density(x$retention.length, na.rm=T)
    x1 = tmp$x
    y1 = tmp$y
    data.frame(retention.length = x1, dens = y1, fc.raw.file = x$fc.raw.file[1])
  }
  d_evd.m.d_l = dlply(d_evd[,c("retention.length","fc.raw.file")], "fc.raw.file", .fun = fcn_peakWidth)
  d_evd.m.d = Reduce(rbind, d_evd.m.d_l)
  ## the merged (=average peak)  
  #d_evd.m.d = rbind(d_evd.m.d, fcn_peakWidth(data.frame(retention.length = d_evd$retention.length, fc.raw.file="merge")))  
  head(d_evd.m.d)
  tail(d_evd.m.d)
  ## median and position in density
  d_evd.m.d_med = ddply(d_evd[,c("retention.length","fc.raw.file")], "fc.raw.file", .fun = function(x) {
    fcr = as.character(x$fc.raw.file[1])
    #cat(fcr)
    m = median(x$retention.length, na.rm=T);
    ## closest point in density
    idx = which.min(abs(m - d_evd.m.d_l[[fcr]]$retention.length))
    y = d_evd.m.d_l[[fcr]]$dens[idx]
    return(data.frame(m = m, y = y))
  })


  d_evd.m.d$block = factor(assignBlocks(d_evd.m.d$fc.raw.file, 8))
  ## identical limits for all plots
  d_evd.xlim = quantile(d_evd.m.d$retention.length, c(0,1))
  d_evd.xlim = c(max(1e-1,d_evd.xlim[1]), d_evd.xlim[2]) ## could give negative numbers and we plan to plot on log scale
  d_evd.ylim = quantile(d_evd.m.d$dens, c(0,1))
  for (bl in unique(d_evd.m.d$block))
  {
    p = ggplot(d_evd.m.d[d_evd.m.d$block==bl,], aes_string(x = "retention.length", y = "dens", colour = "fc.raw.file")) +
            #scale_fill_manual(values = brewer.pal(8,"Accent")) + 
            #scale_colour_manual(values = brewer.pal(8,"Accent")) +
            xlab("retention length [min]") +
            ylab("density") +
            ylim(d_evd.ylim) +
            scale_x_continuous(limits=d_evd.xlim, trans = "log10", breaks = c(0.01, 0.1, 0.25, 0.5, 1, 3, 10, 30)) +
            ggtitle("EVD: Peak width distribution") +
            theme(legend.title=element_blank(), axis.text.x = element_text(angle = 90, vjust = 0.5)) +
            geom_line(stat="identity", size=2, alpha=0.7) +
            geom_point(data = d_evd.m.d_med[d_evd.m.d_med$fc.raw.file %in% d_evd.m.d$fc.raw.file[d_evd.m.d$block==bl],],
                       aes_string(x="m", y="y", colour = "fc.raw.file"), size=2) ## currently not visible (confusing)
    #print(p)
    GPL$add(p)
  }
  ## QC measure for reproducibility of peak shape
  ##.. create a list of distributions
  l_dists = dlply(d_evd[,c("retention.length","fc.raw.file")], "fc.raw.file", function(x) return(x$retention.length))
  qc_evd_PeakShape = qualBestKS(l_dists)
  colnames(qc_evd_PeakShape) = c("fc.raw.file", "X017X.EVD.RT_Peak_Similarity")
  QCM[["EVD.PeakShape"]] = qc_evd_PeakShape

  
  ### barplot
  ## determine duplicated sequences
  raws = as.factor(sort(as.character(unique(d_evd$fc.raw.file))))

  ## plot overview: percent of duplicate identifications (exclusion not "long" enough)
  d_dups = ddply(d_evd[, c("fc.raw.file","modified.sequence", "charge", "match.time.difference")], "fc.raw.file", 
    function(d_sub)
    { 
      nrDuplicated = sum(duplicated(d_sub) ) # | duplicated(d, fromLast=TRUE)) ## depending on how we want to count...
      dups = data.frame(dups = nrDuplicated/nrow(d_sub)*100)
      return (dups)
    })
  twinThresh = 100 ## disabled for now... (much too slow)
  
  fcnPlotTwin = function(d_dups)
  {
    GPL$add(
      ggplot(d_dups) + 
                     geom_bar(stat="identity", aes_string(x = "fc.raw.file", y = "dups")) +
                     xlab("") +
                     ylab("percent") +
                     ggtitle(paste0("EVD: Percent twin sequences (identical sequence & charge & rawfile)")) + 
                     theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
    )
    return(TRUE)
  }
  byXflex(d_dups, d_dups$fc.raw.file, 30, fcnPlotTwin, sort_indices = F)
  ## QC measure for centered-ness of MS2-calibration
  qc_evd_twin = d_dups
  qc_evd_twin$X020X.EVD.Twin_Sequences = 1 - qualLinThresh(qc_evd_twin$dups/100)
  QCM[["EVD.Twin"]] = qc_evd_twin[, c("fc.raw.file", "X020X.EVD.Twin_Sequences")]

  if (max(d_dups$dups)>twinThresh)
  { ## warn:: very!! slow!!
    d_evd$duplicateMinRTDiff = NA;
    #install.packages("foreach")
    #install.packages("doParallel")
    #library(doParallel)
    #require(foreach)
    #registerDoParallel(cores=3)
    s = Sys.time();
    for (rf in raws) 
    {
      cat(rf)
      idx = which(d_evd$fc.raw.file==rf) ## subset of certain raw.file
      d_string = sapply(idx, function(x) 
        ## MTD is important to not consider inferred evidence by match between runs
        paste0(d_evd[x,c("raw.file","modified.sequence", "charge", "match.time.difference")], collapse=""))
      groups = Filter(function(x) length(x)>1, split(idx, d_string))
      head(groups)
      ## for each group: get minimal RT difference between all elements
      names(groups) = sapply(groups, function(g) return (g[1]))
      minRTs = unlist(lapply(groups, function(g) {
        RT_min = min(diff(sort(d_evd$retention.time[g])))
        return (RT_min)
      }))
      ## minRTs is now a list of minimal RT differences, with element names giving the index of a first group member
      head(minRTs)
      d_evd$duplicateMinRTDiff[as.numeric(names(minRTs))] = minRTs
    }
    s - Sys.time()
    
    ## plot histograms of time differences
    plotTimeDiff = function(d_sub)
    {
      GPL$add(ggplot(d_sub) +
              geom_histogram(aes_string(x = "duplicateMinRTDiff"), binwidth = 0.05) +
              xlim(-1,5) + 
              facet_wrap(~fc.raw.file) +
              xlab("retention delta between twin identifications") +
              ggtitle("EVD: Dynamic Exclusion Performance")
             )
      return(1)
    }
    pp = byXflex(d_evd, d_evd$fc.raw.file, raws_perPlot, plotTimeDiff, sort_indices=F)
  }  
  
}  


######
######  msms.txt ...
######

enabled_msms = getYAML(yaml_obj, "File$MsMs$enabled", TRUE)
if (enabled_msms)
{
  ### missed cleavages (again)
  ### this is the real missed cleavages estimate ... but slow
  #d_msms_s = mq$readMQ(txt_files$msms, type="msms", filter = "", nrows=10)
  #colnames(d_msms_s)
  #head(d_msms)
  d_msms = mq$readMQ(txt_files$msms, type="msms", filter = "", col_subset=c("Missed\\.cleavages", "^Raw.file$", "mass.deviations..da.", "reverse"))
  
  d_msms = d_msms[order(match(as.character(d_msms$fc.raw.file), mq$raw_file_mapping$to)),]
  ## sort fc.raw.file's factor values as well
  d_msms$fc.raw.file = factor(d_msms$fc.raw.file, levels = mq$raw_file_mapping$to, ordered = TRUE)
  
  
  ms2_decal = ddply(d_msms, "fc.raw.file", .fun = function(x) {
    #system.time((ms = unlist(sapply(x$mass.deviations..da., function(xs) strsplit(xs, split=";", fixed=T)))))
    # much faster:
    #system.time((ms = unlist(strsplit(paste(x$mass.deviations..da., sep="", collapse=";"), split=";", fixed=T))))
    idx_nr = which(!x$reverse)
    ## select a representative subset, otherwise the number of datapoints is just too large
    step = ceiling(length(idx_nr)/1000)
    idx_nr_subset = idx_nr[seq(1,length(idx_nr), by=step)]
    
    x_nr = paste(x$mass.deviations..da.[idx_nr_subset], sep="", collapse=";")
    ms = unlist(strsplit(x_nr, split=";", fixed=T))
    df.ms = data.frame(msErr = ms, type="forward")
    
    if (any(x$reverse))
    {
      idx_nr = which(x$reverse)
      ## select a representative subset, otherwise the number of datapoints is just too large
      step = ceiling(length(idx_nr)/1000)
      idx_nr_subset = idx_nr[seq(1,length(idx_nr), by=step)]
      
      x_nr = paste(x$mass.deviations..da.[idx_nr_subset], sep="", collapse=";")
      ms = unlist(strsplit(x_nr, split=";", fixed=T))
      ## only merge if we have hits (reverse hits might be few and $mass.deviations..da. might be empty)
      if (length(ms)) df.ms = rbind(df.ms, data.frame(msErr = ms, type="decoy"))
    }
    
    return (df.ms)
  })
  head(ms2_decal)
  ms2_decal$msErr = as.numeric(as.character(ms2_decal$msErr))
  ms2_binwidth = (max(ms2_decal$msErr, na.rm=T) - min(ms2_decal$msErr, na.rm=T))/20
  ## precision (plotting is just so much quicker, despite using a fixed binwidth)
  ms2_decal$msErr = round(ms2_decal$msErr, digits=ceiling(-log10(ms2_binwidth)+1))
  head(ms2_decal)
  
  fcPlotMS2Dec <- function(d_sub)
  {
    pl = 
      ggplot(data = d_sub, aes_string(x = "msErr", fill="type")) + 
      geom_histogram(binwidth = ms2_binwidth) +
      xlab("fragment mass delta [Da]") +  
      ylab("count") + 
      scale_fill_manual(values = c("#99d594",  "#ff0000")) +
      ggtitle("MSMS: Fragment mass errors per Raw file") +
      facet_wrap(~fc.raw.file)
    GPL$add(pl)
    return(1)
  }
  byXflex(ms2_decal, ms2_decal$fc.raw.file, 9, fcPlotMS2Dec, sort_indices=F)
  ## QC measure for centered-ness of MS2-calibration
  head(ms2_decal)
  qc_MS2_decal = ddply(ms2_decal, "fc.raw.file", 
                       function(x)
                       {
                         xx = na.omit(x$msErr);
                         data.frame(X028X.MSMS.MS2_Calibration = qualCentered(xx))
                       }) 
  qc_MS2_decal
  QCM[["MSMS.MS2_Calibration"]] = qc_MS2_decal[, c("fc.raw.file", "X028X.MSMS.MS2_Calibration")]
  
  
  ## missed cleavages per Raw file
  max_mc = max(-Inf, d_msms$missed.cleavages, na.rm=T) ## will be -Inf iff enzyme was not specified and columns is 100% NA
  if (!is.infinite(max_mc))
  { ## MC's require an enzyme to be set
    smr_msmsMC = summary(d_msms$missed.cleavages)
    fcMCRTSubset <- function(d_sub, smr_msmsMC)
    {
      st_bin.m = melt(d_sub, id.vars = c("fc.raw.file"))
      pl = 
        ggplot(data = st_bin.m, aes_string(x = "factor(fc.raw.file)", y = "value", fill = "variable")) + 
                  geom_bar(stat="identity") +
                  xlab("RAW file") +  
                  ylab("missed cleavages [%]") + 
                  theme(legend.title=element_blank()) +
                  scale_fill_manual(values = rep(c("#99d594", "#ffffbf", "#fc8d59", "#ff0000"), 10)) +
                  geom_abline(alpha = 0.5, intercept = 0.75, slope = 0, colour = "black", linetype = "dashed", size = 1.5) +
                  coord_flip() +
                  scale_x_discrete_reverse(st_bin.m$fc.raw.file)
      pl = addGGtitle(pl, "MSMS: Missed cleavages per RAW file", "(includes contaminants)")
      GPL$add(pl)
      return(1)
    }
    
    st_bin = ddply(d_msms, "fc.raw.file", .fun = function(x) {
      t = table(x$missed.cleavages)/nrow(x)
      r = rep(0, max_mc + 1)
      names(r) = as.character(0:max_mc)
      cat("r")
      cat(r)
      r[names(t)] = t
      return (r)
    })
    byXflex(st_bin, st_bin$fc.raw.file, 25, fcMCRTSubset, smr_msmsMC=smr_msmsMC, sort_indices=F)
    
    mcZero = st_bin[, "0"] * 100
    mcZero_stat = 100 - rev(quantile(mcZero, probs=c(0,0.5,1)))
    cat(pastet("missedCleavages>0 (min,median,max) [%]", paste0(mcZero_stat, collapse=",")), file=stats_file, append=T, sep="\n")
    
    ## QC measure for missed-cleavages variation
    qc_mc = data.frame(fc.raw.file = st_bin$fc.raw.file, X004X.MSMS.MC = st_bin[, "0"])
    QCM[["MSMS.MC"]] = qc_mc
    qc_mc$X007X.MSMS.MC_Var = qualMedianDist(qc_mc$X004X.MSMS.MC)
    QCM[["MSMS.MC_Var"]] = qc_mc
    
    
  } ## end MC check
  
 
}

######
######  msmsScans.txt ...
######

enabled_msmsscans = getYAML(yaml_obj, "File$MsMsScans$enabled", TRUE)
if (enabled_msmsscans)
{
  #d_msmsScan_h = mq$readMQ(txt_files$msmsScan, type="msms", filter = "", nrows=2)
  d_msmsScan = mq$readMQ(txt_files$msmsScan, type="msms", filter = "", col_subset=c("^retention.time$", "^Identified", "Scan.event.number", "Raw.file", "Elapsed.Time", "Ion.Injection.Time"))
  #colnames(d_msmsScan)
  #head(d_msmsScan)
  #unique(d_msmsScan$Identified)
  
  d_msmsScan = d_msmsScan[order(match(as.character(d_msmsScan$fc.raw.file), mq$raw_file_mapping$to)),]
  ## sort fc.raw.file's factor values as well
  d_msmsScan$fc.raw.file = factor(d_msmsScan$fc.raw.file, levels = mq$raw_file_mapping$to, ordered = TRUE)
  
  
  ## scan event number
  scan.event.number = NULL ## make R check happy
  
  ## maximum scan event over time
  # round RT to 1 min intervals
  d_msmsScan$rRT = round(d_msmsScan$retention.time/2)*2
  
  DFmse = ddply(d_msmsScan, c("fc.raw.file"), function(x) {
    ## sort by RT
    if (is.unsorted(x$retention.time))
    { ## should not happen, but just to make sure
      x = x[, order(x$retention.time)]
    }
    ## only take the highest scan event (SE) in a series
    maxN = getMaxima(x$scan.event.number, thresh_rel = 0.0)
    df.max = x[maxN,]
    ## use median of that within one RT bin
    meanN = ddply(df.max, c("rRT"), summarise, medSE = median(scan.event.number))
    return (meanN)    
  })
  
  head(DFmse)
  plotMaxSEinRT = function(data)
  { 
    GPL$add(
      ggplot(data, aes_string(x = "rRT", y = "medSE", col = "fc.raw.file")) +
        geom_point(stat="identity", position = "jitter") +
        xlab("retention time [min]") +
        ylab("highest N [median per RT bin]") +
        #stat_smooth(method = "loess", formula = y ~ x, se = FALSE, span = 0.1) +
        guides(color=guide_legend(title="")) +
        ggtitle("MSMSscans: TopN over RT")
    )
    return (1)
  }
  byXflex(DFmse, DFmse$fc.raw.file, 9, plotMaxSEinRT, sort_indices=F)
  
  ## QC measure for smoothness of TopN over RT
  qc_TopNRT = ddply(DFmse, "fc.raw.file", function(x) data.frame(X012X.MSMSScans.TopN_over_RT = qualUniform(x$medSE)))
  QCM[["MSMSscans.TopN_over_RT"]] = qc_TopNRT
  
  
  ##
  ## scan event counts
  ##
  DFc = ddply(d_msmsScan, c("scan.event.number", "fc.raw.file"), summarise, n = length(scan.event.number))
  dfc.ratio = ddply(DFc, "fc.raw.file", function(x, maxn)
  {
    ## sort x by scan event
    event_count = x$n
    ## verify its monotonically increasing
    if (is.unsorted(rev(event_count))) {
      #print(x)
      stop("Scan event distribution is not monotonically increasing!")
    } 
    ## verify that there are no gaps
    if (max(x$scan.event.number) != nrow(x)) {
      #print(x)
      stop("Scan event distribution has unexpected holes...!")
    }
    
    event_pre = c(event_count[-1], 0)
    event_diff = event_count - event_pre
    
    ## build new DF of fixed length
    sn = x$scan.event.number
    if (max(sn) < maxn) 
    {
      event_diff = c(event_diff, rep(0, maxn-max(sn)))
      sn = c(sn, (max(sn)+1):maxn)
    }
    DF.new = data.frame(scan.event.number = sn, n = event_diff)
    return (DF.new)
  }, maxn = max(DFc$scan.event.number))
  head(dfc.ratio)
  
  plotScanEventDiff = function(dfc.ratio)
  {
    GPL$add(
      ggplot(dfc.ratio, aes_string(x = "scan.event.number", y = "n")) +
        geom_bar(stat="identity") +
        xlab("highest scan event") +
        ylab("count") +
        facet_wrap(~ fc.raw.file, scales = "free_y") +
        ggtitle(paste0("MSMSscans: TopN"))
    )
    return (1)
  }
  byXflex(dfc.ratio, dfc.ratio$fc.raw.file, 9, plotScanEventDiff, sort_indices=F)
  
  ## QC measure for always reaching the maximum TopN
  maxTopN = max(dfc.ratio$scan.event.number)
  qc_TopN = ddply(dfc.ratio, "fc.raw.file", function(x) data.frame(X035X.MSMSScans.TopN_high = qualHighest(x$n, maxTopN)))
  QCM[["MSMSscans.TopN"]] = qc_TopN
  

  ##
  ## Scan event: % identified
  ##
  #require(plyr)
  DF = ddply(d_msmsScan, c("scan.event.number", "identified", "fc.raw.file"), summarise, n = length(scan.event.number))
  
  # try KS on underlying data instead of using qualUniform()
#   DF2= ddply(d_msmsScan, "fc.raw.file", function(rf){
#     cat(class(rf))
#     cat(rf$fc.raw.file[1])
#     idx_p = rf$identified=="+"
#     cat(length(idx_p) %+% "\n")
#     kk = ks.test(rf$scan.event.number[idx_p], rf$scan.event.number[-idx_p])
#     cat(kk$p.value)
#     kk$statistic  # = 'D' ,,  p.value is much smaller (~0)
#   })
#   --> fail, 'D' and p-values are too low
  df.ratio = ddply(DF, c("scan.event.number", "fc.raw.file"), function(x)
  {
    xp = xm = 0
    if ("+" %in% x$identified) xp = x$n[x$identified=="+"]
    if ("-" %in% x$identified) xm = x$n[x$identified=="-"]
    ratio = xp * 100 / sum(xp, xm)
    return (data.frame(ratio = ratio, count = sum(x$n)))
  })
  head(df.ratio)

  plotScanEvent = function(df.ratio)
  {
    
    p = ggplot(df.ratio, aes_string(x = "scan.event.number", y = "ratio", alpha = "count")) +
        geom_bar(stat="identity") +
        xlab("scan event") +
        ylab("percent identified") +
        facet_wrap(~ fc.raw.file) +
        ggtitle(paste0("MSMSscans: TopN % identified over N"))
    return (p)
  }
  pl = byXflex(df.ratio, df.ratio$fc.raw.file, 9, plotScanEvent, sort_indices=F)
  for (p in pl) GPL$add(p)
  
  ## QC measure for constantly identifiying peptides, irrespective of scan event number
  ## -- we weight scan events by their number of occurence
  qc_TopN_ID = ddply(df.ratio, "fc.raw.file", function(x) data.frame(X038X.MSMSScans.TopN_ID_rate_over_N = qualUniform(x$ratio, x$count)))
  QCM[["MSMSscans.TopN_ID_over_N"]] = qc_TopN_ID
  
}

hm = getQCHeatMap(QCM, mq$raw_file_mapping)
write.table(hm[["table"]], file = heatmap_values_file, quote= T, sep = "\t", row.names=F)
GPL$add(hm[["plot"]], ".heatmap")

## get MQ short name mapping plot (might be NULL if no mapping was required)
GPL$add(mq$plotNameMapping(), ".name_mapping")

##
## plot it to PDF!
##
pdf(report_file, onefile=T)
print(GPL$get(".pl_params"))    # parameters
print(GPL$get(".name_mapping")) # short file mapping (if required)
print(GPL$get(".heatmap"))      # summary heatmap
GPL_lst = GPL$getList()
for (idx in sort(names(GPL_lst)))
{
  if (grepl("^\\.", idx)) next;
  print(GPL_lst[[idx]])
}
dev.off();

## save plot object (for easier access, in case someone wants high-res plots)
save(file = R_plots_file, list = "GPL")

### write YAML config
writeYAML(yaml_file, yaml_obj)

cat(paste("Report file created at\n\n    ", report_file, "\n\n", sep=""))
cat(paste0("\n\nTime elapsed: ", round(as.double(Sys.time() - time_start, units="mins"), 1), " min\n\n"))

## return path to PDF report and YAML config
return (list(report_filename = report_file, yaml_filename = yaml_file, heatmap_filename = heatmap_values_file))
}
